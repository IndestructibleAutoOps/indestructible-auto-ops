#!/usr/bin/env python3
"""
GL Platform Consolidation Tool
è‡ªå‹•æ•´åˆæ ¹ç›®éŒ„çš„ GL å¹³å°åˆ°çµ±ä¸€æ¶æ§‹
"""

import json
import shutil
import subprocess
from pathlib import Path
from typing import Dict, List

# å¹³å°é·ç§»æ˜ å°„è¡¨
CONSOLIDATION_MAP = {
    # GL00-09: ä¼æ¥­æ¶æ§‹å±¤
    "gl00-09-enterprise-architecture": {
        "gl-enterprise-architecture": "specifications/",
        "gl-governance-architecture-platform": "governance/",
    },
    # GL10-19: å¹³å°æœå‹™å±¤
    "gl10-19-platform-services": {
        "gl-platform-core-platform": "core/",
        "gl-platform-services": "services/",
    },
    # GL20-29: æ•¸æ“šè™•ç†å±¤
    "gl20-29-data-processing": {
        "gl-data-processing": "processing/",
        "gl-data-processing-platform": "processing-platform/",
        "gl-search-elasticsearch-platform": "search/",
    },
    # GL30-49: é‹è¡Œæ™‚åŸ·è¡Œå±¤
    "gl30-49-runtime-execution": {
        "gl-execution-runtime": "execution/",
        "gl-runtime-engine-platform": "engine/",
        "gl-runtime-execution-platform": "execution-platform/",
        "gl-runtime-services-platform": "services/",
    },
    # GL50-59: ç›£æ§å¯è§€æ¸¬æ€§å±¤
    "gl50-59-monitoring-observability": {
        "gl-monitoring-observability-platform": "monitoring/",
        "gl-monitoring-system-platform": "system/",
        "gl-observability": "observability/",
    },
    # GL60-80: æ²»ç†åˆè¦å±¤
    "gl60-80-governance-compliance": {
        "gl-governance-compliance": "compliance/",
        "gl-governance-compliance-platform": "compliance-platform/",
    },
    # GL81-83: æ“´å±•æœå‹™å±¤
    "gl81-83-extension-services": {
        "gl-extension-services": "extensions/",
        "gl-extension-services-platform": "extensions-platform/",
        "gl-integration-hub-platform": "integrations/",
    },
    # GL90-99: å…ƒè¦ç¯„å±¤
    "gl90-99-meta-specifications": {
        "gl-meta-specifications": "specifications/",
        "gl-meta-specifications-platform": "specifications-platform/",
        "gl-semantic-core-platform": "semantic-core/",
    },
}

# å°ˆé …å¹³å°é·ç§»åˆ° platforms/
SPECIAL_PLATFORMS = {
    "gl-automation-instant-platform": "platforms/automation/instant/",
    "gl-automation-organizer-platform": "platforms/automation/organizer/",
    "gl-quantum-computing-platform": "platforms/quantum/",
    "gl-infrastructure-foundation-platform": "platforms/infrastructure/",
}


class PlatformConsolidator:
    def __init__(
        self, workspace_root: Path, dry_run: bool = True, skip_backup: bool = False
    ):
        self.root = workspace_root
        self.dry_run = dry_run
        self.skip_backup = skip_backup
        self.moved_dirs = []
        self.errors = []

    def backup_current_state(self):
        """å‰µå»ºå‚™ä»½"""
        print("ğŸ“¦ Creating backup...")
        if self.skip_backup:
            print("   Skipped (backup disabled)")
            return

        if not self.dry_run:
            subprocess.run(
                ["git", "add", "-A"],
                cwd=self.root,
                check=True,
            )
            subprocess.run(
                [
                    "git",
                    "commit",
                    "-m",
                    "backup: before platform consolidation",
                    "--allow-empty",
                ],
                cwd=self.root,
            )
            tag_name = f"platform-consolidation-backup"
            subprocess.run(
                ["git", "tag", "-f", tag_name],
                cwd=self.root,
                check=True,
            )
            print(f"âœ… Backup created with tag: {tag_name}")
        else:
            print("   [DRY RUN] Would create git backup")

    def create_new_structure(self):
        """å‰µå»ºæ–°çš„ç›®éŒ„çµæ§‹"""
        print("\nğŸ“ Creating new directory structure...")
        for target_dir in CONSOLIDATION_MAP.keys():
            target_path = self.root / target_dir
            if not self.dry_run:
                target_path.mkdir(parents=True, exist_ok=True)
                print(f"   âœ“ Created: {target_dir}")
            else:
                print(f"   [DRY RUN] Would create: {target_dir}")

        # å‰µå»º platforms å­ç›®éŒ„
        for target in set(p.split("/")[0] for p in SPECIAL_PLATFORMS.values()):
            target_path = self.root / target
            if not self.dry_run:
                target_path.mkdir(parents=True, exist_ok=True)
            else:
                print(f"   [DRY RUN] Would create: {target}")

    def migrate_platforms(self):
        """é·ç§»å¹³å°ç›®éŒ„"""
        print("\nğŸ”„ Migrating platforms...")

        # é·ç§»åˆ° GL å±¤ç´šç›®éŒ„
        for target_dir, sources in CONSOLIDATION_MAP.items():
            print(f"\n   â†’ {target_dir}:")
            for source_name, sub_path in sources.items():
                source_path = self.root / source_name
                target_path = self.root / target_dir / sub_path

                if source_path.exists():
                    if not self.dry_run:
                        target_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.move(str(source_path), str(target_path))
                        self.moved_dirs.append(
                            (source_name, f"{target_dir}/{sub_path}")
                        )
                        print(f"     âœ“ {source_name} â†’ {sub_path}")
                    else:
                        print(f"     [DRY RUN] Would move: {source_name} â†’ {sub_path}")
                else:
                    msg = f"     âš  Source not found: {source_name}"
                    print(msg)
                    self.errors.append(msg)

        # é·ç§»å°ˆé …å¹³å°
        print("\n   â†’ Special Platforms:")
        for source_name, target_rel in SPECIAL_PLATFORMS.items():
            source_path = self.root / source_name
            target_path = self.root / target_rel

            if source_path.exists():
                if not self.dry_run:
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(source_path), str(target_path))
                    self.moved_dirs.append((source_name, target_rel))
                    print(f"     âœ“ {source_name} â†’ {target_rel}")
                else:
                    print(f"     [DRY RUN] Would move: {source_name} â†’ {target_rel}")
            else:
                msg = f"     âš  Source not found: {source_name}"
                print(msg)

    def generate_report(self):
        """ç”Ÿæˆé·ç§»å ±å‘Š"""
        print("\nğŸ“Š Generating migration report...")

        report = {
            "timestamp": "2026-02-06",
            "dry_run": self.dry_run,
            "moved_directories": len(self.moved_dirs),
            "migrations": self.moved_dirs,
            "errors": self.errors,
            "status": "success" if not self.errors else "completed_with_warnings",
        }

        report_path = self.root / "platform-consolidation-report.json"
        if not self.dry_run:
            with open(report_path, "w") as f:
                json.dump(report, f, indent=2)
            print(f"   âœ“ Report saved to: {report_path}")
        else:
            print(f"   [DRY RUN] Would save report to: {report_path}")

        return report

    def verify_migration(self):
        """é©—è­‰é·ç§»å®Œæ•´æ€§"""
        print("\nâœ… Verifying migration...")

        # æª¢æŸ¥èˆŠç›®éŒ„æ˜¯å¦é‚„å­˜åœ¨
        remaining = []
        for target_dir, sources in CONSOLIDATION_MAP.items():
            for source_name in sources.keys():
                source_path = self.root / source_name
                if source_path.exists():
                    remaining.append(source_name)

        if remaining:
            print(f"   âš  Warning: {len(remaining)} old directories still exist:")
            for name in remaining[:5]:
                print(f"     - {name}")
            if len(remaining) > 5:
                print(f"     ... and {len(remaining) - 5} more")
        else:
            print("   âœ“ All old directories removed")

        # æª¢æŸ¥æ–°ç›®éŒ„
        created = 0
        for target_dir in CONSOLIDATION_MAP.keys():
            target_path = self.root / target_dir
            if target_path.exists():
                created += 1

        print(f"   âœ“ {created}/{len(CONSOLIDATION_MAP)} new directories verified")

    def run(self):
        """åŸ·è¡Œå®Œæ•´çš„æ•´åˆæµç¨‹"""
        print("=" * 60)
        print("ğŸš€ GL Platform Consolidation Tool")
        print("=" * 60)
        print(
            f"Mode: {'DRY RUN (no changes)' if self.dry_run else 'LIVE (will make changes)'}"
        )
        print(f"Workspace: {self.root}")
        print()

        try:
            # Phase 1: å‚™ä»½
            self.backup_current_state()

            # Phase 2: å‰µå»ºçµæ§‹
            self.create_new_structure()

            # Phase 3: é·ç§»
            self.migrate_platforms()

            # Phase 4: é©—è­‰
            if not self.dry_run:
                self.verify_migration()

            # Phase 5: å ±å‘Š
            report = self.generate_report()

            print("\n" + "=" * 60)
            print("âœ¨ Consolidation Complete!")
            print("=" * 60)
            print(f"Moved directories: {report['moved_directories']}")
            print(f"Errors: {len(report['errors'])}")
            print(f"Status: {report['status']}")

            if self.dry_run:
                print("\nâš ï¸  This was a DRY RUN. No changes were made.")
                print("   Run with --execute to apply changes.")

            return 0

        except Exception as e:
            print(f"\nâŒ Error during consolidation: {e}")
            import traceback

            traceback.print_exc()
            return 1


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Consolidate GL platforms")
    parser.add_argument(
        "--execute",
        action="store_true",
        help="Execute the consolidation (default is dry-run)",
    )
    parser.add_argument(
        "--skip-backup",
        action="store_true",
        help="Skip creating git backup/tag before executing",
    )
    parser.add_argument(
        "--workspace",
        default="/workspace",
        help="Workspace root directory",
    )

    args = parser.parse_args()

    consolidator = PlatformConsolidator(
        workspace_root=Path(args.workspace),
        dry_run=not args.execute,
        skip_backup=args.skip_backup,
    )

    return consolidator.run()


if __name__ == "__main__":
    import sys

    sys.exit(main())
