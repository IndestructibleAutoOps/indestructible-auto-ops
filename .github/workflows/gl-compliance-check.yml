# =============================================================================
# GL Compliance Check Workflow
# Comprehensive governance compliance validation
# =============================================================================
name: GL Compliance Check
permissions:
  contents: read

on:
  push:
    branches:
      - main
    paths:
      - 'workspace/governance/**'
      - '.github/workflows/gl-compliance-check.yml'
  pull_request:
    branches:
      - main
    paths:
      - 'workspace/governance/**'
  schedule:
    # Run daily at 00:00 UTC
    - cron: '0 0 * * *'
  workflow_dispatch:
    inputs:
      full_audit:
        description: 'Run full compliance audit'
        required: false
        default: false
        type: boolean
      generate_report:
        description: 'Generate detailed compliance report'
        required: false
        default: true
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  COMPLIANCE_REPORT_PATH: 'reports/compliance'
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ==========================================================================
  # Job 1: Policy Compliance Check
  # ==========================================================================
  policy-compliance:
    name: Policy Compliance Check
    runs-on: ubuntu-latest
    outputs:
      compliance_score: ${{ steps.check.outputs.score }}
      violations_count: ${{ steps.check.outputs.violations }}
      
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v6
        with:
          fetch-depth: 0
          
      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install Dependencies
        run: |
          pip install pyyaml
          
      - name: Create Policy Compliance Checker
        run: |
          mkdir -p scripts/gl-engine
          cat > scripts/gl-engine/policy_compliance.py << 'EOF'
          #!/usr/bin/env python3
          """GL Policy Compliance Checker"""
          
          import os
          import sys
          import yaml
          import json
          from pathlib import Path
          from datetime import datetime, timedelta
          from typing import Dict, List, Any, Tuple
          
          class PolicyComplianceChecker:
              """Checks governance artifacts against policy requirements."""
              
              # Policy rules by layer
              POLICY_RULES = {
                  'GL00-09': {
                      'required_reviews': True,
                      'max_age_days': 365,
                      'required_approvals': 2,
                      'required_fields': ['vision', 'mission', 'values'],
                  },
                  'GL10-29': {
                      'required_reviews': True,
                      'max_age_days': 90,
                      'required_approvals': 1,
                      'required_fields': ['objectives', 'resources', 'timeline'],
                  },
                  'GL30-49': {
                      'required_reviews': False,
                      'max_age_days': 30,
                      'required_approvals': 1,
                      'required_fields': ['deliverables', 'timeline'],
                  },
                  'GL50-59': {
                      'required_reviews': True,
                      'max_age_days': 180,
                      'required_approvals': 1,
                      'required_fields': ['metrics', 'thresholds'],
                  },
                  'GL60-80': {
                      'required_reviews': False,
                      'max_age_days': 90,
                      'required_approvals': 1,
                      'required_fields': [],
                  },
                  'GL81-83': {
                      'required_reviews': False,
                      'max_age_days': 180,
                      'required_approvals': 0,
                      'required_fields': [],
                  },
                  'GL90-99': {
                      'required_reviews': True,
                      'max_age_days': 365,
                      'required_approvals': 2,
                      'required_fields': ['specification', 'governance'],
                  },
              }
              
              def __init__(self):
                  self.violations: List[Dict[str, Any]] = []
                  self.warnings: List[Dict[str, Any]] = []
                  self.compliant_count = 0
                  self.total_count = 0
                  
              def check_artifact(self, artifact: Dict, file_path: str) -> Tuple[bool, List[Dict]]:
                  """Check a single artifact for policy compliance."""
                  violations = []
                  
                  metadata = artifact.get('metadata', {})
                  spec = artifact.get('spec', {})
                  status = artifact.get('status', {})
                  layer = metadata.get('layer', '')
                  
                  if layer not in self.POLICY_RULES:
                      return True, []
                      
                  rules = self.POLICY_RULES[layer]
                  
                  # Check 1: Age compliance
                  created_at = metadata.get('created_at', '')
                  updated_at = metadata.get('updated_at', created_at)
                  
                  if updated_at:
                      try:
                          update_date = datetime.fromisoformat(updated_at.replace('Z', '+00:00'))
                          age_days = (datetime.now(update_date.tzinfo) - update_date).days
                          
                          if age_days > rules['max_age_days']:
                              violations.append({
                                  'rule': 'max_age',
                                  'severity': 'warning',
                                  'message': f"Artifact is {age_days} days old, exceeds {rules['max_age_days']} day limit",
                                  'file': file_path
                              })
                      except Exception:
                          pass
                          
                  # Check 2: Required fields in spec
                  for field in rules['required_fields']:
                      if field not in spec:
                          # Check nested fields
                          found = False
                          for key, value in spec.items():
                              if isinstance(value, dict) and field in value:
                                  found = True
                                  break
                          if not found:
                              violations.append({
                                  'rule': 'required_field',
                                  'severity': 'error',
                                  'message': f"Missing required field: {field}",
                                  'file': file_path
                              })
                              
                  # Check 3: Owner assignment
                  if not metadata.get('owner'):
                      violations.append({
                          'rule': 'owner_required',
                          'severity': 'error',
                          'message': "Artifact must have an owner",
                          'file': file_path
                      })
                      
                  # Check 4: Version format
                  version = metadata.get('version', '')
                  if version and not self._is_valid_semver(version):
                      violations.append({
                          'rule': 'version_format',
                          'severity': 'warning',
                          'message': f"Version '{version}' is not valid semver format",
                          'file': file_path
                      })
                      
                  # Check 5: Status phase
                  phase = status.get('phase', '')
                  valid_phases = ['draft', 'review', 'approved', 'active', 'deprecated', 'archived']
                  if phase and phase not in valid_phases:
                      violations.append({
                          'rule': 'status_phase',
                          'severity': 'warning',
                          'message': f"Invalid status phase: {phase}",
                          'file': file_path
                      })
                      
                  return len([v for v in violations if v['severity'] == 'error']) == 0, violations
                  
              def _is_valid_semver(self, version: str) -> bool:
                  """Check if version follows semver format."""
                  import re
                  pattern = r'^(\d+)\.(\d+)\.(\d+)(-[a-zA-Z0-9]+)?(\+[a-zA-Z0-9]+)?$'
                  return bool(re.match(pattern, version))
                  
              def check_directory(self, directory: Path) -> Dict[str, Any]:
                  """Check all artifacts in a directory."""
                  results = {
                      'total': 0,
                      'compliant': 0,
                      'non_compliant': 0,
                      'violations': [],
                      'warnings': [],
                      'by_layer': {},
                      'by_severity': {'error': 0, 'warning': 0}
                  }
                  
                  yaml_files = list(directory.rglob('*.yaml')) + list(directory.rglob('*.yml'))
                  
                  for file_path in yaml_files:
                      try:
                          with open(file_path, 'r', encoding='utf-8') as f:
                              content = yaml.safe_load(f)
                              
                          if content is None or 'apiVersion' not in content:
                              continue
                              
                          results['total'] += 1
                          
                          compliant, violations = self.check_artifact(content, str(file_path))
                          
                          layer = content.get('metadata', {}).get('layer', 'unknown')
                          if layer not in results['by_layer']:
                              results['by_layer'][layer] = {'total': 0, 'compliant': 0, 'violations': 0}
                          results['by_layer'][layer]['total'] += 1
                          
                          if compliant:
                              results['compliant'] += 1
                              results['by_layer'][layer]['compliant'] += 1
                          else:
                              results['non_compliant'] += 1
                              results['by_layer'][layer]['violations'] += 1
                              
                          for v in violations:
                              if v['severity'] == 'error':
                                  results['violations'].append(v)
                                  results['by_severity']['error'] += 1
                              else:
                                  results['warnings'].append(v)
                                  results['by_severity']['warning'] += 1
                                  
                      except Exception as e:
                          results['warnings'].append({
                              'rule': 'parse_error',
                              'severity': 'warning',
                              'message': str(e),
                              'file': str(file_path)
                          })
                          
                  # Calculate compliance score
                  if results['total'] > 0:
                      results['compliance_score'] = (results['compliant'] / results['total']) * 100
                  else:
                      results['compliance_score'] = 100
                      
                  return results
                  
              def generate_report(self, results: Dict[str, Any]) -> str:
                  """Generate compliance report."""
                  report = []
                  report.append("# GL Compliance Report\n")
                  report.append(f"**Generated**: {datetime.utcnow().isoformat()}Z\n")
                  
                  # Summary
                  report.append("## Summary\n")
                  report.append(f"| Metric | Value |")
                  report.append(f"|--------|-------|")
                  report.append(f"| Total Artifacts | {results['total']} |")
                  report.append(f"| Compliant | {results['compliant']} |")
                  report.append(f"| Non-Compliant | {results['non_compliant']} |")
                  report.append(f"| Compliance Score | {results['compliance_score']:.1f}% |")
                  report.append(f"| Errors | {results['by_severity']['error']} |")
                  report.append(f"| Warnings | {results['by_severity']['warning']} |")
                  report.append("")
                  
                  # By Layer
                  report.append("## Compliance by Layer\n")
                  report.append("| Layer | Total | Compliant | Violations |")
                  report.append("|-------|-------|-----------|------------|")
                  for layer, data in sorted(results['by_layer'].items()):
                      status = "âœ…" if data['violations'] == 0 else "âŒ"
                      report.append(f"| {layer} {status} | {data['total']} | {data['compliant']} | {data['violations']} |")
                  report.append("")
                  
                  # Violations
                  if results['violations']:
                      report.append("## Violations (Errors)\n")
                      for v in results['violations']:
                          report.append(f"- **{v['file']}**")
                          report.append(f"  - Rule: `{v['rule']}`")
                          report.append(f"  - Message: {v['message']}")
                      report.append("")
                      
                  # Warnings
                  if results['warnings']:
                      report.append("## Warnings\n")
                      for w in results['warnings'][:20]:  # Limit to 20 warnings
                          report.append(f"- **{w['file']}**: {w['message']}")
                      if len(results['warnings']) > 20:
                          report.append(f"\n*... and {len(results['warnings']) - 20} more warnings*")
                      report.append("")
                      
                  # Recommendations
                  report.append("## Recommendations\n")
                  if results['by_severity']['error'] > 0:
                      report.append("1. âš ï¸ Address all error-level violations before merging")
                  if results['by_severity']['warning'] > 5:
                      report.append("2. ðŸ“‹ Review and address warnings to improve compliance score")
                  if results['compliance_score'] < 80:
                      report.append("3. ðŸŽ¯ Target 80%+ compliance score for production readiness")
                  if results['compliance_score'] >= 95:
                      report.append("âœ… Excellent compliance! Keep up the good work.")
                      
                  return '\n'.join(report)
          
          def main():
              checker = PolicyComplianceChecker()
              results = checker.check_directory(Path('workspace/governance'))
              
              report = checker.generate_report(results)
              
              os.makedirs('reports/compliance', exist_ok=True)
              with open('reports/compliance/policy-compliance.md', 'w') as f:
                  f.write(report)
                  
              # Output for GitHub Actions
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f"score={results['compliance_score']:.1f}\n")
                  f.write(f"violations={results['by_severity']['error']}\n")
              
              print(report)
              
              # Fail if there are errors
              sys.exit(0 if results['by_severity']['error'] == 0 else 1)
              
          if __name__ == '__main__':
              main()
          EOF
          
      - name: Run Policy Compliance Check
        id: check
        run: |
          python scripts/gl-engine/policy_compliance.py
          
      - name: Upload Compliance Report
        uses: actions/upload-artifact@v4
        with:
          name: policy-compliance-report
          path: reports/compliance/policy-compliance.md
          retention-days: 90

  # ==========================================================================
  # Job 2: Security Compliance Check
  # ==========================================================================
  security-compliance:
    name: Security Compliance Check
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v6
        
      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install Dependencies
        run: |
          pip install pyyaml
          
      - name: Create Security Checker
        run: |
          mkdir -p scripts/gl-engine
          cat > scripts/gl-engine/security_compliance.py << 'EOF'
          #!/usr/bin/env python3
          """GL Security Compliance Checker"""
          
          import os
          import sys
          import yaml
          import re
          from pathlib import Path
          from typing import Dict, List, Any
          
          class SecurityComplianceChecker:
              """Checks governance artifacts for security compliance."""
              
              # Patterns that might indicate sensitive data
              SENSITIVE_PATTERNS = [
                  (r'password\s*[:=]\s*["\']?[^"\'\s]+', 'Potential password exposure'),
                  (r'api[_-]?key\s*[:=]\s*["\']?[a-zA-Z0-9]{20,}', 'Potential API key exposure'),
                  (r'secret\s*[:=]\s*["\']?[^"\'\s]+', 'Potential secret exposure'),
                  (r'token\s*[:=]\s*["\']?[a-zA-Z0-9]{20,}', 'Potential token exposure'),
                  (r'private[_-]?key', 'Potential private key reference'),
                  (r'-----BEGIN\s+(RSA\s+)?PRIVATE\s+KEY-----', 'Private key detected'),
                  (r'aws[_-]?access[_-]?key[_-]?id', 'AWS access key reference'),
                  (r'aws[_-]?secret[_-]?access[_-]?key', 'AWS secret key reference'),
              ]
              
              # Required security fields for certain artifact types
              SECURITY_REQUIREMENTS = {
                  'GovernanceCharter': ['accountability', 'audit_requirements'],
                  'OperationalPlan': ['risks'],
                  'DeploymentRecord': ['verification'],
                  'AlertRules': ['notification'],
              }
              
              def __init__(self):
                  self.findings: List[Dict[str, Any]] = []
                  
              def check_file(self, file_path: Path) -> List[Dict[str, Any]]:
                  """Check a single file for security issues."""
                  findings = []
                  
                  try:
                      content = file_path.read_text(encoding='utf-8')
                      
                      # Check for sensitive patterns
                      for pattern, description in self.SENSITIVE_PATTERNS:
                          matches = re.finditer(pattern, content, re.IGNORECASE)
                          for match in matches:
                              # Get line number
                              line_num = content[:match.start()].count('\n') + 1
                              findings.append({
                                  'type': 'sensitive_data',
                                  'severity': 'critical',
                                  'file': str(file_path),
                                  'line': line_num,
                                  'description': description,
                                  'match': match.group()[:50] + '...' if len(match.group()) > 50 else match.group()
                              })
                              
                      # Parse YAML and check structure
                      try:
                          artifact = yaml.safe_load(content)
                          if artifact and isinstance(artifact, dict):
                              kind = artifact.get('kind', '')
                              
                              # Check for required security fields
                              if kind in self.SECURITY_REQUIREMENTS:
                                  spec = artifact.get('spec', {})
                                  for field in self.SECURITY_REQUIREMENTS[kind]:
                                      if field not in spec and field not in artifact:
                                          findings.append({
                                              'type': 'missing_security_field',
                                              'severity': 'warning',
                                              'file': str(file_path),
                                              'description': f"Missing recommended security field: {field}",
                                              'kind': kind
                                          })
                      except yaml.YAMLError:
                          pass
                          
                  except Exception as e:
                      findings.append({
                          'type': 'scan_error',
                          'severity': 'info',
                          'file': str(file_path),
                          'description': str(e)
                      })
                      
                  return findings
                  
              def check_directory(self, directory: Path) -> Dict[str, Any]:
                  """Check all files in a directory."""
                  results = {
                      'total_files': 0,
                      'files_with_issues': 0,
                      'findings': [],
                      'by_severity': {'critical': 0, 'high': 0, 'warning': 0, 'info': 0}
                  }
                  
                  for file_path in directory.rglob('*'):
                      if file_path.is_file() and file_path.suffix in ['.yaml', '.yml', '.md', '.txt']:
                          results['total_files'] += 1
                          findings = self.check_file(file_path)
                          
                          if findings:
                              results['files_with_issues'] += 1
                              results['findings'].extend(findings)
                              
                              for f in findings:
                                  severity = f.get('severity', 'info')
                                  if severity in results['by_severity']:
                                      results['by_severity'][severity] += 1
                                      
                  return results
                  
              def generate_report(self, results: Dict[str, Any]) -> str:
                  """Generate security compliance report."""
                  report = []
                  report.append("# GL Security Compliance Report\n")
                  
                  # Summary
                  report.append("## Summary\n")
                  report.append(f"| Metric | Value |")
                  report.append(f"|--------|-------|")
                  report.append(f"| Total Files Scanned | {results['total_files']} |")
                  report.append(f"| Files with Issues | {results['files_with_issues']} |")
                  report.append(f"| Critical Findings | {results['by_severity']['critical']} |")
                  report.append(f"| High Findings | {results['by_severity']['high']} |")
                  report.append(f"| Warnings | {results['by_severity']['warning']} |")
                  report.append("")
                  
                  # Critical findings
                  critical = [f for f in results['findings'] if f['severity'] == 'critical']
                  if critical:
                      report.append("## ðŸš¨ Critical Findings\n")
                      for f in critical:
                          report.append(f"### {f['file']}")
                          report.append(f"- **Type**: {f['type']}")
                          report.append(f"- **Description**: {f['description']}")
                          if 'line' in f:
                              report.append(f"- **Line**: {f['line']}")
                          report.append("")
                          
                  # Warnings
                  warnings = [f for f in results['findings'] if f['severity'] == 'warning']
                  if warnings:
                      report.append("## âš ï¸ Warnings\n")
                      for f in warnings[:10]:
                          report.append(f"- **{f['file']}**: {f['description']}")
                      if len(warnings) > 10:
                          report.append(f"\n*... and {len(warnings) - 10} more warnings*")
                      report.append("")
                      
                  # Status
                  if results['by_severity']['critical'] == 0:
                      report.append("## âœ… Security Status: PASS\n")
                      report.append("No critical security issues found.")
                  else:
                      report.append("## âŒ Security Status: FAIL\n")
                      report.append("Critical security issues must be addressed before merge.")
                      
                  return '\n'.join(report)
          
          def main():
              checker = SecurityComplianceChecker()
              results = checker.check_directory(Path('workspace/governance'))
              
              report = checker.generate_report(results)
              
              os.makedirs('reports/compliance', exist_ok=True)
              with open('reports/compliance/security-compliance.md', 'w') as f:
                  f.write(report)
                  
              print(report)
              
              # Fail on critical findings
              sys.exit(0 if results['by_severity']['critical'] == 0 else 1)
              
          if __name__ == '__main__':
              main()
          EOF
          
      - name: Run Security Compliance Check
        run: |
          python scripts/gl-engine/security_compliance.py
          
      - name: Upload Security Report
        uses: actions/upload-artifact@v4
        with:
          name: security-compliance-report
          path: reports/compliance/security-compliance.md
          retention-days: 90

  # ==========================================================================
  # Job 3: Cross-Layer Consistency Check
  # ==========================================================================
  consistency-check:
    name: Cross-Layer Consistency Check
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v6
        
      - name: Setup Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install Dependencies
        run: |
          pip install pyyaml
          
      - name: Create Consistency Checker
        run: |
          mkdir -p scripts/gl-engine
          cat > scripts/gl-engine/consistency_checker.py << 'EOF'
          #!/usr/bin/env python3
          """GL Cross-Layer Consistency Checker"""
          
          import os
          import sys
          import yaml
          from pathlib import Path
          from typing import Dict, List, Set, Any
          from collections import defaultdict
          
          class ConsistencyChecker:
              """Checks consistency across GL layers."""
              
              def __init__(self):
                  self.artifacts: Dict[str, List[Dict]] = defaultdict(list)
                  self.references: Dict[str, Set[str]] = defaultdict(set)
                  self.inconsistencies: List[Dict[str, Any]] = []
                  
              def load_artifacts(self, directory: Path):
                  """Load all artifacts from directory."""
                  yaml_files = list(directory.rglob('*.yaml')) + list(directory.rglob('*.yml'))
                  
                  for file_path in yaml_files:
                      try:
                          with open(file_path, 'r', encoding='utf-8') as f:
                              content = yaml.safe_load(f)
                              
                          if content and isinstance(content, dict) and 'apiVersion' in content:
                              layer = content.get('metadata', {}).get('layer', 'unknown')
                              content['_file_path'] = str(file_path)
                              self.artifacts[layer].append(content)
                              
                              # Extract references
                              self._extract_references(content, str(file_path))
                              
                      except Exception:
                          pass
                          
              def _extract_references(self, obj: Any, file_path: str, path: str = ''):
                  """Extract references to other artifacts."""
                  if isinstance(obj, dict):
                      for key, value in obj.items():
                          new_path = f"{path}.{key}" if path else key
                          
                          # Look for reference patterns
                          if key in ['objective_id', 'initiative_id', 'artifact_ref', 'depends_on']:
                              if isinstance(value, str):
                                  self.references[file_path].add(value)
                              elif isinstance(value, list):
                                  for v in value:
                                      if isinstance(v, str):
                                          self.references[file_path].add(v)
                                          
                          self._extract_references(value, file_path, new_path)
                          
                  elif isinstance(obj, list):
                      for i, item in enumerate(obj):
                          self._extract_references(item, file_path, f"{path}[{i}]")
                          
              def check_consistency(self) -> Dict[str, Any]:
                  """Check consistency across layers."""
                  results = {
                      'total_artifacts': sum(len(a) for a in self.artifacts.values()),
                      'layers_found': list(self.artifacts.keys()),
                      'inconsistencies': [],
                      'warnings': []
                  }
                  
                  # Check 1: Strategic objectives should be referenced by operational plans
                  strategic_objectives = set()
                  for artifact in self.artifacts.get('GL00-09', []):
                      if artifact.get('kind') == 'StrategicObjectives':
                          for obj in artifact.get('spec', {}).get('objectives', []):
                              if 'id' in obj:
                                  strategic_objectives.add(obj['id'])
                                  
                  referenced_objectives = set()
                  for artifact in self.artifacts.get('GL10-29', []):
                      alignment = artifact.get('spec', {}).get('alignment', {})
                      for ref in alignment.get('strategic_objectives', []):
                          if isinstance(ref, dict) and 'objective_id' in ref:
                              referenced_objectives.add(ref['objective_id'])
                          elif isinstance(ref, str):
                              referenced_objectives.add(ref)
                              
                  unreferenced = strategic_objectives - referenced_objectives
                  if unreferenced:
                      results['warnings'].append({
                          'type': 'unreferenced_objectives',
                          'message': f"Strategic objectives not referenced in operational plans: {unreferenced}",
                          'severity': 'warning'
                      })
                      
                  # Check 2: Naming consistency
                  all_names = defaultdict(list)
                  for layer, artifacts in self.artifacts.items():
                      for artifact in artifacts:
                          name = artifact.get('metadata', {}).get('name', '')
                          if name:
                              all_names[name].append({
                                  'layer': layer,
                                  'file': artifact.get('_file_path', '')
                              })
                              
                  for name, occurrences in all_names.items():
                      if len(occurrences) > 1:
                          # Check if same name in different layers (might be intentional)
                          layers = set(o['layer'] for o in occurrences)
                          if len(layers) == 1:
                              results['inconsistencies'].append({
                                  'type': 'duplicate_name',
                                  'message': f"Duplicate artifact name '{name}' in layer {list(layers)[0]}",
                                  'files': [o['file'] for o in occurrences],
                                  'severity': 'warning'
                              })
                              
                  # Check 3: Version consistency
                  api_versions = set()
                  for layer, artifacts in self.artifacts.items():
                      for artifact in artifacts:
                          api_version = artifact.get('apiVersion', '')
                          if api_version:
                              api_versions.add(api_version)
                              
                  if len(api_versions) > 1:
                      results['warnings'].append({
                          'type': 'api_version_mismatch',
                          'message': f"Multiple API versions in use: {api_versions}",
                          'severity': 'info'
                      })
                      
                  return results
                  
              def generate_report(self, results: Dict[str, Any]) -> str:
                  """Generate consistency report."""
                  report = []
                  report.append("# GL Cross-Layer Consistency Report\n")
                  
                  # Summary
                  report.append("## Summary\n")
                  report.append(f"- Total Artifacts: {results['total_artifacts']}")
                  report.append(f"- Layers Found: {', '.join(results['layers_found'])}")
                  report.append(f"- Inconsistencies: {len(results['inconsistencies'])}")
                  report.append(f"- Warnings: {len(results['warnings'])}")
                  report.append("")
                  
                  # Inconsistencies
                  if results['inconsistencies']:
                      report.append("## Inconsistencies\n")
                      for inc in results['inconsistencies']:
                          report.append(f"### {inc['type']}")
                          report.append(f"- **Message**: {inc['message']}")
                          if 'files' in inc:
                              report.append(f"- **Files**: {', '.join(inc['files'])}")
                          report.append("")
                          
                  # Warnings
                  if results['warnings']:
                      report.append("## Warnings\n")
                      for w in results['warnings']:
                          report.append(f"- **{w['type']}**: {w['message']}")
                      report.append("")
                      
                  # Status
                  if not results['inconsistencies']:
                      report.append("## âœ… Consistency Status: PASS\n")
                  else:
                      report.append("## âš ï¸ Consistency Status: REVIEW NEEDED\n")
                      
                  return '\n'.join(report)
          
          def main():
              checker = ConsistencyChecker()
              checker.load_artifacts(Path('workspace/governance'))
              results = checker.check_consistency()
              
              report = checker.generate_report(results)
              
              os.makedirs('reports/compliance', exist_ok=True)
              with open('reports/compliance/consistency-report.md', 'w') as f:
                  f.write(report)
                  
              print(report)
              
          if __name__ == '__main__':
              main()
          EOF
          
      - name: Run Consistency Check
        run: |
          python scripts/gl-engine/consistency_checker.py
          
      - name: Upload Consistency Report
        uses: actions/upload-artifact@v4
        with:
          name: consistency-report
          path: reports/compliance/consistency-report.md
          retention-days: 90

  # ==========================================================================
  # Job 4: Generate Compliance Dashboard
  # ==========================================================================
  compliance-dashboard:
    name: Generate Compliance Dashboard
    runs-on: ubuntu-latest
    needs: [policy-compliance, security-compliance, consistency-check]
    if: always()
    permissions:
      contents: read
      pull-requests: write
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v6
        
      - name: Download All Reports
        uses: actions/download-artifact@v4
        with:
          path: downloaded-reports
          
      - name: Generate Dashboard
        run: |
          mkdir -p reports/compliance
          
          cat > reports/compliance/dashboard.md << 'EOF'
          # GL Compliance Dashboard
          
          ## Overview
          
          | Check | Status | Details |
          |-------|--------|---------|
          | Policy Compliance | ${{ needs.policy-compliance.result }} | Score: ${{ needs.policy-compliance.outputs.compliance_score }}% |
          | Security Compliance | ${{ needs.security-compliance.result }} | - |
          | Consistency Check | ${{ needs.consistency-check.result }} | - |
          
          ## Workflow Information
          
          - **Run ID**: ${{ github.run_id }}
          - **Triggered by**: ${{ github.event_name }}
          - **Branch**: ${{ github.ref_name }}
          - **Commit**: ${{ github.sha }}
          
          ## Reports
          
          - [Policy Compliance Report](./policy-compliance.md)
          - [Security Compliance Report](./security-compliance.md)
          - [Consistency Report](./consistency-report.md)
          
          ## Next Steps
          
          1. Review any failed checks
          2. Address critical and high-severity findings
          3. Re-run compliance workflow
          4. Merge when all checks pass
          
          ---
          *Generated by GL Compliance Check Workflow*
          EOF
          
      - name: Upload Dashboard
        uses: actions/upload-artifact@v4
        with:
          name: compliance-dashboard
          path: reports/compliance/dashboard.md
          retention-days: 90
          
      - name: Post to PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            
            let body = `## GL Compliance Check Results\n\n`;
            body += `| Check | Status |\n`;
            body += `|-------|--------|\n`;
            body += `| Policy Compliance | ${{ needs.policy-compliance.result }} |\n`;
            body += `| Security Compliance | ${{ needs.security-compliance.result }} |\n`;
            body += `| Consistency Check | ${{ needs.consistency-check.result }} |\n`;
            body += `\n`;
            body += `**Compliance Score**: ${{ needs.policy-compliance.outputs.compliance_score }}%\n`;
            body += `**Violations**: ${{ needs.policy-compliance.outputs.violations }}\n`;
            body += `\n---\n*View detailed reports in workflow artifacts*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });