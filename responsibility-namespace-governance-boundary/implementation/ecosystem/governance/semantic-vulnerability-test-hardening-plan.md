# Era-1 Semantic Vulnerability Test Hardening Plan v1.0

## Executive Summary

This document defines a comprehensive test hardening plan to detect and prevent semantic vulnerabilities in Era-1. The plan implements global best practices from formal verification, proof-carrying code, blockchain evidence management, and semantic integrity verification research (2024-2025).

## Core Philosophy

> **"Era-1 測試不是為了「全部通過」，而是為了「逼出語義錯誤、破壞 hash、破壞 pipeline、破壞補件」，讓系統變得不可欺騙、不可漂移、不可敘事化。"**

Semantic vulnerabilities are the most critical security class in Era-1 because:
- They can bypass cryptographic protections
- They can create false semantic declarations
- They can manipulate narrative without changing hashes
- They can undermine the entire governance foundation

---

## 1. Test Hardening Architecture

### 1.1 Five-Layer Defense Model

```
┌─────────────────────────────────────────────────────────────┐
│ Layer 5: Pipeline Integrity Tests                            │
│   - Pipeline interruption tests                              │
│   - Replay verification                                      │
│   - Deterministic execution                                  │
└─────────────────────────────────────────────────────────────┘
                    ↑
┌─────────────────────────────────────────────────────────────┐
│ Layer 4: Semantic Consistency Tests                          │
│   - Semantic declaration ↔ Entity binding                   │
│   - Entity ↔ Complement mapping                              │
│   - Complement ↔ Hash validation                             │
└─────────────────────────────────────────────────────────────┘
                    ↑
┌─────────────────────────────────────────────────────────────┐
│ Layer 3: Canonicalization Tests                              │
│   - Canonicalization reverse tests                           │
│   - Layered sorting conflict tests                           │
│   - Hash reproducibility                                     │
└─────────────────────────────────────────────────────────────┘
                    ↑
┌─────────────────────────────────────────────────────────────┐
│ Layer 2: Structural Integrity Tests                          │
│   - Event stream completeness                                │
│   - Evidence chain verification                              │
│   - Registry integrity                                       │
└─────────────────────────────────────────────────────────────┘
                    ↑
┌─────────────────────────────────────────────────────────────┐
│ Layer 1: Semantic Corruption Tests                          │
│   - Fuzzy language detection                                 │
│   - Narrative wrapper detection                             │
│   - Semantic declaration mismatch                            │
└─────────────────────────────────────────────────────────────┘
```

---

## 2. Layer 1: Semantic Corruption Tests

### TC-1.1: Fuzzy Language Detection

**Objective**: Detect imprecise, non-deterministic language in reports and artifacts.

**Attack Patterns**:
- "大致完成" (approximately completed)
- "應該沒問題" (should be fine)
- "基本上" (basically)
- "差不多" (more or less)
- "估計" (estimate)
- "可能" (possibly)

**Detection Method**:
```python
FUZZY_LANGUAGE_PATTERNS = [
    r"大致|大約|差不多|基本|應該|估計|可能|或許|也許",
    r"想來說|從.*角度來看|我們認為",
    r"預期|將會|未來可能"
]

def detect_fuzzy_language(text):
    violations = []
    for pattern in FUZZY_LANGUAGE_PATTERNS:
        matches = re.findall(pattern, text, re.IGNORECASE)
        if matches:
            violations.append({
                "pattern": pattern,
                "matches": matches,
                "severity": "MEDIUM"
            })
    return violations
```

**Expected Result**: **FAIL** if fuzzy language detected in status/result declarations.

---

### TC-1.2: Narrative Wrapper Detection

**Objective**: Detect narrative wrappers that hide semantic meaning.

**Attack Patterns**:
- "我們認為這個實作完成了" (We think this implementation is completed)
- "從...角度來看" (From the perspective of...)
- "考慮到..." (Considering that...)
- "在...情況下" (In the situation that...)

**Detection Method**:
```python
NARRATIVE_WRAPPER_PATTERNS = [
    r"我們認為|我們覺得|我們相信",
    r"從.*角度來看|從.*視角出發",
    r"根據.*判斷|基於.*考量"
]

def detect_narrative_wrappers(text):
    violations = []
    for pattern in NARRATIVE_WRAPPER_PATTERNS:
        if re.search(pattern, text, re.IGNORECASE):
            violations.append({
                "pattern": pattern,
                "context": extract_context(text, pattern),
                "severity": "HIGH"
            })
    return violations
```

**Expected Result**: **FAIL** if narrative wrappers used for status/result declarations.

---

### TC-1.3: Semantic Declaration Mismatch

**Objective**: Verify that semantic declarations have corresponding evidence.

**Detection Method**:
```python
def verify_semantic_declaration(declaration, artifacts, events):
    # Check if "status": "completed" has artifact evidence
    if declaration.get("status") == "completed":
        if not any(art["id"] == declaration["artifact_id"] for art in artifacts):
            return {
                "status": "FAIL",
                "reason": f"Semantic declaration 'completed' without corresponding artifact",
                "declaration": declaration
            }
    
    # Check if "result": "passed" has verification evidence
    if declaration.get("result") == "passed":
        if not any(event["type"] == "VERIFICATION" and 
                   event["target"] == declaration["id"] 
                   for event in events):
            return {
                "status": "FAIL",
                "reason": f"Semantic declaration 'passed' without verification event",
                "declaration": declaration
            }
    
    return {"status": "PASS"}
```

**Expected Result**: **FAIL** if semantic declaration lacks evidence.

---

## 3. Layer 2: Structural Integrity Tests

### TC-2.1: Event Stream Completeness

**Objective**: Verify event stream has all required fields.

**Required Fields**:
- `uuid` (UUID v4)
- `timestamp` (ISO8601)
- `type` (event type)
- `payload` (event data)
- `canonical_hash` (SHA256)

**Detection Method**:
```python
REQUIRED_EVENT_FIELDS = ["uuid", "timestamp", "type", "payload", "canonical_hash"]

def verify_event_stream_completeness(event_stream):
    violations = []
    for i, event in enumerate(event_stream):
        missing_fields = [f for f in REQUIRED_EVENT_FIELDS if f not in event]
        if missing_fields:
            violations.append({
                "event_index": i,
                "event_id": event.get("uuid", "UNKNOWN"),
                "missing_fields": missing_fields,
                "severity": "CRITICAL"
            })
    
    return violations
```

**Expected Result**: **FAIL** if any event missing required fields.

---

### TC-2.2: Evidence Chain Verification

**Objective**: Verify evidence chain is complete and linked.

**Detection Method**:
```python
def verify_evidence_chain(artifacts, events):
    violations = []
    
    # Verify artifact chain
    for i, artifact in enumerate(artifacts):
        if i > 0:
            if artifact.get("hash_chain", {}).get("parent") != artifacts[i-1]["sha256_hash"]:
                violations.append({
                    "type": "artifact_chain_break",
                    "artifact_id": artifact["artifact_id"],
                    "expected_parent": artifacts[i-1]["sha256_hash"],
                    "actual_parent": artifact.get("hash_chain", {}).get("parent"),
                    "severity": "CRITICAL"
                })
    
    # Verify event chain
    for i, event in enumerate(events):
        if i > 0:
            if event.get("hash_chain", {}).get("previous_event") != events[i-1]["canonical_hash"]:
                violations.append({
                    "type": "event_chain_break",
                    "event_id": event["uuid"],
                    "expected_previous": events[i-1]["canonical_hash"],
                    "actual_previous": event.get("hash_chain", {}).get("previous_event"),
                    "severity": "CRITICAL"
                })
    
    return violations
```

**Expected Result**: **FAIL** if evidence chain is broken.

---

### TC-2.3: Registry Integrity

**Objective**: Verify hash registry contains all required hashes.

**Detection Method**:
```python
def verify_registry_integrity(artifacts, events, registry):
    # Verify all artifact hashes in registry
    artifact_hashes_in_registry = set(registry.get("artifacts", {}).keys())
    expected_artifact_hashes = {art["sha256_hash"] for art in artifacts}
    
    missing_hashes = expected_artifact_hashes - artifact_hashes_in_registry
    if missing_hashes:
        return {
            "status": "FAIL",
            "reason": f"Artifact hashes missing from registry: {missing_hashes}",
            "severity": "HIGH"
        }
    
    return {"status": "PASS"}
```

**Expected Result**: **FAIL** if registry missing hashes.

---

## 4. Layer 3: Canonicalization Tests

### TC-3.1: Canonicalization Reverse Test

**Objective**: Verify hash can be reproduced by re-canonicalizing.

**Detection Method**:
```python
from rfc8785 import canonicalize

def test_canonicalization_reverse(artifact):
    try:
        # Remove canonicalization metadata
        artifact_copy = artifact.copy()
        artifact_copy.pop("canonical_hash", None)
        artifact_copy.pop("canonicalization_version", None)
        artifact_copy.pop("canonicalization_method", None)
        
        # Re-canonicalize
        canonicalized = canonicalize(artifact_copy)
        re_hash = hashlib.sha256(canonicalized.encode()).hexdigest()
        
        # Compare with original
        original_hash = artifact["canonical_hash"]
        if re_hash != original_hash:
            return {
                "status": "FAIL",
                "reason": f"Hash mismatch after re-canonicalization",
                "original_hash": original_hash,
                "re_hash": re_hash,
                "severity": "CRITICAL"
            }
        
        return {"status": "PASS"}
    except Exception as e:
        return {
            "status": "FAIL",
            "reason": f"Canonicalization failed: {str(e)}",
            "severity": "CRITICAL"
        }
```

**Expected Result**: **PASS** only if hash is reproducible.

---

### TC-3.2: Layered Sorting Conflict Test

**Objective**: Verify layered sorting protocol is consistent.

**Detection Method**:
```python
def test_layered_sorting_conflict(artifact):
    # Extract field order
    field_order = list(artifact.keys())
    
    # Define expected layers
    LAYER_1_FIELDS = ["artifact_id", "step_number", "timestamp", "era", "success"]
    LAYER_2_FIELDS = ["metadata", "execution_time_ms", "violations_count"]
    
    # Verify Layer 1 comes first
    l1_index = next((i for i, f in enumerate(field_order) if f in LAYER_1_FIELDS), None)
    l2_index = next((i for i, f in enumerate(field_order) if f in LAYER_2_FIELDS), None)
    
    if l1_index is not None and l2_index is not None:
        if l2_index < l1_index:
            return {
                "status": "FAIL",
                "reason": "Layer 2 field appears before Layer 1 field",
                "l1_index": l1_index,
                "l2_index": l2_index,
                "severity": "HIGH"
            }
    
    return {"status": "PASS"}
```

**Expected Result**: **FAIL** if layered sorting violated.

---

## 5. Layer 4: Semantic Consistency Tests

### TC-4.1: Semantic ↔ Entity Binding

**Objective**: Verify semantic declarations have corresponding entities.

**Detection Method**:
```python
def verify_semantic_entity_binding(semantic_declarations, entities):
    violations = []
    
    for decl in semantic_declarations:
        decl_id = decl.get("id")
        entity_id = decl.get("entity_id")
        
        if entity_id:
            if not any(ent["id"] == entity_id for ent in entities):
                violations.append({
                    "type": "semantic_entity_mismatch",
                    "semantic_id": decl_id,
                    "missing_entity_id": entity_id,
                    "severity": "HIGH"
                })
    
    return violations
```

**Expected Result**: **FAIL** if semantic declaration references missing entity.

---

### TC-4.2: Entity ↔ Complement Mapping

**Objective**: Verify entities have corresponding complements.

**Detection Method**:
```python
def verify_entity_complement_mapping(entities, complements):
    violations = []
    
    for entity in entities:
        entity_id = entity.get("id")
        complement_id = entity.get("complement_id")
        
        if complement_id:
            if not any(comp["id"] == complement_id for comp in complements):
                violations.append({
                    "type": "entity_complement_mismatch",
                    "entity_id": entity_id,
                    "missing_complement_id": complement_id,
                    "severity": "HIGH"
                })
    
    return violations
```

**Expected Result**: **FAIL** if entity references missing complement.

---

### TC-4.3: Complement ↔ Hash Validation

**Objective**: Verify complements have valid hashes.

**Detection Method**:
```python
def verify_complement_hash_validation(complements):
    violations = []
    
    for comp in complements:
        comp_id = comp.get("id")
        canonical_hash = comp.get("canonical_hash")
        
        if not canonical_hash:
            violations.append({
                "type": "complement_missing_hash",
                "complement_id": comp_id,
                "severity": "CRITICAL"
            })
        else:
            # Verify hash format (64 hex characters)
            if not re.match(r'^[0-9a-f]{64}$', canonical_hash):
                violations.append({
                    "type": "complement_invalid_hash",
                    "complement_id": comp_id,
                    "invalid_hash": canonical_hash,
                    "severity": "HIGH"
                })
    
    return violations
```

**Expected Result**: **FAIL** if complement missing or has invalid hash.

---

## 6. Layer 5: Pipeline Integrity Tests

### TC-5.1: Pipeline Replay Test

**Objective**: Verify pipeline can be replayed to produce same results.

**Detection Method**:
```python
def test_pipeline_replay(original_artifacts):
    # Re-run pipeline
    new_artifacts = run_pipeline()
    
    # Compare results
    if len(original_artifacts) != len(new_artifacts):
        return {
            "status": "FAIL",
            "reason": f"Pipeline produced different number of artifacts",
            "original_count": len(original_artifacts),
            "new_count": len(new_artifacts),
            "severity": "CRITICAL"
        }
    
    for orig, new in zip(original_artifacts, new_artifacts):
        if orig["sha256_hash"] != new["sha256_hash"]:
            return {
                "status": "FAIL",
                "reason": f"Artifact hash mismatch on replay",
                "artifact_id": orig["artifact_id"],
                "original_hash": orig["sha256_hash"],
                "replay_hash": new["sha256_hash"],
                "severity": "CRITICAL"
            }
    
    return {"status": "PASS"}
```

**Expected Result**: **PASS** only if replay produces identical results.

---

### TC-5.2: Deterministic Execution Test

**Objective**: Verify pipeline execution is deterministic across different environments.

**Detection Method**:
```python
def test_deterministic_execution():
    # Execute pipeline in different environments
    results = []
    for env in ["linux", "windows", "macos"]:
        result = execute_pipeline_in_environment(env)
        results.append(result)
    
    # Compare hashes
    hash_sets = [set(art["sha256_hash"] for art in r) for r in results]
    
    if not all(hs == hash_sets[0] for hs in hash_sets):
        return {
            "status": "FAIL",
            "reason": f"Pipeline not deterministic across environments",
            "hash_sets": hash_sets,
            "severity": "CRITICAL"
        }
    
    return {"status": "PASS"}
```

**Expected Result**: **PASS** only if deterministic across environments.

---

### TC-5.3: Pipeline Interruption Test

**Objective**: Verify pipeline handles interruptions gracefully.

**Detection Method**:
```python
def test_pipeline_interruption():
    # Start pipeline
    pipeline = start_pipeline()
    
    # Interrupt at step 5
    interrupt_pipeline(pipeline, step=5)
    
    # Verify cleanup
    state = get_pipeline_state(pipeline)
    
    if not state.get("cleaned_up"):
        return {
            "status": "FAIL",
            "reason": "Pipeline did not clean up after interruption",
            "severity": "HIGH"
        }
    
    if not state.get("rollback_complete"):
        return {
            "status": "FAIL",
            "reason": "Pipeline did not rollback after interruption",
            "severity": "HIGH"
        }
    
    return {"status": "PASS"}
```

**Expected Result**: **PASS** only if interruption handled gracefully.

---

## 7. Test Execution Strategy

### 7.1 Test Categories

| Category | Test Cases | Priority | Execution Frequency |
|----------|------------|----------|---------------------|
| Semantic Corruption | 3 | CRITICAL | Every run |
| Structural Integrity | 3 | CRITICAL | Every run |
| Canonicalization | 2 | HIGH | Every run |
| Semantic Consistency | 3 | HIGH | Every run |
| Pipeline Integrity | 3 | CRITICAL | Pre-sealing |

**Total**: 14 test cases

### 7.2 Test Execution Order

```python
TEST_EXECUTION_ORDER = [
    # Layer 1: Semantic Corruption (Critical)
    TC_1_1_FUZZY_LANGUAGE,
    TC_1_2_NARRATIVE_WRAPPER,
    TC_1_3_SEMANTIC_DECLARATION_MISMATCH,
    
    # Layer 2: Structural Integrity (Critical)
    TC_2_1_EVENT_STREAM_COMPLETENESS,
    TC_2_2_EVIDENCE_CHAIN_VERIFICATION,
    TC_2_3_REGISTRY_INTEGRITY,
    
    # Layer 3: Canonicalization (High)
    TC_3_1_CANONICALIZATION_REVERSE,
    TC_3_2_LAYERED_SORTING_CONFLICT,
    
    # Layer 4: Semantic Consistency (High)
    TC_4_1_SEMANTIC_ENTITY_BINDING,
    TC_4_2_ENTITY_COMPLEMENT_MAPPING,
    TC_4_3_COMPLEMENT_HASH_VALIDATION,
    
    # Layer 5: Pipeline Integrity (Critical)
    TC_5_1_PIPELINE_REPLAY,
    TC_5_2_DETERMINISTIC_EXECUTION,
    TC_5_3_PIPELINE_INTERRUPTION
]
```

### 7.3 Test Hardening Criteria

**PASS Criteria**:
- All CRITICAL tests: 100% pass rate
- All HIGH tests: ≥95% pass rate
- All MEDIUM tests: ≥90% pass rate
- Overall: ≥97% pass rate

**FAIL Criteria**:
- Any CRITICAL test fails → BLOCK sealing
- >5% HIGH tests fail → BLOCK sealing
- >10% MEDIUM tests fail → WARNING

---

## 8. Integration with Era-1

### 8.1 Pre-Sealing Gate

```yaml
pre_sealing_gate:
  tests:
    - name: semantic_corruption_tests
      required: true
      threshold: 100%
    
    - name: structural_integrity_tests
      required: true
      threshold: 100%
    
    - name: canonicalization_tests
      required: true
      threshold: 95%
    
    - name: semantic_consistency_tests
      required: true
      threshold: 95%
    
    - name: pipeline_integrity_tests
      required: true
      threshold: 100%
  
  overall_threshold: 97%
  failure_action: BLOCK_SEALING
```

### 8.2 CI/CD Integration

```yaml
test_hardening_step:
  stage: test_hardening
  script:
    - python ecosystem/tools/semantic_hardening_runner.py --all-tests
    - python ecosystem/tools/semantic_hardening_runner.py --generate-report
  artifacts:
    reports:
      - semantic_hardening_report.html
      - semantic_hardening_report.json
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: false
```

---

## 9. Reporting and Remediation

### 9.1 Report Structure

```json
{
  "test_run_id": "uuid",
  "timestamp": "ISO8601",
  "overall_score": 97.5,
  "passed": 14,
  "failed": 0,
  "skipped": 0,
  "results": [
    {
      "test_id": "TC-1.1",
      "name": "Fuzzy Language Detection",
      "status": "PASS",
      "severity": "MEDIUM",
      "duration_ms": 123
    }
  ],
  "violations": [],
  "remediation_plan": []
}
```

### 9.2 Violation Handling

**CRITICAL Violations**:
- Immediate notification
- Block all operations
- Require manual review
- Document in incident log

**HIGH Violations**:
- Immediate notification
- Block sealing operations
- Require fix within 24 hours

**MEDIUM Violations**:
- Notification
- Warning in logs
- Require fix within 1 week

---

## 10. Continuous Improvement

### 10.1 Test Case Evolution

- Monthly review of test effectiveness
- Add new test cases based on emerging attack patterns
- Refine detection patterns based on false positives
- Update thresholds based on production data

### 10.2 Metrics and KPIs

- Test execution time (target: <30s for all tests)
- False positive rate (target: <5%)
- Detection rate (target: >95%)
- Mean time to remediation (target: <24h for CRITICAL)

---

## 11. Conclusion

This test hardening plan provides comprehensive semantic vulnerability detection for Era-1. By implementing these 14 test cases across 5 layers, the system becomes:

- **Uncheatable**: All semantic declarations must have evidence
- **Undrifting**: Hash reproducibility prevents drift
- **Unnarratable**: Narrative wrappers are detected and blocked
- **Auditable**: Complete evidence chain from declaration to hash

The test hardening plan is the foundation for Era-1 sealing and Era-2 migration.

---

**Version**: 1.0  
**Last Updated**: 2026-02-04  
**Status**: READY FOR IMPLEMENTATION