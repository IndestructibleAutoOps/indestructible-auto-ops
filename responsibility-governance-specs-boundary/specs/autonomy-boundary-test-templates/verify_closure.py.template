#!/usr/bin/env python3
"""
Autonomy Boundary Test - Closure Verification Template
Test ID: {test_id}
Scenario: {scenario}
Generated: {timestamp}
Mode: CLOSURE_MODE_AUTONOMY_BOUNDARY_TEST
MNGA Version: v2.0
"""

import json
import os
import sys
import hashlib
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime

# Add validators to path
sys.path.insert(0, '/workspace/ecosystem/validators')

try:
    from governance_validator import GovernanceValidator
except ImportError:
    # Fallback if validator not available
    GovernanceValidator = None

class ClosureVerifier:
    """æ²»ç†é–‰ç’°é©—è­‰å™¨ - MNGA Compliant"""
    
    def __init__(self, test_id: str, scenario: str):
        self.test_id = test_id
        self.scenario = scenario
        self.base_path = Path(f"tests/gl/autonomy-boundary/{scenario}")
        self.violations = []
        self.warnings = []
        
        # Initialize governance validator if available
        self.governance_validator = GovernanceValidator() if GovernanceValidator else None
        
        # Paths
        self.governance_dir = Path("/workspace/ecosystem/.governance")
        self.event_stream = self.governance_dir / "event-stream.jsonl"
        self.hash_registry = self.governance_dir / "hash-registry.json"
        self.gl_events_dir = self.governance_dir / "gl-events"
        
    def verify_all(self) -> bool:
        """åŸ·è¡Œæ‰€æœ‰é©—è­‰"""
        
        print(f"ğŸ” [{self.test_id}] é–‹å§‹é–‰ç’°é©—è­‰: {self.scenario}")
        print(f"ğŸ“ è·¯å¾‘: {self.base_path.absolute()}")
        print()
        
        checks = [
            ("ç›®éŒ„çµæ§‹", self.verify_directory_structure),
            ("Meta.yaml æ ¼å¼", self.verify_meta_yaml),
            ("GL Event å­˜åœ¨æ€§", self.verify_gl_event_exists),
            ("GL Event æ ¼å¼", self.verify_gl_event_format),
            ("GL Event æ—¥èªŒè¨˜éŒ„", self.verify_gl_event_logged),
            ("Fallback æ±ºç­–è¿½è¹¤", self.verify_fallback_trace),
            ("Schema Hash", self.verify_schema_hash),
            ("å¯é‡æ’­æ€§", self.verify_replayability),
            ("ç„¡æœªæˆæ¬Šä¿®å¾©", self.verify_no_unauthorized_repair),
            ("è­‰æ“šå®Œæ•´æ€§", self.verify_evidence_integrity),
            ("Hash è¨»å†Š", self.verify_hash_registry),
            ("Event Stream å®Œæ•´æ€§", self.verify_event_stream),
            ("Hash é‚Šç•Œ", self.verify_hash_boundary),
            ("Era å°å­˜", self.verify_era_seal),
            ("MNGA åˆè¦æ€§", self.verify_mnga_compliance),
        ]
        
        all_passed = True
        
        for check_name, check_func in checks:
            try:
                result = check_func()
                if result:
                    print(f"  âœ… {check_name}")
                else:
                    print(f"  âŒ {check_name}")
                    all_passed = False
            except Exception as e:
                print(f"  âŒ {check_name}: {e}")
                self.violations.append({
                    "check": check_name,
                    "error": str(e),
                    "type": "exception"
                })
                all_passed = False
        
        # ç”¢ç”Ÿé©—è­‰å ±å‘Š
        self.generate_verification_report(all_passed)
        
        # è¨˜éŒ„é©—è­‰å®Œæˆåˆ° event stream
        self.log_verification_complete(all_passed)
        
        return all_passed
    
    def verify_directory_structure(self) -> bool:
        """é©—è­‰ç›®éŒ„çµæ§‹"""
        required_dirs = [
            self.base_path,
            self.base_path / "expected_artifacts",
            self.base_path / "expected_artifacts" / "gl-events",
            self.base_path / "evidence",
            self.base_path / "evidence" / "injection",
        ]
        
        for dir_path in required_dirs:
            if not dir_path.exists():
                raise FileNotFoundError(f"ç›®éŒ„ä¸å­˜åœ¨: {dir_path}")
        
        return True
    
    def verify_meta_yaml(self) -> bool:
        """é©—è­‰ Meta.yaml æ ¼å¼"""
        meta_file = self.base_path / "meta.yaml"
        
        if not meta_file.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ° meta.yaml: {meta_file}")
        
        # Load and parse YAML
        import yaml
        with open(meta_file, 'r') as f:
            meta = yaml.safe_load(f)
        
        # é©—è­‰å¿…è¦æ¬„ä½
        required_fields = [
            "test_id", "test_name", "scenario", "gl_level", "era", 
            "platform", "namespace", "generated_by", "mnga_integration"
        ]
        
        for field in required_fields:
            if field not in meta:
                raise ValueError(f"meta.yaml ç¼ºå°‘æ¬„ä½: {field}")
        
        # é©—è­‰ MNGA åˆè¦æ€§æ¬„ä½
        if meta.get("namespace") != "/governance/kernel/tests/autonomy-boundary":
            raise ValueError(f"namespace ä¸ç¬¦: {meta.get('namespace')}")
        
        if meta.get("mnga_version") != "v2.0":
            raise ValueError(f"MNGA ç‰ˆæœ¬ä¸ç¬¦: {meta.get('mnga_version')}")
        
        return True
    
    def verify_gl_event_exists(self) -> bool:
        """é©—è­‰ GL Event å­˜åœ¨"""
        if not self.gl_events_dir.exists():
            raise FileNotFoundError(
                f"GL events ç›®éŒ„ä¸å­˜åœ¨: {self.gl_events_dir}"
            )
        
        # å°‹æ‰¾ç¬¦åˆæ¨¡å¼çš„äº‹ä»¶æª”æ¡ˆ
        pattern = f"*_{self.scenario}.json"
        matching_files = list(self.gl_events_dir.glob(pattern))
        
        if not matching_files:
            raise FileNotFoundError(
                f"æ‰¾ä¸åˆ° GL Event æª”æ¡ˆ (pattern: {pattern})"
            )
        
        return True
    
    def verify_gl_event_format(self) -> bool:
        """é©—è­‰ GL Event æ ¼å¼"""
        pattern = f"*_{self.scenario}.json"
        event_file = list(self.gl_events_dir.glob(pattern))[0]
        
        with open(event_file, 'r') as f:
            event = json.load(f)
        
        required_fields = [
            "event_id", "timestamp", "event_type", "namespace",
            "layer", "platform", "era", "payload"
        ]
        
        for field in required_fields:
            if field not in event:
                raise ValueError(f"GL Event ç¼ºå°‘æ¬„ä½: {field}")
        
        # é©—è­‰ event_type æ­£ç¢º
        if self.scenario not in event["event_type"]:
            raise ValueError(
                f"Event type ä¸ç¬¦: expected '{self.scenario}', "
                f"got '{event['event_type']}'"
            )
        
        # é©—è­‰ namespace
        if not event["namespace"].startswith("/governance/kernel/"):
            raise ValueError(
                f"GL Event namespace ä¸ç¬¦: {event['namespace']}"
            )
        
        return True
    
    def verify_gl_event_logged(self) -> bool:
        """é©—è­‰ GL Event å·²è¨˜éŒ„åˆ° event-stream.jsonl"""
        if not self.event_stream.exists():
            raise FileNotFoundError(
                f"event-stream.jsonl ä¸å­˜åœ¨: {self.event_stream}"
            )
        
        # å°‹æ‰¾ç›¸é—œäº‹ä»¶
        found = False
        with open(self.event_stream, 'r') as f:
            for line in f:
                event = json.loads(line)
                if (event.get("event_type") == f"test_{self.scenario}" or
                    self.scenario in event.get("event_type", "")):
                    found = True
                    break
        
        if not found:
            raise ValueError(
                f"GL Event æœªè¨˜éŒ„åˆ° event-stream.jsonl: {self.scenario}"
            )
        
        return True
    
    def verify_fallback_trace(self) -> bool:
        """é©—è­‰ Fallback æ±ºç­–è¿½è¹¤"""
        trace_file = self.base_path / "evidence" / "fallback_decision_trace.json"
        
        if not trace_file.exists():
            raise FileNotFoundError(
                f"æ‰¾ä¸åˆ° fallback æ±ºç­–è¿½è¹¤: {trace_file}"
            )
        
        with open(trace_file, 'r') as f:
            trace = json.load(f)
        
        # é©—è­‰å¿…è¦æ¬„ä½
        required_fields = [
            "test_id", "scenario", "fallback_decisions", "decision_trace_hash"
        ]
        
        for field in required_fields:
            if field not in trace:
                raise ValueError(f"Fallback trace ç¼ºå°‘æ¬„ä½: {field}")
        
        # é©—è­‰è‡³å°‘æœ‰ä¸€å€‹æ±ºç­–
        if len(trace["fallback_decisions"]) == 0:
            raise ValueError("Fallback trace æ²’æœ‰ä»»ä½•æ±ºç­–è¨˜éŒ„")
        
        # é©—è­‰æ¯å€‹æ±ºç­–éƒ½æœ‰æ™‚é–“æˆ³å’Œç†ç”±
        for decision in trace["fallback_decisions"]:
            if "timestamp" not in decision or "reason" not in decision:
                raise ValueError("Fallback æ±ºç­–ç¼ºå°‘æ™‚é–“æˆ³æˆ–ç†ç”±")
        
        # é©—è­‰ hash æ ¼å¼
        if len(trace["decision_trace_hash"]) != 64:
            raise ValueError("decision_trace_hash æ ¼å¼éŒ¯èª¤")
        
        return True
    
    def verify_schema_hash(self) -> bool:
        """é©—è­‰ Schema Hash"""
        hash_file = self.base_path / "evidence" / "hash_of_last_verified_schema.txt"
        
        if not hash_file.exists():
            raise FileNotFoundError(
                f"æ‰¾ä¸åˆ° schema hash: {hash_file}"
            )
        
        with open(hash_file, 'r') as f:
            hash_value = f.read().strip()
        
        # é©—è­‰ hash æ ¼å¼ (SHA256)
        if len(hash_value) != 64:
            raise ValueError(
                f"Schema hash æ ¼å¼éŒ¯èª¤ (expected 64 chars, got {len(hash_value)})"
            )
        
        # é©—è­‰ hash åªåŒ…å«åå…­é€²åˆ¶å­—ç¬¦
        try:
            int(hash_value, 16)
        except ValueError:
            raise ValueError("Schema hash åŒ…å«ç„¡æ•ˆå­—ç¬¦")
        
        return True
    
    def verify_replayability(self) -> bool:
        """é©—è­‰å¯é‡æ’­æ€§"""
        replay_file = self.base_path / "evidence" / "replayability_report.json"
        
        if not replay_file.exists():
            raise FileNotFoundError(
                f"æ‰¾ä¸åˆ°å¯é‡æ’­æ€§å ±å‘Š: {replay_file}"
            )
        
        with open(replay_file, 'r') as f:
            report = json.load(f)
        
        # é©—è­‰å¯é‡æ’­æ€§
        if not report.get("replay_consistent", False):
            raise ValueError("ç³»çµ±æ±ºç­–ä¸å¯é‡æ’­")
        
        # é©—è­‰é‡æ’­æ¬¡æ•¸
        if report.get("replay_count", 0) < 2:
            self.warnings.append({
                "check": "Replayability",
                "warning": "é‡æ’­æ¬¡æ•¸å°‘æ–¼ 2 æ¬¡ï¼Œå»ºè­°å¢åŠ é‡æ’­æ¸¬è©¦"
            })
        
        return True
    
    def verify_no_unauthorized_repair(self) -> bool:
        """é©—è­‰ç„¡æœªæˆæ¬Šä¿®å¾©"""
        replay_file = self.base_path / "evidence" / "replayability_report.json"
        
        with open(replay_file, 'r') as f:
            report = json.load(f)
        
        # é©—è­‰æ²’æœ‰æœªæˆæ¬Šä¿®å¾©
        if report.get("unauthorized_self_healing", False):
            raise ValueError("åµæ¸¬åˆ°æœªæˆæ¬Šçš„è‡ªæˆ‘ä¿®å¾©è¡Œç‚º")
        
        return True
    
    def verify_evidence_integrity(self) -> bool:
        """é©—è­‰è­‰æ“šå®Œæ•´æ€§"""
        evidence_dir = self.base_path / "evidence"
        
        required_files = [
            "test_generation_trace.json",
            "test_seal.json",
            "injection/injection_trace.json",
            "fallback_decision_trace.json",
            "hash_of_last_verified_schema.txt",
            "replayability_report.json",
        ]
        
        for required_file in required_files:
            file_path = evidence_dir / required_file
            if not file_path.exists():
                raise FileNotFoundError(
                    f"è­‰æ“šæª”æ¡ˆç¼ºå¤±: {required_file}"
                )
        
        return True
    
    def verify_hash_registry(self) -> bool:
        """é©—è­‰ Hash è¨»å†Š"""
        if not self.hash_registry.exists():
            raise FileNotFoundError(
                f"hash-registry.json ä¸å­˜åœ¨: {self.hash_registry}"
            )
        
        with open(self.hash_registry, 'r') as f:
            registry = json.load(f)
        
        # é©—è­‰è‡³å°‘æœ‰ä¸€å€‹æ¢ç›®
        if not isinstance(registry, dict) or len(registry) == 0:
            raise ValueError("hash-registry.json ç‚ºç©ºæˆ–æ ¼å¼éŒ¯èª¤")
        
        # é©—è­‰è­‰æ“šæª”æ¡ˆéƒ½å·²è¨»å†Š
        evidence_files = [
            self.base_path / "meta.yaml",
            self.base_path / "inject_failure.sh",
            self.base_path / "verify_closure.py",
            self.base_path / "evidence" / "test_generation_trace.json",
            self.base_path / "evidence" / "test_seal.json",
        ]
        
        for file_path in evidence_files:
            if not file_path.exists():
                continue
            
            file_path_str = str(file_path)
            if file_path_str not in registry:
                raise ValueError(
                    f"æª”æ¡ˆæœªè¨»å†Šåˆ° hash-registry.json: {file_path_str}"
                )
            
            # é©—è­‰ hash æ ¼å¼
            entry = registry[file_path_str]
            if "sha256" not in entry:
                raise ValueError(
                    f"hash-registry.json æ¢ç›®ç¼ºå°‘ sha256: {file_path_str}"
                )
            
            # é©—è­‰ hash é•·åº¦
            if len(entry["sha256"]) != 64:
                raise ValueError(
                    f"hash-registry.json æ¢ç›® hash æ ¼å¼éŒ¯èª¤: {file_path_str}"
                )
        
        return True
    
    def verify_event_stream(self) -> bool:
        """é©—è­‰ Event Stream å®Œæ•´æ€§"""
        if not self.event_stream.exists():
            raise FileNotFoundError(
                f"event-stream.jsonl ä¸å­˜åœ¨: {self.event_stream}"
            )
        
        # é©—è­‰è‡³å°‘æœ‰ä¸€å€‹æ¸¬è©¦ç›¸é—œäº‹ä»¶
        test_events_found = 0
        with open(self.event_stream, 'r') as f:
            for line in f:
                event = json.loads(line)
                if event.get("test_id") == self.test_id:
                    test_events_found += 1
        
        if test_events_found == 0:
            raise ValueError(
                f"event-stream.jsonl ä¸­æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦ {self.test_id} çš„äº‹ä»¶"
            )
        
        return True
    
    def verify_hash_boundary(self) -> bool:
        """é©—è­‰ Hash é‚Šç•Œ"""
        hash_boundary_file = Path(".governance/hash_boundary.yaml")
        
        if not hash_boundary_file.exists():
            raise FileNotFoundError(
                f"æ‰¾ä¸åˆ° hash boundary: {hash_boundary_file}"
            )
        
        with open(hash_boundary_file, 'r') as f:
            content = f.read()
        
        # é©—è­‰å¿…è¦æ¬„ä½å­˜åœ¨
        required_fields = ["gl_root:", "era:", "test_id:"]
        for field in required_fields:
            if field not in content:
                raise ValueError(f"Hash boundary ç¼ºå°‘æ¬„ä½: {field}")
        
        return True
    
    def verify_era_seal(self) -> bool:
        """é©—è­‰ Era å°å­˜"""
        seal_file = self.base_path / "evidence" / "era_boundary_seal.json"
        
        if not seal_file.exists():
            raise FileNotFoundError(
                f"æ‰¾ä¸åˆ° era seal: {seal_file}"
            )
        
        with open(seal_file, 'r') as f:
            seal = json.load(f)
        
        # é©—è­‰å°å­˜æ¬„ä½
        required_fields = [
            "test_id", "scenario", "sealed_at", "evidence_hash", "artifacts"
        ]
        
        for field in required_fields:
            if field not in seal:
                raise ValueError(f"Era seal ç¼ºå°‘æ¬„ä½: {field}")
        
        # é©—è­‰ MNGA ç‰ˆæœ¬
        if seal.get("mnga_version") != "v2.0":
            raise ValueError(
                f"Era seal MNGA ç‰ˆæœ¬ä¸ç¬¦: {seal.get('mnga_version')}"
            )
        
        return True
    
    def verify_mnga_compliance(self) -> bool:
        """é©—è­‰ MNGA åˆè¦æ€§"""
        meta_file = self.base_path / "meta.yaml"
        
        import yaml
        with open(meta_file, 'r') as f:
            meta = yaml.safe_load(f)
        
        # é©—è­‰ MNGA æ•´åˆè¦æ±‚
        mnga_integration = meta.get("mnga_integration", {})
        
        required_integrations = [
            "event_stream_logging",
            "hash_registry_registration",
            "validator_integration",
            "closure_verification_required"
        ]
        
        for integration in required_integrations:
            if not mnga_integration.get(integration, False):
                raise ValueError(
                    f"MNGA æ•´åˆè¦æ±‚æœªæ»¿è¶³: {integration}"
                )
        
        return True
    
    def generate_verification_report(self, all_passed: bool):
        """ç”¢ç”Ÿé©—è­‰å ±å‘Š"""
        report = {
            "test_id": self.test_id,
            "scenario": self.scenario,
            "verified_at": datetime.utcnow().isoformat() + 'Z',
            "all_checks_passed": all_passed,
            "violations": self.violations,
            "warnings": self.warnings,
            "closure_verified": all_passed,
            "mnga_compliant": all_passed,
            "validator_version": "v2.0"
        }
        
        report_file = self.base_path / "evidence" / "closure_verification_report.json"
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ é©—è­‰å ±å‘Š: {report_file}")
        
        if all_passed:
            print("âœ… æ‰€æœ‰é–‰ç’°é©—è­‰é€šé")
            print("âœ… MNGA åˆè¦æ€§é©—è­‰é€šé")
        else:
            print(f"âŒ {len(self.violations)} å€‹é©—è­‰å¤±æ•—")
            for violation in self.violations:
                print(f"  - {violation['check']}: {violation['error']}")
        
        if self.warnings:
            print(f"âš ï¸  {len(self.warnings)} å€‹è­¦å‘Š")
            for warning in self.warnings:
                print(f"  - {warning['check']}: {warning.get('warning', '')}")
    
    def log_verification_complete(self, all_passed: bool):
        """è¨˜éŒ„é©—è­‰å®Œæˆåˆ° event stream"""
        try:
            import uuid
            event_id = str(uuid.uuid4())
            
            event = {
                "event_id": event_id,
                "timestamp": datetime.utcnow().isoformat() + 'Z',
                "event_type": "test_verification_complete",
                "namespace": "/governance/kernel/tests/autonomy-boundary",
                "layer": "kernel",
                "platform": "test",
                "era": "current-era",
                "test_id": self.test_id,
                "scenario": self.scenario,
                "payload": {
                    "all_checks_passed": all_passed,
                    "violations_count": len(self.violations),
                    "warnings_count": len(self.warnings),
                    "closure_verified": all_passed,
                    "mnga_compliant": all_passed
                }
            }
            
            with open(self.event_stream, 'a') as f:
                f.write(json.dumps(event) + '\n')
            
            print(f"ğŸ“ é©—è­‰å®Œæˆå·²è¨˜éŒ„åˆ° event-stream.jsonl")
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•è¨˜éŒ„åˆ° event-stream.jsonl: {e}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Autonomy Boundary Test - Closure Verification"
    )
    parser.add_argument("test_id", help="Test ID (e.g., ABT-001)")
    parser.add_argument("scenario", help="Test scenario name")
    
    args = parser.parse_args()
    
    verifier = ClosureVerifier(args.test_id, args.scenario)
    
    if verifier.verify_all():
        sys.exit(0)
    else:
        sys.exit(1)