#!/usr/bin/env python3
"""
NG æ‰¹æ¬¡åŸ·è¡Œå™¨
NG Batch Executor

NG Code: NG00002
Purpose: æ‰¹é‡åŸ·è¡Œ NG å‘½åç©ºé–“æ²»ç†æ“ä½œ

å°ˆé–€è™•ç†ï¼š
- æ‰¹æ¬¡ 1-5 çš„è‡ªå‹•åŒ–åŸ·è¡Œ
- å¤§è¦æ¨¡å‘½åç©ºé–“æ“ä½œ
- ä¸¦è¡ŒåŸ·è¡Œå’Œé€²åº¦è¿½è¹¤
- æ‰¹æ¬¡å ±å‘Šç”Ÿæˆ
"""

import sys
import json
import logging
import importlib.util
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass

SCRIPT_DIR = Path(__file__).resolve().parent
NG_ROOT = SCRIPT_DIR.parent

logger = logging.getLogger(__name__)


@dataclass
class BatchTask:
    """æ‰¹æ¬¡ä»»å‹™"""

    task_id: str
    task_type: str  # register, validate, migrate, etc.
    target: str  # ç›®æ¨™å‘½åç©ºé–“æˆ–ç¯„åœ
    params: Dict[str, Any]
    status: str = "pending"  # pending, running, completed, failed
    result: Any = None
    error: str = None


class NgBatchExecutor:
    """NG æ‰¹æ¬¡åŸ·è¡Œå™¨"""

    def __init__(self, batch_id: str = "batch-1", max_workers: int = 4):
        """
        åˆå§‹åŒ–æ‰¹æ¬¡åŸ·è¡Œå™¨

        Args:
            batch_id: æ‰¹æ¬¡ ID (batch-1 åˆ° batch-5)
            max_workers: æœ€å¤§ä¸¦è¡Œå·¥ä½œç·šç¨‹æ•¸
        """
        self.batch_id = batch_id
        self.max_workers = max_workers
        self.tasks: List[BatchTask] = []
        self.execution_start = None
        self.execution_end = None

        logger.info(f"ğŸ¯ æ‰¹æ¬¡åŸ·è¡Œå™¨å·²åˆå§‹åŒ–: {batch_id} (workers={max_workers})")

    def add_task(self, task: BatchTask):
        """æ·»åŠ æ‰¹æ¬¡ä»»å‹™"""
        self.tasks.append(task)
        logger.info(f"ğŸ“ æ·»åŠ ä»»å‹™: {task.task_type} â†’ {task.target}")

    def add_tasks_from_config(self, config_path: str):
        """å¾é…ç½®æ–‡ä»¶æ·»åŠ ä»»å‹™"""
        config_file = Path(config_path)

        if not config_file.exists():
            logger.warning(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return

        with open(config_file, "r", encoding="utf-8") as f:
            if config_path.endswith(".json"):
                config = json.load(f)
            else:  # YAML
                import yaml

                config = yaml.safe_load(f)

        batch_tasks = config.get("tasks", [])

        for task_config in batch_tasks:
            task = BatchTask(
                task_id=task_config.get("id", f"task-{len(self.tasks)}"),
                task_type=task_config["type"],
                target=task_config["target"],
                params=task_config.get("params", {}),
            )
            self.add_task(task)

        logger.info(f"âœ… å¾é…ç½®è¼‰å…¥ {len(batch_tasks)} å€‹ä»»å‹™")

    def execute_sequential(self) -> Dict[str, Any]:
        """é †åºåŸ·è¡Œæ‰€æœ‰ä»»å‹™"""
        logger.info(f"ğŸš€ é–‹å§‹é †åºåŸ·è¡Œ: {len(self.tasks)} å€‹ä»»å‹™")

        self.execution_start = datetime.now()

        results = {
            "batch_id": self.batch_id,
            "mode": "sequential",
            "total_tasks": len(self.tasks),
            "completed": 0,
            "failed": 0,
            "tasks": [],
        }

        for task in self.tasks:
            result = self._execute_single_task(task)
            results["tasks"].append(result)

            if result["status"] == "completed":
                results["completed"] += 1
            elif result["status"] == "failed":
                results["failed"] += 1

        self.execution_end = datetime.now()
        duration = (self.execution_end - self.execution_start).total_seconds()

        results["duration_seconds"] = duration
        results["success_rate"] = (
            (results["completed"] / results["total_tasks"] * 100)
            if results["total_tasks"] > 0
            else 0
        )

        logger.info(
            f"âœ… æ‰¹æ¬¡åŸ·è¡Œå®Œæˆ: {results['completed']}/{results['total_tasks']} æˆåŠŸ"
        )

        return results

    def execute_parallel(self) -> Dict[str, Any]:
        """ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰ä»»å‹™"""
        logger.info(
            f"ğŸš€ é–‹å§‹ä¸¦è¡ŒåŸ·è¡Œ: {len(self.tasks)} å€‹ä»»å‹™ (workers={self.max_workers})"
        )

        self.execution_start = datetime.now()

        results = {
            "batch_id": self.batch_id,
            "mode": "parallel",
            "total_tasks": len(self.tasks),
            "completed": 0,
            "failed": 0,
            "tasks": [],
        }

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™
            future_to_task = {
                executor.submit(self._execute_single_task, task): task
                for task in self.tasks
            }

            # æ”¶é›†çµæœ
            for future in as_completed(future_to_task):
                result = future.result()
                results["tasks"].append(result)

                if result["status"] == "completed":
                    results["completed"] += 1
                elif result["status"] == "failed":
                    results["failed"] += 1

                # é¡¯ç¤ºé€²åº¦
                progress = (
                    (results["completed"] + results["failed"])
                    / results["total_tasks"]
                    * 100
                )
                logger.info(
                    f"ğŸ“Š é€²åº¦: {progress:.1f}% ({results['completed'] + results['failed']}/{results['total_tasks']})"
                )

        self.execution_end = datetime.now()
        duration = (self.execution_end - self.execution_start).total_seconds()

        results["duration_seconds"] = duration
        results["success_rate"] = (
            (results["completed"] / results["total_tasks"] * 100)
            if results["total_tasks"] > 0
            else 0
        )

        logger.info(
            f"âœ… ä¸¦è¡ŒåŸ·è¡Œå®Œæˆ: {results['completed']}/{results['total_tasks']} æˆåŠŸ"
        )

        return results

    def _execute_single_task(self, task: BatchTask) -> Dict[str, Any]:
        """åŸ·è¡Œå–®å€‹ä»»å‹™"""
        task.status = "running"
        start_time = datetime.now()

        try:
            # æ ¹æ“šä»»å‹™é¡å‹åŸ·è¡Œç›¸æ‡‰æ“ä½œ
            if task.task_type == "register":
                result = self._execute_register(task)
            elif task.task_type == "validate":
                result = self._execute_validate(task)
            elif task.task_type == "migrate":
                result = self._execute_migrate(task)
            elif task.task_type == "audit":
                result = self._execute_audit(task)
            else:
                result = {
                    "status": "skipped",
                    "reason": f"æœªçŸ¥ä»»å‹™é¡å‹: {task.task_type}",
                }

            task.status = "completed"
            task.result = result

        except Exception as e:
            task.status = "failed"
            task.error = str(e)
            logger.error(f"âŒ ä»»å‹™å¤±æ•— {task.task_id}: {e}")

        duration = (datetime.now() - start_time).total_seconds() * 1000

        return {
            "task_id": task.task_id,
            "task_type": task.task_type,
            "target": task.target,
            "status": task.status,
            "duration_ms": int(duration),
            "result": task.result,
            "error": task.error,
        }

    def _execute_register(self, task: BatchTask) -> Dict[str, Any]:
        """åŸ·è¡Œè¨»å†Šä»»å‹™"""
        return {"action": "register", "target": task.target, "status": "simulated"}

    def _execute_validate(self, task: BatchTask) -> Dict[str, Any]:
        """åŸ·è¡Œé©—è­‰ä»»å‹™"""
        return {
            "action": "validate",
            "target": task.target,
            "valid": True,
            "issues": [],
        }

    def _execute_migrate(self, task: BatchTask) -> Dict[str, Any]:
        """åŸ·è¡Œé·ç§»ä»»å‹™"""
        return {
            "action": "migrate",
            "source": task.target,
            "target": task.params.get("target_namespace", "unknown"),
            "status": "mapped",
        }

    def _execute_audit(self, task: BatchTask) -> Dict[str, Any]:
        """åŸ·è¡Œå¯©è¨ˆä»»å‹™"""
        return {
            "action": "audit",
            "target": task.target,
            "events_count": 0,
            "violations": [],
        }

    def generate_batch_report(self) -> str:
        """ç”Ÿæˆæ‰¹æ¬¡å ±å‘Š"""
        if not self.execution_end:
            return "æ‰¹æ¬¡å°šæœªåŸ·è¡Œ"

        duration = (self.execution_end - self.execution_start).total_seconds()

        completed = sum(1 for t in self.tasks if t.status == "completed")
        failed = sum(1 for t in self.tasks if t.status == "failed")
        success_rate = (completed / len(self.tasks) * 100) if self.tasks else 0

        report_lines = [
            "=" * 70,
            f"NG æ‰¹æ¬¡åŸ·è¡Œå ±å‘Š - {self.batch_id}",
            "=" * 70,
            f"é–‹å§‹æ™‚é–“: {self.execution_start.isoformat()}",
            f"çµæŸæ™‚é–“: {self.execution_end.isoformat()}",
            f"ç¸½è€—æ™‚: {duration:.2f} ç§’",
            "",
            "åŸ·è¡Œçµæœ:",
            f"  ç¸½ä»»å‹™æ•¸: {len(self.tasks)}",
            f"  âœ… å®Œæˆ: {completed}",
            f"  âŒ å¤±æ•—: {failed}",
            f"  æˆåŠŸç‡: {success_rate:.1f}%",
            "",
            "ä»»å‹™è©³æƒ…:",
        ]

        for task in self.tasks:
            status_icon = "âœ…" if task.status == "completed" else "âŒ"
            report_lines.append(
                f"  {status_icon} {task.task_id}: {task.task_type} â†’ {task.target}"
            )

        report_lines.extend(["", "=" * 70])

        return "\n".join(report_lines)

    def save_batch_results(self, output_path: str = None):
        """ä¿å­˜æ‰¹æ¬¡åŸ·è¡Œçµæœ"""
        if not output_path:
            output_path = f"logs/batch-{self.batch_id}-results.json"

        results = {
            "batch_id": self.batch_id,
            "execution_start": (
                self.execution_start.isoformat() if self.execution_start else None
            ),
            "execution_end": (
                self.execution_end.isoformat() if self.execution_end else None
            ),
            "tasks": [
                {
                    "task_id": t.task_id,
                    "task_type": t.task_type,
                    "target": t.target,
                    "status": t.status,
                    "params": t.params,
                    "result": t.result,
                    "error": t.error,
                }
                for t in self.tasks
            ],
        }

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ’¾ æ‰¹æ¬¡çµæœå·²ä¿å­˜: {output_path}")


if __name__ == "__main__":
    # æ¸¬è©¦æ‰¹æ¬¡åŸ·è¡Œå™¨
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s | %(levelname)-8s | %(message)s"
    )

    print("=" * 70)
    print("NG æ‰¹æ¬¡åŸ·è¡Œå™¨æ¸¬è©¦")
    print("=" * 70)

    # å‰µå»ºæ‰¹æ¬¡åŸ·è¡Œå™¨
    batch_executor = NgBatchExecutor(batch_id="batch-test")

    # æ·»åŠ æ¸¬è©¦ä»»å‹™
    print("\næ·»åŠ æ¸¬è©¦ä»»å‹™...")

    for i in range(5):
        task = BatchTask(
            task_id=f"task-{i+1}",
            task_type="validate",
            target=f"pkg.era1.test.component{i+1}",
            params={},
        )
        batch_executor.add_task(task)

    # é †åºåŸ·è¡Œ
    print("\n=== æ¸¬è©¦ 1: é †åºåŸ·è¡Œ ===")
    results_seq = batch_executor.execute_sequential()
    print(f"âœ… é †åºåŸ·è¡Œå®Œæˆ: {results_seq['success_rate']:.1f}% æˆåŠŸç‡")

    # é‡ç½®ä»»å‹™ç‹€æ…‹
    for task in batch_executor.tasks:
        task.status = "pending"

    # ä¸¦è¡ŒåŸ·è¡Œ
    print("\n=== æ¸¬è©¦ 2: ä¸¦è¡ŒåŸ·è¡Œ ===")
    results_par = batch_executor.execute_parallel()
    print(f"âœ… ä¸¦è¡ŒåŸ·è¡Œå®Œæˆ: {results_par['success_rate']:.1f}% æˆåŠŸç‡")

    # ç”Ÿæˆå ±å‘Š
    print("\n" + batch_executor.generate_batch_report())

    # ä¿å­˜çµæœ
    batch_executor.save_batch_results()

    print("\n" + "=" * 70)
    print("âœ… NG æ‰¹æ¬¡åŸ·è¡Œå™¨æ¸¬è©¦å®Œæˆ")
    print("=" * 70)
