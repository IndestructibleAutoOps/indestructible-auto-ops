"""è¨»å†Šè¡¨å‚™ä»½ä»»å‹™

ç”¨é€”: å®šæœŸå‚™ä»½æ‰€æœ‰è¨»å†Šè¡¨æ•¸æ“š
æ•´åˆ: è·¨è¨»å†Šè¡¨å‚™ä»½ç­–ç•¥
"""

import logging
import json
import shutil
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime
from auto_executor import Task, executor

logger = logging.getLogger(__name__)


class RegistryBackupManager:
    """è¨»å†Šè¡¨å‚™ä»½ç®¡ç†å™¨"""

    def __init__(
        self,
        registries_dir: str = "tasks/registries",
        backup_dir: str = "backups/registries",
    ):
        """åˆå§‹åŒ–å‚™ä»½ç®¡ç†å™¨"""
        self.registries_dir = Path(registries_dir)
        self.backup_dir = Path(backup_dir)

    def create_backup(self) -> Dict[str, Any]:
        """å‰µå»ºå‚™ä»½"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / timestamp

        results = {
            "timestamp": timestamp,
            "backup_path": str(backup_path),
            "files_backed_up": 0,
            "total_size": 0,
            "errors": [],
        }

        try:
            # å‰µå»ºå‚™ä»½ç›®éŒ„
            backup_path.mkdir(parents=True, exist_ok=True)

            # å‚™ä»½æ‰€æœ‰è¨»å†Šè¡¨æ–‡ä»¶
            if self.registries_dir.exists():
                for file in self.registries_dir.rglob("*"):
                    if file.is_file() and not file.name.startswith("."):
                        try:
                            # ä¿æŒç›®éŒ„çµæ§‹
                            relative_path = file.relative_to(self.registries_dir)
                            dest_path = backup_path / relative_path
                            dest_path.parent.mkdir(parents=True, exist_ok=True)

                            shutil.copy2(file, dest_path)
                            results["files_backed_up"] += 1
                            results["total_size"] += file.stat().st_size
                        except Exception as e:
                            results["errors"].append(f"{file.name}: {e}")

            # ä¿å­˜å‚™ä»½å…ƒæ•¸æ“š
            metadata = {
                "created_at": datetime.now().isoformat(),
                "files_count": results["files_backed_up"],
                "total_size_bytes": results["total_size"],
                "source": str(self.registries_dir),
            }

            metadata_path = backup_path / "backup_metadata.json"
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            logger.info(f"âœ… å‚™ä»½å®Œæˆ: {backup_path}")

        except Exception as e:
            logger.error(f"âŒ å‚™ä»½å¤±æ•—: {e}")
            results["errors"].append(str(e))

        return results

    def cleanup_old_backups(self, keep_days: int = 30) -> int:
        """æ¸…ç†èˆŠå‚™ä»½"""
        if not self.backup_dir.exists():
            return 0

        removed_count = 0
        cutoff_time = datetime.now().timestamp() - (keep_days * 86400)

        for backup_folder in self.backup_dir.iterdir():
            if backup_folder.is_dir():
                try:
                    folder_time = backup_folder.stat().st_mtime
                    if folder_time < cutoff_time:
                        shutil.rmtree(backup_folder)
                        removed_count += 1
                        logger.info(f"ğŸ—‘ï¸  ç§»é™¤èˆŠå‚™ä»½: {backup_folder.name}")
                except Exception as e:
                    logger.error(f"ç§»é™¤å‚™ä»½å¤±æ•— {backup_folder.name}: {e}")

        return removed_count

    def list_backups(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å‚™ä»½"""
        backups = []

        if not self.backup_dir.exists():
            return backups

        for backup_folder in sorted(self.backup_dir.iterdir(), reverse=True):
            if backup_folder.is_dir():
                metadata_path = backup_folder / "backup_metadata.json"

                if metadata_path.exists():
                    try:
                        with open(metadata_path, "r", encoding="utf-8") as f:
                            metadata = json.load(f)
                        backups.append(
                            {
                                "name": backup_folder.name,
                                "path": str(backup_folder),
                                **metadata,
                            }
                        )
                    except Exception as e:
                        logger.error(f"è®€å–å‚™ä»½å…ƒæ•¸æ“šå¤±æ•— {backup_folder.name}: {e}")

        return backups


class RegistryBackupTask(Task):
    """è¨»å†Šè¡¨å‚™ä»½ä»»å‹™"""

    name = "è¨»å†Šè¡¨å‚™ä»½"
    priority = 2  # é«˜å„ªå…ˆç´šï¼ˆæ•¸æ“šä¿è­·ï¼‰

    def __init__(self):
        super().__init__()
        self.backup_manager = RegistryBackupManager()

    def execute(self):
        """åŸ·è¡Œè¨»å†Šè¡¨å‚™ä»½"""
        logger.info("ğŸ’¾ é–‹å§‹å‚™ä»½è¨»å†Šè¡¨...")

        # å‰µå»ºå‚™ä»½
        results = self.backup_manager.create_backup()

        logger.info(f"ğŸ“¦ å‚™ä»½çµæœ:")
        logger.info(f"  å‚™ä»½æ™‚é–“: {results['timestamp']}")
        logger.info(f"  æª”æ¡ˆæ•¸: {results['files_backed_up']}")
        logger.info(f"  ç¸½å¤§å°: {results['total_size'] / 1024:.1f} KB")

        if results["errors"]:
            logger.error(f"âŒ å‚™ä»½éŒ¯èª¤ ({len(results['errors'])}):")
            for error in results["errors"]:
                logger.error(f"  - {error}")
        else:
            logger.info("âœ… å‚™ä»½å®Œæˆï¼Œç„¡éŒ¯èª¤")

        # æ¸…ç†èˆŠå‚™ä»½ï¼ˆä¿ç•™ 30 å¤©ï¼‰
        removed = self.backup_manager.cleanup_old_backups(keep_days=30)
        if removed > 0:
            logger.info(f"ğŸ—‘ï¸  æ¸…ç†äº† {removed} å€‹èˆŠå‚™ä»½")

        # åˆ—å‡ºç¾æœ‰å‚™ä»½
        backups = self.backup_manager.list_backups()
        logger.info(f"ğŸ“š ç¾æœ‰å‚™ä»½æ•¸: {len(backups)}")
        if backups:
            logger.info(f"  æœ€æ–°å‚™ä»½: {backups[0]['name']}")


# è¨»å†Šä»»å‹™ï¼šæ¯å¤©å‡Œæ™¨ 3 é»å‚™ä»½
executor.register(RegistryBackupTask, cron="0 3 * * *", priority=2)
