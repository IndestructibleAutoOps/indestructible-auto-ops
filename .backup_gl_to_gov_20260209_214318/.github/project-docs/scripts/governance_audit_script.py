# @GL-governed
# @GL-layer: GL90-99
# @GL-semantic: legacy-scripts
# @GL-audit-trail: ../../engine/gl_platform_universe.gl_platform_universe.governance/GL_SEMANTIC_ANCHOR.json
#
# GL Unified Charter Activated
#!/usr/bin/env python3
"""
GL Governance Audit Script
Performs one-by-one isolated file execution audit for root directory files.

GL Unified Charter Activated âœ“
Audit dates are recorded dynamically in audit reports.
"""

"""
Module docstring
================

This module is part of the GL governance framework.
Please add specific module documentation here.
"""
# MNGA-002: Import organization needs review
import sys
import re
import json
import yaml
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Any


class GLGovernanceAudit:
    """GL Governance Audit for machine-native-ops root directory."""
    
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path).resolve()
        self.root_path = self.base_path / "root"
        self.audit_reports_path = self.root_path / ".audit-reports"
        self.timestamp = datetime.now().isoformat()
        self.audit_results = {
            "audit_metadata": {
                "gl_unified_charter": "activated",
                "audit_date": self.timestamp,
                "auditor": "GL Governance Audit Script",
                "version": "1.0.0"
            },
            "summary": {
                "total_files": 0,
                "successful_executions": 0,
                "files_with_issues": 0,
                "total_issues": 0,
                "gl_platform_universe.gl_platform_universe.governance_events": 0,
                "severity_breakdown": {
                    "CRITICAL": 0,
                    "HIGH": 0,
                    "MEDIUM": 0,
                    "LOW": 0
                }
            },
            "file_reports": [],
            "issues": [],
            "recommendations": []
        }
        
    def ensure_directories(self) -> None:
        """Create required directories for audit reports."""
        self.audit_reports_path.mkdir(parents=True, exist_ok=True)
        
    def compute_file_hash(self, file_path: Path) -> str:
        """Compute SHA-256 hash of file for integrity verification."""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    
    def scan_root_files(self) -> list[Path]:
        """Recursively scan all files in root directory."""
        files = []
        # Files generated by this audit that should be excluded
        excluded_files = [
            "GLOBAL_GOVERNANCE_AUDIT_REPORT.json",
            "file-inventory.json"
        ]
        for file_path in self.root_path.rglob("*"):
            if file_path.is_file():
                # Exclude audit reports directory and generated files
                if ".audit-reports" not in str(file_path):
                    if file_path.name not in excluded_files:
                        files.append(file_path)
        return sorted(files)
    
    def normalize_extension(self, ext: str) -> str:
        """Normalize file extension to lowercase."""
        return ext.lower()
    
    def check_gl_markers(self, content: str, file_ext: str) -> list[dict[str, Any]]:
        """Check for GL layer markers in file content."""
        issues = []
        gl_markers = ["GL Layer", "gl-layer", "GL:", "gl:", "machinenativeops.io"]
        
        has_gl_marker = any(marker in content for marker in gl_markers)
        
        # Normalize extension to lowercase for consistent comparison
        normalized_ext = self.normalize_extension(file_ext)
        if not has_gl_marker and normalized_ext in ['.yaml', '.yml', '.json']:
            issues.append({
                "type": "missing_gl_marker",
                "severity": "MEDIUM",
                "message": "File lacks GL layer markers for gl_platform_universe.gl_platform_universe.governance traceability",
                "recommendation": "Add GL layer markers (e.g., machinenativeops.io annotations)"
            })
        
        return issues
    
    def check_metadata(
        self, content: str, file_ext: str, parsed_data: Any
    ) -> list[dict[str, Any]]:
        """Check for required metadata fields."""
        issues = []
        
        if file_ext in ['.yaml', '.yml'] and isinstance(parsed_data, dict):
            # Check for standard metadata
            required_fields = ['version', 'metadata']
            missing = []
            
            for field in required_fields:
                if field not in parsed_data:
                    # Check for alternative patterns
                    if field == 'version':
                        if 'apiVersion' not in parsed_data:
                            missing.append(field)
                    else:
                        missing.append(field)
            
            if missing:
                issues.append({
                    "type": "missing_metadata",
                    "severity": "MEDIUM",
                    "message": f"Missing standard metadata fields: {', '.join(missing)}",
                    "recommendation": "Add standard metadata section with version and description"
                })
                
        return issues
    
    def execute_yaml_file(
        self, file_path: Path
    ) -> dict[str, Any]:
        """Execute isolated audit on YAML file."""
        result = {
            "file": str(file_path.relative_to(self.base_path)),
            "type": "yaml",
            "status": "success",
            "execution_time": datetime.now().isoformat(),
            "structure": {},
            "issues": [],
            "gl_platform_universe.gl_platform_universe.governance_events": []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse YAML
            try:
                parsed_data = yaml.safe_load(content)
                result["structure"] = {
                    "type": str(type(parsed_data).__name__),
                    "top_level_keys": (
                        list(parsed_data.keys()) if isinstance(parsed_data, dict) 
                        else None
                    )
                }
                
                # Check GL markers
                result["issues"].extend(
                    self.check_gl_markers(content, '.yaml')
                )
                
                # Check metadata
                result["issues"].extend(
                    self.check_metadata(content, '.yaml', parsed_data)
                )
                
                # Log gl_platform_universe.gl_platform_universe.governance event
                result["gl_platform_universe.gl_platform_universe.governance_events"].append({
                    "event": "yaml_parsed",
                    "timestamp": datetime.now().isoformat(),
                    "details": "YAML file successfully parsed and validated"
                })
                
            except yaml.YAMLError as e:
                result["status"] = "error"
                result["issues"].append({
                    "type": "yaml_parse_error",
                    "severity": "HIGH",
                    "message": f"YAML parsing failed: {str(e)}",
                    "recommendation": "Fix YAML syntax errors"
                })
                
        except Exception as e:
            result["status"] = "error"
            result["issues"].append({
                "type": "file_read_error",
                "severity": "HIGH",
                "message": f"Failed to read file: {str(e)}",
                "recommendation": "Check file permissions and encoding"
            })
            
        return result
    
    def execute_json_file(
        self, file_path: Path
    ) -> dict[str, Any]:
        """Execute isolated audit on JSON file."""
        result = {
            "file": str(file_path.relative_to(self.base_path)),
            "type": "json",
            "status": "success",
            "execution_time": datetime.now().isoformat(),
            "structure": {},
            "issues": [],
            "gl_platform_universe.gl_platform_universe.governance_events": []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse JSON
            try:
                parsed_data = json.loads(content)
                result["structure"] = {
                    "type": str(type(parsed_data).__name__),
                    "top_level_keys": (
                        list(parsed_data.keys()) if isinstance(parsed_data, dict)
                        else None
                    )
                }
                
                # Check GL markers
                result["issues"].extend(
                    self.check_gl_markers(content, '.json')
                )
                
                # Log gl_platform_universe.gl_platform_universe.governance event
                result["gl_platform_universe.gl_platform_universe.governance_events"].append({
                    "event": "json_parsed",
                    "timestamp": datetime.now().isoformat(),
                    "details": "JSON file successfully parsed and validated"
                })
                
            except json.JSONDecodeError as e:
                result["status"] = "error"
                result["issues"].append({
                    "type": "json_parse_error",
                    "severity": "HIGH",
                    "message": f"JSON parsing failed: {str(e)}",
                    "recommendation": "Fix JSON syntax errors"
                })
                
        except Exception as e:
            result["status"] = "error"
            result["issues"].append({
                "type": "file_read_error",
                "severity": "HIGH",
                "message": f"Failed to read file: {str(e)}",
                "recommendation": "Check file permissions and encoding"
            })
            
        return result
    
    def execute_shell_file(
        self, file_path: Path
    ) -> dict[str, Any]:
        """Execute isolated audit on shell script file."""
        result = {
            "file": str(file_path.relative_to(self.base_path)),
            "type": "shell",
            "status": "success",
            "execution_time": datetime.now().isoformat(),
            "structure": {},
            "issues": [],
            "gl_platform_universe.gl_platform_universe.governance_events": []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            # Safely check for shebang (handles empty files and empty first lines)
            has_shebang = False
            if lines and len(lines[0]) > 0:
                has_shebang = lines[0].startswith('#!')
            
            # Check for 'set -e' or variants like 'set -euo pipefail'
            set_e_pattern = re.compile(r'^set\s+-[^\s]*e', re.MULTILINE)
            uses_set_e = bool(set_e_pattern.search(content))
            
            result["structure"] = {
                "line_count": len(lines),
                "has_shebang": has_shebang,
                "uses_set_e": uses_set_e
            }
            
            # Check for safety practices using regex pattern
            if not uses_set_e:
                result["issues"].append({
                    "type": "missing_safety_flag",
                    "severity": "LOW",
                    "message": "Shell script missing 'set -e' safety flag",
                    "recommendation": "Add 'set -e' to exit on errors"
                })
            
            # Check for shellcheck validation syntax
            result["gl_platform_universe.gl_platform_universe.governance_events"].append({
                "event": "shell_analyzed",
                "timestamp": datetime.now().isoformat(),
                "details": "Shell script structure analyzed"
            })
            
        except Exception as e:
            result["status"] = "error"
            result["issues"].append({
                "type": "file_read_error",
                "severity": "HIGH",
                "message": f"Failed to read file: {str(e)}",
                "recommendation": "Check file permissions and encoding"
            })
            
        return result
    
    def execute_markdown_file(
        self, file_path: Path
    ) -> dict[str, Any]:
        """Execute isolated audit on Markdown file."""
        result = {
            "file": str(file_path.relative_to(self.base_path)),
            "type": "markdown",
            "status": "success",
            "execution_time": datetime.now().isoformat(),
            "structure": {},
            "issues": [],
            "gl_platform_universe.gl_platform_universe.governance_events": []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            # Extract headers
            headers = [
                line.strip() for line in lines if line.startswith('#')
            ]
            
            result["structure"] = {
                "line_count": len(lines),
                "header_count": len(headers),
                "headers": headers[:10]  # First 10 headers
            }
            
            result["gl_platform_universe.gl_platform_universe.governance_events"].append({
                "event": "markdown_analyzed",
                "timestamp": datetime.now().isoformat(),
                "details": "Markdown file structure analyzed"
            })
            
        except Exception as e:
            result["status"] = "error"
            result["issues"].append({
                "type": "file_read_error",
                "severity": "HIGH",
                "message": f"Failed to read file: {str(e)}",
                "recommendation": "Check file permissions and encoding"
            })
            
        return result
    
    def execute_file(
        self, file_path: Path
    ) -> dict[str, Any]:
        """Execute isolated audit on a single file based on type."""
        ext = self.normalize_extension(file_path.suffix)
        
        # Route to appropriate handler
        if ext in ['.yaml', '.yml']:
            return self.execute_yaml_file(file_path)
        elif ext == '.json':
            return self.execute_json_file(file_path)
        elif ext == '.sh':
            return self.execute_shell_file(file_path)
        elif ext == '.md':
            return self.execute_markdown_file(file_path)
        else:
            # Generic file audit
            return {
                "file": str(file_path.relative_to(self.base_path)),
                "type": "unknown",
                "status": "skipped",
                "execution_time": datetime.now().isoformat(),
                "structure": {},
                "issues": [],
                "gl_platform_universe.gl_platform_universe.governance_events": [{
                    "event": "file_skipped",
                    "timestamp": datetime.now().isoformat(),
                    "details": f"Unknown file type: {ext}"
                }]
            }
    
    def generate_file_inventory(
        self, files: list[Path]
    ) -> dict[str, Any]:
        """Generate comprehensive file inventory."""
        inventory = {
            "generated": self.timestamp,
            "root_path": str(self.root_path),
            "total_files": len(files),
            "files": []
        }
        
        for file_path in files:
            stat = file_path.stat()
            inventory["files"].append({
                "path": str(file_path.relative_to(self.base_path)),
                "name": file_path.name,
                "extension": file_path.suffix,
                "size_bytes": stat.st_size,
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "sha256": self.compute_file_hash(file_path)
            })
        
        return inventory
    
    def save_individual_report(
        self, report: dict[str, Any], file_path: Path
    ) -> None:
        """Save individual file audit report."""
        report_name = (
            file_path.relative_to(self.root_path)
            .as_posix()
            .replace('/', '_')
            .replace('.', '_')
        )
        report_path = self.audit_reports_path / f"{report_name}_audit.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, default=str)
    
    def run_audit(self) -> dict[str, Any]:
        """Execute the complete gl_platform_universe.gl_platform_universe.governance audit."""
        print("=" * 60)
        print("GL Governance Audit - Starting")
        print("=" * 60)
        
        # Ensure directories exist
        self.ensure_directories()
        
        # Scan files
        files = self.scan_root_files()
        self.audit_results["summary"]["total_files"] = len(files)
        print(f"\nðŸ“ Found {len(files)} files in root directory\n")
        
        # Generate file inventory
        inventory = self.generate_file_inventory(files)
        inventory_path = self.root_path / "file-inventory.json"
        with open(inventory_path, 'w', encoding='utf-8') as f:
            json.dump(inventory, f, indent=2, default=str)
        print(f"âœ… Generated file inventory: {inventory_path}")
        
        # Execute audit for each file
        for i, file_path in enumerate(files, 1):
            print(f"\n[{i}/{len(files)}] Auditing: {file_path.relative_to(self.base_path)}")
            
            # Execute isolated audit
            report = self.execute_file(file_path)
            
            # Save individual report
            self.save_individual_report(report, file_path)
            
            # Update summary
            self.audit_results["file_reports"].append(report)
            
            if report["status"] == "success":
                self.audit_results["summary"]["successful_executions"] += 1
            
            if report["issues"]:
                self.audit_results["summary"]["files_with_issues"] += 1
                for issue in report["issues"]:
                    self.audit_results["issues"].append({
                        "file": report["file"],
                        **issue
                    })
                    severity = issue.get("severity", "LOW")
                    self.audit_results["summary"]["severity_breakdown"][severity] += 1
                    self.audit_results["summary"]["total_issues"] += 1
            
            # Count gl_platform_universe.gl_platform_universe.governance events
            events = len(report.get("gl_platform_universe.gl_platform_universe.governance_events", []))
            self.audit_results["summary"]["gl_platform_universe.gl_platform_universe.governance_events"] += events
            
            status = "âœ…" if report["status"] == "success" else "âŒ"
            issue_count = len(report.get("issues", []))
            print(f"   {status} Status: {report['status']}, Issues: {issue_count}")
        
        # Generate recommendations
        self.audit_results["recommendations"] = [
            {
                "id": "REC-001",
                "priority": "HIGH",
                "title": "Add GL Layer Markers",
                "description": (
                    "Most YAML/JSON files lack GL layer markers. "
                    "Add machinenativeops.io annotations to all gl_platform_universe.gl_platform_universe.governance-critical files."
                ),
                "affected_files": len([
                    i for i in self.audit_results["issues"]
                    if i.get("type") == "missing_gl_marker"
                ])
            },
            {
                "id": "REC-002",
                "priority": "MEDIUM",
                "title": "Add Standard Metadata",
                "description": (
                    "General recommendation: ensure configuration files include "
                    "standard metadata fields (version, description) for better "
                    "traceability, even if no missing-metadata issues were detected "
                    "in this report."
                ),
                "affected_files": len([
                    i for i in self.audit_results["issues"]
                    if i.get("type") == "missing_metadata"
                ])
            },
            {
                "id": "REC-003",
                "priority": "LOW",
                "title": "Best Practice Directory Structure",
                "description": (
                    "Consider organizing root files into logical subdirectories: "
                    "config/, policies/, scripts/, docs/"
                ),
                "affected_files": 0
            }
        ]
        
        # Save global report
        global_report_path = self.root_path / "GLOBAL_GOVERNANCE_AUDIT_REPORT.json"
        with open(global_report_path, 'w', encoding='utf-8') as f:
            json.dump(self.audit_results, f, indent=2, default=str)
        
        print("\n" + "=" * 60)
        print("GL Governance Audit - Complete")
        print("=" * 60)
        print("\nðŸ“Š Summary:")
        summary = self.audit_results["summary"]
        print(f"   Total Files: {summary['total_files']}")
        print(f"   Successful: {summary['successful_executions']}")
        print(f"   With Issues: {summary['files_with_issues']}")
        print(f"   Total Issues: {summary['total_issues']}")
        print(f"   Governance Events: {summary['gl_platform_universe.gl_platform_universe.governance_events']}")
        print("\nðŸ” Severity Breakdown:")
        for sev, count in summary["severity_breakdown"].items():
            print(f"   {sev}: {count}")
        print(f"\nâœ… Report saved: {global_report_path}")
        print(f"âœ… Individual reports saved: {self.audit_reports_path}")
        
        return self.audit_results


def main() -> None:
    """Main entry point for GL Governance Audit."""
    # Determine base path
    script_dir = Path(__file__).resolve().parent
    base_path = script_dir
    
    # Check if root directory exists
    root_path = base_path / "root"
    if not root_path.exists():
        print(f"Error: Root directory not found: {root_path}")
        sys.exit(1)
    
    # Run audit
    auditor = GLGovernanceAudit(base_path=str(base_path))
    results = auditor.run_audit()
    
    # Exit with appropriate code
    if results["summary"]["severity_breakdown"]["CRITICAL"] > 0:
        sys.exit(2)
    elif results["summary"]["severity_breakdown"]["HIGH"] > 0:
        sys.exit(1)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()
