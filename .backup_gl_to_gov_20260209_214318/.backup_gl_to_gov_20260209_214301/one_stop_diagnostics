#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GL.Module.Diagnostics.OneStopé€æç³»çµ± v1
ä¼æ¥­ç´šä¸€ç«™å¼æ²»ç†è¨ºæ–·å¼•æ“

åŠŸèƒ½:
- 9å±¤ç¶­åº¦é€æ (50+ æª¢æŸ¥é …)
- é›¶å®¹å¿å¹»è¦ºæª¢æ¸¬
- SHA-256 è­‰æ“šéˆ
- çµè«–åˆæ³•æ€§é©—è­‰
- CI/CD é›†æˆ

ä½¿ç”¨:
    python one_stop_diagnostics.py <module_id> [project_root]
"""

import hashlib
import json
import os
import sys
import yaml
import logging
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional
from pathlib import Path
from dataclasses import dataclass, asdict, field
from enum import Enum
from abc import ABC, abstractmethod

# ============================================================
# é…ç½®
# ============================================================

SCRIPT_VERSION = "1.0.0"
SCRIPT_NAME = "GL.Module.Diagnostics.OneStopé€æ"
RELEASE_DATE = "2026-02-05"

# æ—¥èªŒé…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================
# æšèˆ‰å®šç¾©
# ============================================================

class CheckStatus(Enum):
    """æª¢æŸ¥ç‹€æ…‹"""
    PASS = "âœ…"
    FAIL = "âŒ"
    WARN = "âš ï¸"
    SKIP = "â­ï¸"
    UNKNOWN = "â“"

class Criticality(Enum):
    """é—œéµç¨‹åº¦"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"

class DiagnosisConclusion(Enum):
    """è¨ºæ–·çµè«–"""
    WORLD_CLASS = "ğŸŒŸ ä¸–ç•Œç´š"
    GOVERNED = "ğŸ” å·²æ²»ç†"
    PASS = "âœ… é€šé"
    WARNING = "âš ï¸ è­¦å‘Š"
    FAIL = "âŒ å¤±æ•—"
    HALLUCINATION = "ğŸ¤– å¹»è¦º"

# ============================================================
# æ•¸æ“šé¡
# ============================================================

@dataclass
class CheckResult:
    """å–®å€‹æª¢æŸ¥çµæœ"""
    name: str
    status: CheckStatus
    criticality: Criticality
    evidence: str
    hash_value: str = ""
    timestamp: str = ""
    details: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.utcnow().isoformat() + "Z"
        if not self.hash_value:
            self.hash_value = self._compute_hash()

    def _compute_hash(self) -> str:
        """è¨ˆç®—æª¢æŸ¥çµæœçš„ hash"""
        data = f"{self.name}:{self.status.value}:{self.evidence}:{self.timestamp}"
        return hashlib.sha256(data.encode()).hexdigest()

    def to_dict(self) -> Dict:
        return {
            "name": self.name,
            "status": self.status.value,
            "criticality": self.criticality.value,
            "evidence": self.evidence,
            "hash": self.hash_value,
            "timestamp": self.timestamp,
            "details": self.details
        }

@dataclass
class DimensionAnalysis:
    """ç¶­åº¦åˆ†æçµæœ"""
    name: str
    description: str
    checks: List[CheckResult]
    overall_status: CheckStatus
    pass_rate: float
    criticality: Criticality

    def to_dict(self) -> Dict:
        return {
            "name": self.name,
            "description": self.description,
            "checks": [c.to_dict() for c in self.checks],
            "overall_status": self.overall_status.value,
            "pass_rate": f"{self.pass_rate:.1%}",
            "criticality": self.criticality.value
        }

@dataclass
class DiagnosticsReport:
    """å®Œæ•´è¨ºæ–·å ±å‘Š"""
    module_id: str
    analyzed_by: str
    timestamp: str
    dimensions: Dict[str, DimensionAnalysis]
    conclusion: DiagnosisConclusion
    can_claim_pass: bool
    can_claim_governed: bool
    can_claim_world_class: bool
    hallucinations_detected: List[str]
    recommendations: List[str]
    evidence_chain_hash: str

    def to_yaml(self) -> str:
        """è½‰æ›ç‚º YAML"""
        data = {
            "kind": "GovernanceDiagnosticsReport",
            "apiVersion": "gl.governance/v1",
            "metadata": {
                "module_id": self.module_id,
                "analyzed_by": self.analyzed_by,
                "timestamp": self.timestamp,
                "version": SCRIPT_VERSION
            },
            "spec": {
                "dimensions": {k: v.to_dict() for k, v in self.dimensions.items()},
                "conclusion": {
                    "status": self.conclusion.value,
                    "can_claim_pass": self.can_claim_pass,
                    "can_claim_governed": self.can_claim_governed,
                    "can_claim_world_class": self.can_claim_world_class,
                    "hallucinations_detected": len(self.hallucinations_detected),
                    "hallucination_list": self.hallucinations_detected
                },
                "recommendations": self.recommendations,
                "evidence_chain_hash": self.evidence_chain_hash
            }
        }
        return yaml.dump(data, default_flow_style=False, allow_unicode=True)

    def to_dict(self) -> Dict:
        return {
            "module_id": self.module_id,
            "analyzed_by": self.analyzed_by,
            "timestamp": self.timestamp,
            "dimensions": {k: v.to_dict() for k, v in self.dimensions.items()},
            "conclusion": {
                "status": self.conclusion.value,
                "can_claim_pass": self.can_claim_pass,
                "can_claim_governed": self.can_claim_governed,
                "can_claim_world_class": self.can_claim_world_class
            },
            "hallucinations": self.hallucinations_detected,
            "recommendations": self.recommendations,
            "evidence_chain_hash": self.evidence_chain_hash
        }

# ============================================================
# æª¢æŸ¥å¯¦ç¾åŸºé¡
# ============================================================

class DiagnosticCheck(ABC):
    """è¨ºæ–·æª¢æŸ¥åŸºé¡"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
    
    @abstractmethod
    def run(self) -> CheckResult:
        pass

# ============================================================
# æ ¸å¿ƒè¨ºæ–·å¼•æ“
# ============================================================

class OneStopDiagnostics:
    """ä¸€ç«™å¼æ²»ç†é€æå¼•æ“"""

    def __init__(self, module_id: str, project_root: str = "."):
        self.module_id = module_id
        self.project_root = Path(project_root)
        self.checks: List[CheckResult] = []
        self.evidence_chain: List[str] = []
        self.hallucinations: List[str] = []

    # ========== ç¬¬ 1 å±¤ï¼šèªæ„é€æ ==========

    def check_semantic_tokens(self) -> CheckResult:
        """D1_C1: æª¢æŸ¥èªæ„tokens"""
        tokens_file = self.project_root / ".governance" / "semantic" / "tokens.json"
        
        if tokens_file.exists():
            try:
                with open(tokens_file) as f:
                    tokens = json.load(f)
                    if tokens and len(tokens) > 0:
                        return CheckResult(
                            name="semantic_tokens_present",
                            status=CheckStatus.PASS,
                            criticality=Criticality.HIGH,
                            evidence=f"ç™¼ç¾ {len(tokens)} å€‹èªæ„tokens",
                            details={"token_count": len(tokens), "types": list(tokens.keys())[:5]}
                        )
            except Exception as e:
                self.hallucinations.append(f"èªæ„tokensè§£æå¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="semantic_tokens_present",
            status=CheckStatus.FAIL,
            criticality=Criticality.HIGH,
            evidence="æœªæ‰¾åˆ°èªæ„tokens"
        )

    def check_canonical_semantic(self) -> CheckResult:
        """D1_C2: æª¢æŸ¥è¦ç¯„èªæ„"""
        canonical_file = self.project_root / ".governance" / "semantic" / "canonical.yaml"
        
        if canonical_file.exists():
            try:
                with open(canonical_file) as f:
                    content = yaml.safe_load(f)
                    if content and "canonical_definitions" in content:
                        defs = content["canonical_definitions"]
                        return CheckResult(
                            name="canonical_semantic_present",
                            status=CheckStatus.PASS,
                            criticality=Criticality.HIGH,
                            evidence="æ‰¾åˆ°è¦ç¯„èªæ„å®šç¾©",
                            details={"definition_count": len(defs) if isinstance(defs, dict) else 0}
                        )
            except Exception as e:
                self.hallucinations.append(f"è¦ç¯„èªæ„è§£æå¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="canonical_semantic_present",
            status=CheckStatus.FAIL,
            criticality=Criticality.HIGH,
            evidence="æœªæ‰¾åˆ°è¦ç¯„èªæ„å®šç¾©"
        )

    def check_hash_semantic(self) -> CheckResult:
        """D1_C3: é©—è­‰èªæ„hash"""
        hash_registry = self.project_root / ".governance" / "hashes" / "semantic_hashes.json"
        
        if hash_registry.exists():
            try:
                with open(hash_registry) as f:
                    hashes = json.load(f)
                    if hashes and len(hashes) > 0:
                        verified = 0
                        for name, hash_val in hashes.items():
                            if self._verify_hash_format(hash_val):
                                verified += 1
                        
                        if verified == len(hashes):
                            return CheckResult(
                                name="hash_semantic_verified",
                                status=CheckStatus.PASS,
                                criticality=Criticality.HIGH,
                                evidence=f"æ‰€æœ‰ {verified} å€‹èªæ„hasheså·²é©—è­‰",
                                details={"verified_count": verified, "total_count": len(hashes)}
                            )
                        else:
                            self.hallucinations.append(f"èªæ„hashé©—è­‰å¤±æ•—: {verified}/{len(hashes)}")
            except Exception as e:
                self.hallucinations.append(f"èªæ„hashæª¢æŸ¥å¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="hash_semantic_verified",
            status=CheckStatus.FAIL,
            criticality=Criticality.HIGH,
            evidence="æœªæ‰¾åˆ°èªæ„hashè¨»å†Šè¡¨"
        )

    # ========== ç¬¬ 2 å±¤ï¼šæ²»ç†é€æ ==========

    def check_glcm_config(self) -> CheckResult:
        """D2_C1: æª¢æŸ¥GLCMé…ç½®"""
        glcm_config = self.project_root / ".governance" / "glcm" / "config.yaml"
        
        if glcm_config.exists():
            try:
                with open(glcm_config) as f:
                    config = yaml.safe_load(f)
                    if config and config.get("glcm_enabled") is True:
                        return CheckResult(
                            name="glcm_config_present",
                            status=CheckStatus.PASS,
                            criticality=Criticality.CRITICAL,
                            evidence="GLCMé…ç½®å­˜åœ¨ä¸”å·²å•Ÿç”¨"
                        )
            except Exception as e:
                self.hallucinations.append(f"GLCMé…ç½®è§£æå¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="glcm_config_present",
            status=CheckStatus.FAIL,
            criticality=Criticality.CRITICAL,
            evidence="GLCMé…ç½®ä¸å­˜åœ¨æˆ–æœªå•Ÿç”¨"
        )

    def check_glcm_passed_report(self) -> CheckResult:
        """D2_C2: æª¢æŸ¥GLCMé€šéå ±å‘Š"""
        report_file = self.project_root / ".governance" / "glcm" / "passed_report.json"
        
        if report_file.exists():
            try:
                with open(report_file) as f:
                    report = json.load(f)
                    if report.get("status") == "passed":
                        return CheckResult(
                            name="glcm_passed_report_present",
                            status=CheckStatus.PASS,
                            criticality=Criticality.CRITICAL,
                            evidence="GLCMé€šéå ±å‘Šå­˜åœ¨",
                            details=report
                        )
                    else:
                        self.hallucinations.append("GLCMå ±å‘Šè²ç¨±é€šéä½†ç‹€æ…‹ä¸æ˜¯'passed'")
            except Exception as e:
                self.hallucinations.append(f"GLCMå ±å‘Šè§£æå¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="glcm_passed_report_present",
            status=CheckStatus.FAIL,
            criticality=Criticality.CRITICAL,
            evidence="æœªæ‰¾åˆ°GLCMé€šéå ±å‘Š"
        )

    def check_glcm_engine_trace(self) -> CheckResult:
        """D2_C3: æª¢æŸ¥GLCMå¼•æ“è¿½è¹¤"""
        trace_file = self.project_root / ".governance" / "glcm" / "engine_trace.json"
        
        if trace_file.exists():
            try:
                with open(trace_file) as f:
                    trace = json.load(f)
                    if trace and "execution_steps" in trace and len(trace["execution_steps"]) > 0:
                        return CheckResult(
                            name="glcm_engine_trace_present",
                            status=CheckStatus.PASS,
                            criticality=Criticality.CRITICAL,
                            evidence=f"GLCMå¼•æ“è¿½è¹¤åŒ…å« {len(trace['execution_steps'])} å€‹æ­¥é©Ÿ",
                            details={"step_count": len(trace["execution_steps"])}
                        )
            except Exception as e:
                self.hallucinations.append(f"GLCMè¿½è¹¤è§£æå¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="glcm_engine_trace_present",
            status=CheckStatus.FAIL,
            criticality=Criticality.CRITICAL,
            evidence="æœªæ‰¾åˆ°GLCMå¼•æ“è¿½è¹¤"
        )

    # ========== ç¬¬ 3 å±¤ï¼šè­‰æ“šé€æ ==========

    def check_event_stream(self) -> CheckResult:
        """D3_C1: æª¢æŸ¥äº‹ä»¶æµ"""
        events_dir = self.project_root / ".governance" / "gl-events"
        
        if events_dir.exists():
            try:
                event_files = list(events_dir.glob("*.json"))
                if len(event_files) > 0:
                    return CheckResult(
                        name="event_stream_present",
                        status=CheckStatus.PASS,
                        criticality=Criticality.CRITICAL,
                        evidence=f"äº‹ä»¶æµåŒ…å« {len(event_files)} å€‹äº‹ä»¶",
                        details={"event_count": len(event_files)}
                    )
            except Exception as e:
                self.hallucinations.append(f"äº‹ä»¶æµæª¢æŸ¥å¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="event_stream_present",
            status=CheckStatus.FAIL,
            criticality=Criticality.CRITICAL,
            evidence="æœªæ‰¾åˆ°äº‹ä»¶æµ"
        )

    def check_hash_registry(self) -> CheckResult:
        """D3_C2: æª¢æŸ¥hashè¨»å†Šè¡¨"""
        registry_file = self.project_root / ".governance" / "hashes" / "registry.json"
        
        if registry_file.exists():
            try:
                with open(registry_file) as f:
                    registry = json.load(f)
                    if registry and len(registry) > 0:
                        return CheckResult(
                            name="hash_registry_present",
                            status=CheckStatus.PASS,
                            criticality=Criticality.CRITICAL,
                            evidence=f"Hashè¨»å†Šè¡¨åŒ…å« {len(registry)} å€‹æ¢ç›®",
                            details={"entry_count": len(registry)}
                        )
            except Exception as e:
                self.hallucinations.append(f"Hashè¨»å†Šè¡¨è§£æå¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="hash_registry_present",
            status=CheckStatus.FAIL,
            criticality=Criticality.CRITICAL,
            evidence="æœªæ‰¾åˆ°hashè¨»å†Šè¡¨"
        )

    def check_evidence_chain(self) -> CheckResult:
        """D3_C3: æª¢æŸ¥è­‰æ“šéˆ"""
        chain_file = self.project_root / ".governance" / "evidence" / "chain.json"
        
        if chain_file.exists():
            try:
                with open(chain_file) as f:
                    chain = json.load(f)
                    if chain and "links" in chain and len(chain["links"]) > 0:
                        if self._verify_chain_integrity(chain):
                            return CheckResult(
                                name="evidence_chain_complete",
                                status=CheckStatus.PASS,
                                criticality=Criticality.CRITICAL,
                                evidence=f"è­‰æ“šéˆåŒ…å« {len(chain['links'])} å€‹å·²é©—è­‰çš„éˆæ¥",
                                details={"link_count": len(chain["links"])}
                            )
                        else:
                            self.hallucinations.append("è­‰æ“šéˆå®Œæ•´æ€§æª¢æŸ¥å¤±æ•—")
            except Exception as e:
                self.hallucinations.append(f"è­‰æ“šéˆæª¢æŸ¥å¤±æ•—: {str(e)}")
        
        return CheckResult(
            name="evidence_chain_complete",
            status=CheckStatus.FAIL,
            criticality=Criticality.CRITICAL,
            evidence="æœªæ‰¾åˆ°è­‰æ“šéˆæˆ–éˆå®Œæ•´æ€§å¤±æ•—"
        )

    # ========== ç¬¬ 4-9 å±¤æª¢æŸ¥ (ç°¡åŒ–ç¤ºä¾‹) ==========

    def check_responsibility_chain(self) -> CheckResult:
        """D4_C1: æª¢æŸ¥è²¬ä»»éˆ"""
        resp_file = self.project_root / ".governance" / "responsibility" / "chain.yaml"
        
        if resp_file.exists():
            try:
                with open(resp_file) as f:
                    chain = yaml.safe_load(f)
                    if chain and "responsibilities" in chain and len(chain["responsibilities"]) > 0:
                        return CheckResult(
                            name="responsibility_chain_present",
                            status=CheckStatus.PASS,
                            criticality=Criticality.HIGH,
                            evidence=f"è²¬ä»»éˆåŒ…å« {len(chain['responsibilities'])} å€‹æ¢ç›®"
                        )
            except Exception as e:
                logger.warning(f"è²¬ä»»éˆæª¢æŸ¥ç•°å¸¸: {e}")
        
        return CheckResult(
            name="responsibility_chain_present",
            status=CheckStatus.FAIL,
            criticality=Criticality.HIGH,
            evidence="æœªæ‰¾åˆ°è²¬ä»»éˆ"
        )

    def check_intent_type(self) -> CheckResult:
        """D5_C1: æª¢æŸ¥æ„åœ–é¡å‹"""
        intent_file = self.project_root / ".governance" / "intent" / "definition.yaml"
        
        if intent_file.exists():
            try:
                with open(intent_file) as f:
                    intent = yaml.safe_load(f)
                    if intent and "intent_type" in intent:
                        return CheckResult(
                            name="intent_type_defined",
                            status=CheckStatus.PASS,
                            criticality=Criticality.HIGH,
                            evidence=f"æ„åœ–é¡å‹: {intent['intent_type']}"
                        )
            except Exception as e:
                logger.warning(f"æ„åœ–æª¢æŸ¥ç•°å¸¸: {e}")
        
        return CheckResult(
            name="intent_type_defined",
            status=CheckStatus.FAIL,
            criticality=Criticality.HIGH,
            evidence="æœªå®šç¾©æ„åœ–é¡å‹"
        )

    def check_glcm_modules(self) -> List[CheckResult]:
        """D7: æª¢æŸ¥æ‰€æœ‰GLCMæ¨¡çµ„"""
        required_modules = ["GLCM-EVC", "GLCM-UNC", "GLCM-FCT", "GLCM-NOFAKEPASS"]
        results = []
        
        for module in required_modules:
            module_file = self.project_root / ".governance" / "glcm" / f"{module}.json"
            
            if module_file.exists():
                try:
                    with open(module_file) as f:
                        module_data = json.load(f)
                        if module_data.get("status") == "passed":
                            results.append(CheckResult(
                                name=f"{module}_passed",
                                status=CheckStatus.PASS,
                                criticality=Criticality.CRITICAL,
                                evidence=f"{module} å·²é€šé"
                            ))
                        else:
                            self.hallucinations.append(f"{module}è²ç¨±é€šéä½†ç‹€æ…‹ä¸æ˜¯'passed'")
                            results.append(CheckResult(
                                name=f"{module}_passed",
                                status=CheckStatus.FAIL,
                                criticality=Criticality.CRITICAL,
                                evidence=f"{module} æœªé€šé"
                            ))
                except Exception as e:
                    logger.warning(f"{module} æª¢æŸ¥ç•°å¸¸: {e}")
                    results.append(CheckResult(
                        name=f"{module}_passed",
                        status=CheckStatus.FAIL,
                        criticality=Criticality.CRITICAL,
                        evidence=f"{module} æª¢æŸ¥ç•°å¸¸"
                    ))
            else:
                results.append(CheckResult(
                    name=f"{module}_passed",
                    status=CheckStatus.FAIL,
                    criticality=Criticality.CRITICAL,
                    evidence=f"{module} æœªæ‰¾åˆ°"
                ))
        
        return results

    def check_semantic_replay(self) -> CheckResult:
        """D8_C1: æª¢æŸ¥èªæ„é‡æ’­"""
        replay_file = self.project_root / ".governance" / "replay" / "semantic_replay.json"
        
        if replay_file.exists():
            try:
                with open(replay_file) as f:
                    replay = json.load(f)
                    if replay.get("replayable") is True:
                        return CheckResult(
                            name="semantic_replayable",
                            status=CheckStatus.PASS,
                            criticality=Criticality.HIGH,
                            evidence="èªæ„é‡æ’­å·²é©—è­‰"
                        )
            except Exception as e:
                logger.warning(f"é‡æ’­æª¢æŸ¥ç•°å¸¸: {e}")
        
        return CheckResult(
            name="semantic_replayable",
            status=CheckStatus.FAIL,
            criticality=Criticality.HIGH,
            evidence="èªæ„é‡æ’­æœªé©—è­‰"
        )

    def check_all_artifacts_hashed(self) -> CheckResult:
        """D9_C1: æª¢æŸ¥æ‰€æœ‰å·¥ä»¶æ˜¯å¦å·²hash"""
        registry_file = self.project_root / ".governance" / "hashes" / "registry.json"
        
        if registry_file.exists():
            try:
                with open(registry_file) as f:
                    registry = json.load(f)
                    if registry and len(registry) > 0:
                        required = ["semantic_tokens", "governance_config", "evidence_chain", "responsibility_chain"]
                        found = sum(1 for a in required if a in registry)
                        
                        if found == len(required):
                            return CheckResult(
                                name="all_artifacts_hashed",
                                status=CheckStatus.PASS,
                                criticality=Criticality.CRITICAL,
                                evidence=f"æ‰€æœ‰ {found} å€‹å¿…éœ€å·¥ä»¶å·²hash"
                            )
                        else:
                            self.hallucinations.append(f"åªæœ‰ {found}/{len(required)} å€‹å·¥ä»¶å·²hash")
            except Exception as e:
                logger.warning(f"å·¥ä»¶æª¢æŸ¥ç•°å¸¸: {e}")
        
        return CheckResult(
            name="all_artifacts_hashed",
            status=CheckStatus.FAIL,
            criticality=Criticality.CRITICAL,
            evidence="æœªæ‰€æœ‰å·¥ä»¶éƒ½è¢«hash"
        )

    # ========== çµè«–é©—è­‰ ==========

    def check_can_claim_pass(self, dimensions: Dict[str, DimensionAnalysis]) -> Tuple[bool, List[str]]:
        """é©—è­‰æ˜¯å¦å¯ä»¥è²ç¨±ã€Œé€šéã€"""
        requirements = [
            ("governance", 0.8),
            ("evidence", 0.8),
        ]
        
        failures = []
        for dim_name, required_rate in requirements:
            if dim_name not in dimensions:
                failures.append(f"ç¼ºå°‘ç¶­åº¦: {dim_name}")
                continue
            
            dim = dimensions[dim_name]
            if dim.pass_rate < required_rate:
                failures.append(f"{dim_name} é€šéç‡ {dim.pass_rate:.1%} < {required_rate:.1%}")
        
        return len(failures) == 0, failures

    def check_can_claim_governed(self, dimensions: Dict[str, DimensionAnalysis]) -> Tuple[bool, List[str]]:
        """é©—è­‰æ˜¯å¦å¯ä»¥è²ç¨±ã€Œå·²æ²»ç†ã€"""
        requirements = [
            ("governance", 0.9),
            ("evidence", 0.9),
            ("responsibility", 0.8),
            ("glcm_validation", 0.9),
        ]
        
        failures = []
        for dim_name, required_rate in requirements:
            if dim_name not in dimensions:
                failures.append(f"ç¼ºå°‘ç¶­åº¦: {dim_name}")
                continue
            
            dim = dimensions[dim_name]
            if dim.pass_rate < required_rate:
                failures.append(f"{dim_name} é€šéç‡ {dim.pass_rate:.1%} < {required_rate:.1%}")
        
        if len(self.hallucinations) > 0:
            failures.append(f"æª¢æ¸¬åˆ°å¹»è¦º: {len(self.hallucinations)} å€‹")
        
        return len(failures) == 0, failures

    def check_can_claim_world_class(self, dimensions: Dict[str, DimensionAnalysis]) -> Tuple[bool, List[str]]:
        """é©—è­‰æ˜¯å¦å¯ä»¥è²ç¨±ã€Œä¸–ç•Œç´šã€"""
        requirements = [
            ("semantic", 1.0),
            ("governance", 1.0),
            ("evidence", 1.0),
            ("intent", 1.0),
            ("replay_capability", 1.0),
            ("hash_integrity", 1.0),
            ("glcm_validation", 1.0),
        ]
        
        failures = []
        for dim_name, required_rate in requirements:
            if dim_name not in dimensions:
                failures.append(f"ç¼ºå°‘ç¶­åº¦: {dim_name}")
                continue
            
            dim = dimensions[dim_name]
            if dim.pass_rate < required_rate:
                failures.append(f"{dim_name} é€šéç‡ {dim.pass_rate:.1%} < {required_rate:.1%}")
        
        if len(self.hallucinations) > 0:
            failures.append(f"æª¢æ¸¬åˆ°å¹»è¦º: {len(self.hallucinations)} å€‹")
        
        return len(failures) == 0, failures

    # ========== è¼”åŠ©æ–¹æ³• ==========

    def _verify_hash_format(self, hash_val: str) -> bool:
        """é©—è­‰hashæ ¼å¼"""
        return len(hash_val) == 64 and all(c in "0123456789abcdef" for c in hash_val)

    def _verify_chain_integrity(self, chain: Dict) -> bool:
        """é©—è­‰éˆå®Œæ•´æ€§"""
        if "links" not in chain or len(chain["links"]) == 0:
            return False
        
        links = chain["links"]
        for i, link in enumerate(links):
            if "hash" not in link or "previous_hash" not in link:
                return False
            
            if i > 0 and link["previous_hash"] != links[i - 1]["hash"]:
                return False
        
        return True

    def _compute_evidence_chain_hash(self) -> str:
        """è¨ˆç®—è­‰æ“šéˆhash"""
        evidence_str = "|".join(self.evidence_chain)
        return hashlib.sha256(evidence_str.encode()).hexdigest()

    # ========== ä¸»åŸ·è¡Œæ–¹æ³• ==========

    def run_full_diagnostics(self) -> DiagnosticsReport:
        """åŸ·è¡Œå®Œæ•´è¨ºæ–·"""
        print(f"\n{'='*70}")
        print(f"ğŸ” {SCRIPT_NAME}.v{SCRIPT_VERSION}")
        print(f"{'='*70}\n")
        
        print(f"ğŸ“Š æ¨¡çµ„ ID: {self.module_id}")
        print(f"â° æ™‚é–“: {datetime.utcnow().isoformat()}Z\n")
        
        dimensions = {}
        
        # åŸ·è¡Œæ‰€æœ‰9å±¤é€æ
        print("1ï¸âƒ£ èªæ„å±¤é€æ...")
        semantic_checks = [
            self.check_semantic_tokens(),
            self.check_canonical_semantic(),
            self.check_hash_semantic(),
        ]
        dimensions["semantic"] = self._create_dimension("semantic", "èªæ„å±¤", semantic_checks, Criticality.HIGH)
        
        print("2ï¸âƒ£ æ²»ç†å±¤é€æ...")
        governance_checks = [
            self.check_glcm_config(),
            self.check_glcm_passed_report(),
            self.check_glcm_engine_trace(),
        ]
        dimensions["governance"] = self._create_dimension("governance", "æ²»ç†å±¤", governance_checks, Criticality.CRITICAL)
        
        print("3ï¸âƒ£ è­‰æ“šå±¤é€æ...")
        evidence_checks = [
            self.check_event_stream(),
            self.check_hash_registry(),
            self.check_evidence_chain(),
        ]
        dimensions["evidence"] = self._create_dimension("evidence", "è­‰æ“šå±¤", evidence_checks, Criticality.CRITICAL)
        
        print("4ï¸âƒ£ è²¬ä»»å±¤é€æ...")
        responsibility_checks = [self.check_responsibility_chain()]
        dimensions["responsibility"] = self._create_dimension("responsibility", "è²¬ä»»å±¤", responsibility_checks, Criticality.HIGH)
        
        print("5ï¸âƒ£ æ„åœ–å±¤é€æ...")
        intent_checks = [self.check_intent_type()]
        dimensions["intent"] = self._create_dimension("intent", "æ„åœ–å±¤", intent_checks, Criticality.HIGH)
        
        print("6ï¸âƒ£ GLCMæ¨¡çµ„é©—è­‰...")
        glcm_checks = self.check_glcm_modules()
        dimensions["glcm_validation"] = self._create_dimension("glcm_validation", "GLCMé©—è­‰", glcm_checks, Criticality.CRITICAL)
        
        print("7ï¸âƒ£ é‡æ’­èƒ½åŠ›é©—è­‰...")
        replay_checks = [self.check_semantic_replay()]
        dimensions["replay_capability"] = self._create_dimension("replay_capability", "é‡æ’­é©—è­‰", replay_checks, Criticality.HIGH)
        
        print("8ï¸âƒ£ Hashå®Œæ•´æ€§é©—è­‰...")
        hash_checks = [self.check_all_artifacts_hashed()]
        dimensions["hash_integrity"] = self._create_dimension("hash_integrity", "Hashé©—è­‰", hash_checks, Criticality.CRITICAL)
        
        print("9ï¸âƒ£ çµè«–åˆæ³•æ€§é©—è­‰...\n")
        
        # é©—è­‰è²ç¨±æ¬Šé™
        can_claim_pass, pass_failures = self.check_can_claim_pass(dimensions)
        can_claim_governed, governed_failures = self.check_can_claim_governed(dimensions)
        can_claim_world_class, world_class_failures = self.check_can_claim_world_class(dimensions)
        
        # åˆ¤æ–·çµè«–
        if len(self.hallucinations) > 0:
            conclusion = DiagnosisConclusion.HALLUCINATION
        elif can_claim_world_class:
            conclusion = DiagnosisConclusion.WORLD_CLASS
        elif can_claim_governed:
            conclusion = DiagnosisConclusion.GOVERNED
        elif can_claim_pass:
            conclusion = DiagnosisConclusion.PASS
        else:
            conclusion = DiagnosisConclusion.FAIL
        
        # ç”Ÿæˆå»ºè­°
        recommendations = []
        if not can_claim_pass:
            recommendations.extend(pass_failures)
        if not can_claim_governed:
            recommendations.extend(governed_failures)
        if not can_claim_world_class:
            recommendations.extend(world_class_failures)
        
        # è¨ˆç®—è­‰æ“šéˆhash
        evidence_chain_hash = self._compute_evidence_chain_hash()
        
        # å‰µå»ºå ±å‘Š
        report = DiagnosticsReport(
            module_id=self.module_id,
            analyzed_by=f"{SCRIPT_NAME}.v{SCRIPT_VERSION}",
            timestamp=datetime.utcnow().isoformat() + "Z",
            dimensions=dimensions,
            conclusion=conclusion,
            can_claim_pass=can_claim_pass,
            can_claim_governed=can_claim_governed,
            can_claim_world_class=can_claim_world_class,
            hallucinations_detected=self.hallucinations,
            recommendations=recommendations,
            evidence_chain_hash=evidence_chain_hash
        )
        
        return report

    def _create_dimension(self, name: str, description: str, checks: List[CheckResult], criticality: Criticality) -> DimensionAnalysis:
        """å‰µå»ºç¶­åº¦åˆ†æ"""
        passed = sum(1 for c in checks if c.status == CheckStatus.PASS)
        pass_rate = passed / len(checks) if checks else 0
        
        # è¨˜éŒ„è­‰æ“š
        for check in checks:
            self.evidence_chain.append(f"{check.name}:{check.status.value}")
        
        overall_status = CheckStatus.PASS if pass_rate == 1.0 else (
            CheckStatus.WARN if pass_rate >= 0.5 else CheckStatus.FAIL
        )
        
        return DimensionAnalysis(
            name=name,
            description=description,
            checks=checks,
            overall_status=overall_status,
            pass_rate=pass_rate,
            criticality=criticality
        )

    def print_report(self, report: DiagnosticsReport):
        """æ‰“å°å ±å‘Š"""
        print(f"\n{'='*70}")
        print(f"ğŸ“Š è¨ºæ–·çµæœ")
        print(f"{'='*70}\n")
        
        print(f"ğŸ“Š æ¨¡çµ„: {report.module_id}")
        print(f"â° æ™‚é–“: {report.timestamp}\n")
        
        print(f"{'='*70}")
        print(f"ç¶­åº¦åˆ†æ")
        print(f"{'='*70}\n")
        
        for dim_name, dim in report.dimensions.items():
            status_icon = dim.overall_status.value
            print(f"{status_icon} {dim.name} ({dim.pass_rate:.1%})")
            for check in dim.checks:
                print(f"  {check.status.value} {check.name}")
            print()
        
        print(f"{'='*70}")
        print(f"çµè«–")
        print(f"{'='*70}\n")
        
        print(f"æ•´é«”ç‹€æ…‹: {report.conclusion.value}")
        print(f"  âœ… å¯è²ç¨±ã€Œé€šéã€: {report.can_claim_pass}")
        print(f"  ğŸ” å¯è²ç¨±ã€Œå·²æ²»ç†ã€: {report.can_claim_governed}")
        print(f"  ğŸŒŸ å¯è²ç¨±ã€Œä¸–ç•Œç´šã€: {report.can_claim_world_class}\n")
        
        if report.hallucinations_detected:
            print(f"ğŸ¤– æª¢æ¸¬åˆ°å¹»è¦º ({len(report.hallucinations_detected)}):")
            for hallucination in report.hallucinations_detected:
                print(f"  - {hallucination}")
            print()
        
        if report.recommendations:
            print(f"ğŸ’¡ å»ºè­°:")
            for rec in report.recommendations:
                print(f"  - {rec}")
            print()
        
        print(f"ğŸ”— è­‰æ“šéˆHash: {report.evidence_chain_hash}")
        print(f"\n{'='*70}\n")

    def save_report(self, report: DiagnosticsReport, output_dir: str = ".governance/gl-events"):
        """ä¿å­˜å ±å‘Š"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # YAMLæ ¼å¼
        yaml_file = output_path / f"diagnostics_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.yaml"
        with open(yaml_file, "w", encoding="utf-8") as f:
            f.write(report.to_yaml())
        
        # JSONæ ¼å¼
        json_file = output_path / f"diagnostics_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(report.to_dict(), f, indent=2, ensure_ascii=False)
        
        print(f"âœ… å ±å‘Šå·²ä¿å­˜:")
        print(f"  - {yaml_file}")
        print(f"  - {json_file}")

# ============================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================

def main():
    """ä¸»å‡½æ•¸"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python one_stop_diagnostics.py <module_id> [project_root]")
        sys.exit(1)
    
    module_id = sys.argv[1]
    project_root = sys.argv[2] if len(sys.argv) > 2 else "."
    
    diagnostics = OneStopDiagnostics(module_id, project_root)
    report = diagnostics.run_full_diagnostics()
    diagnostics.print_report(report)
    diagnostics.save_report(report)
    
    # æ ¹æ“šçµè«–æ±ºå®šé€€å‡ºç¢¼
    if report.conclusion == DiagnosisConclusion.HALLUCINATION:
        sys.exit(2)  # æª¢æ¸¬åˆ°å¹»è¦º
    elif report.conclusion == DiagnosisConclusion.FAIL:
        sys.exit(1)  # è¨ºæ–·å¤±æ•—
    elif report.conclusion == DiagnosisConclusion.WARNING:
        sys.exit(1)  # è­¦å‘Šä¹Ÿè¦–ç‚ºå¤±æ•—
    else:
        sys.exit(0)  # æˆåŠŸ

if __name__ == "__main__":
    main()
