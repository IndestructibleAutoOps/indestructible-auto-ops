#!/usr/bin/env python3
"""
å…¨æ©Ÿå™¨è‡ªç† â€” è‡ªä¸»æƒæå¼•æ“ (Autonomous Scanner Engine)

æƒææ‰€æœ‰ 18 å€‹è²¬ä»»é‚Šç•Œç›®éŒ„ï¼Œç”¢ç”Ÿå®Œæ•´çš„æ²»ç†æƒæå ±å‘Šã€‚
é–‰ç’°è¨­è¨ˆï¼šsensing â†’ execution â†’ anchor â†’ feedback

åŠŸèƒ½ï¼š
  1. æ¨¡çµ„å­˜åœ¨æ€§æƒæ â€” é©—è­‰æ‰€æœ‰å·²è¨»å†Šæ¨¡çµ„ç›®éŒ„æ˜¯å¦å­˜åœ¨
  2. å¿…è¦å·¥ä»¶å®Œæ•´æ€§ â€” æª¢æŸ¥ README.md åŠæ ¸å¿ƒå­ç›®éŒ„
  3. é›œæ¹Šå®Œæ•´æ€§ â€” è¨ˆç®—æ¯å€‹é‚Šç•Œç›®éŒ„çš„ SHA-256 é›œæ¹Š
  4. èªç¾©ä¸€è‡´æ€§ â€” é©—è­‰èªç¾©æ¨¹é™„æ›
  5. è·¨é‚Šç•Œé•è¦åµæ¸¬ â€” æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æ”¾éŒ¯é‚Šç•Œ
  6. æ¼‚ç§»åµæ¸¬ â€” èˆ‡ä¸Šæ¬¡æƒææ¯”å°é›œæ¹Šè®ŠåŒ–
"""

import hashlib
import json
import os
import re
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å¸¸æ•¸å®šç¾©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

REGISTRY_PATH = "responsibility-governance-execution-boundary/registry/governance-modules.json"
REPORT_DIR = "responsibility-governance-sensing-boundary/report"
EVENT_STREAM = ".governance/event-stream.jsonl"
BASELINE_PATH = "responsibility-governance-anchor-boundary/baseline/governance-baseline.yaml"
HASH_SPEC_PATH = "responsibility-governance-anchor-boundary/hash-boundary/hash-spec.yaml"

# è·¨é‚Šç•Œé•è¦è¦å‰‡ï¼šå“ªäº›æª”æ¡ˆæ¨¡å¼ä¸æ‡‰å‡ºç¾åœ¨å“ªäº›é‚Šç•Œ
CROSS_BOUNDARY_RULES = {
    "responsibility-governance-anchor-boundary": {
        "forbidden_patterns": [r"\.sh$", r"\.py$", r"Dockerfile"],
        "reason": "anchor é‚Šç•Œç¦æ­¢å­˜æ”¾åŸ·è¡Œè…³æœ¬"
    },
    "responsibility-governance-specs-boundary": {
        "forbidden_patterns": [r"\.sh$", r"\.py$", r"Dockerfile", r"\.tmp$"],
        "reason": "specs é‚Šç•Œç¦æ­¢å­˜æ”¾åŸ·è¡Œè…³æœ¬æˆ–æš«å­˜æª”"
    },
    "responsibility-guardrails-boundary": {
        "forbidden_patterns": [r"scanner.*\.py$", r"scan.*\.sh$"],
        "reason": "guardrails é‚Šç•Œç¦æ­¢å­˜æ”¾æƒæè…³æœ¬ï¼Œæ‡‰æ”¾åœ¨ sensing"
    },
    "responsibility-gateway-boundary": {
        "forbidden_patterns": [r"deploy.*\.sh$", r"Dockerfile"],
        "reason": "gateway é‚Šç•Œç¦æ­¢å­˜æ”¾éƒ¨ç½²è…³æœ¬"
    },
    "responsibility-mnga-architecture-boundary": {
        "forbidden_patterns": [r"ops.*\.sh$", r"runbook.*\.yaml$"],
        "reason": "mnga é‚Šç•Œç¦æ­¢å­˜æ”¾é‹ç¶­æµç¨‹ï¼Œæ‡‰æ”¾åœ¨ mno-operations"
    },
    "responsibility-generation-boundary": {
        "forbidden_patterns": [r"\.bin$", r"\.tar\.gz$", r"\.zip$", r"\.jar$"],
        "reason": "generation é‚Šç•Œç¦æ­¢å­˜æ”¾äºŒé€²ä½å·¥ä»¶"
    },
    "responsibility-gcp-boundary": {
        "forbidden_patterns": [r"aws.*\.yaml$", r"azure.*\.yaml$"],
        "reason": "gcp é‚Šç•Œç¦æ­¢å­˜æ”¾ AWS/Azure é…ç½®"
    },
    "responsibility-global-policy-boundary": {
        "forbidden_patterns": [r"gcp.*\.yaml$", r"aws.*\.yaml$"],
        "reason": "global-policy é‚Šç•Œç¦æ­¢å­˜æ”¾ç‰¹å®šé›²ä¾›æ‡‰å•†é…ç½®"
    },
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å·¥å…·å‡½å¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_file_hash(path: Path) -> str:
    """è¨ˆç®—å–®ä¸€æª”æ¡ˆçš„ SHA-256 é›œæ¹Šã€‚"""
    digest = hashlib.sha256()
    with path.open("rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            digest.update(chunk)
    return digest.hexdigest()


def compute_directory_hash(directory: Path) -> str:
    """è¨ˆç®—ç›®éŒ„ä¸‹æ‰€æœ‰æª”æ¡ˆçš„ç¢ºå®šæ€§ SHA-256 é›œæ¹Šã€‚"""
    digest = hashlib.sha256()
    for file_path in sorted(p for p in directory.rglob("*") if p.is_file()):
        rel = str(file_path.relative_to(directory))
        digest.update(rel.encode("utf-8"))
        digest.update(compute_file_hash(file_path).encode("utf-8"))
    return digest.hexdigest()


def utc_now() -> str:
    """å–å¾— UTC ISO æ™‚é–“æˆ³ã€‚"""
    return datetime.now(timezone.utc).isoformat()


def load_registry(repo_root: Path) -> Dict[str, Any]:
    """è¼‰å…¥æ²»ç†æ¨¡çµ„è¨»å†Šè¡¨ã€‚"""
    registry_file = repo_root / REGISTRY_PATH
    if not registry_file.exists():
        print(f"[FATAL] è¨»å†Šè¡¨ä¸å­˜åœ¨: {registry_file}")
        sys.exit(1)
    with registry_file.open("r", encoding="utf-8") as f:
        return json.load(f)


def load_previous_scan(repo_root: Path) -> Optional[Dict[str, Any]]:
    """è¼‰å…¥ä¸Šæ¬¡æƒæå ±å‘Šä»¥é€²è¡Œæ¼‚ç§»åµæ¸¬ã€‚"""
    report_dir = repo_root / REPORT_DIR
    if not report_dir.exists():
        return None
    reports = sorted(report_dir.glob("scan-report-*.json"), reverse=True)
    if not reports:
        # å˜—è©¦è¼‰å…¥ scan-report.json
        fallback = report_dir / "scan-report.json"
        if fallback.exists():
            with fallback.open("r", encoding="utf-8") as f:
                return json.load(f)
        return None
    with reports[0].open("r", encoding="utf-8") as f:
        return json.load(f)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æƒæå™¨æ ¸å¿ƒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutonomousScanner:
    """å…¨è‡ªä¸»æƒæå¼•æ“ â€” é›¶äººé¡ä»‹å…¥ã€‚"""

    def __init__(self, repo_root: str | Path):
        self.repo_root = Path(repo_root).resolve()
        self.registry = load_registry(self.repo_root)
        self.modules = self.registry.get("modules", [])
        self.previous_scan = load_previous_scan(self.repo_root)
        self.scan_id = f"SCAN-{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%S')}"
        self.results: Dict[str, Any] = {
            "scan_id": self.scan_id,
            "timestamp": utc_now(),
            "scanner_version": "2.0.0",
            "mode": "autonomous",
            "repo_root": str(self.repo_root),
            "total_modules": len(self.modules),
            "modules": [],
            "summary": {},
            "violations": [],
            "drift_detected": [],
            "remediation_required": [],
        }

    def scan_all(self) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´æƒæã€‚"""
        print(f"[{self.scan_id}] å•Ÿå‹•å…¨è‡ªä¸»æƒæå¼•æ“...")
        print(f"[{self.scan_id}] å·²è¨»å†Šæ¨¡çµ„æ•¸: {len(self.modules)}")

        passed = 0
        failed = 0
        warnings = 0

        for module in self.modules:
            module_result = self._scan_module(module)
            self.results["modules"].append(module_result)

            status = module_result["status"]
            if status == "PASS":
                passed += 1
            elif status == "FAIL":
                failed += 1
            else:
                warnings += 1

        # è·¨é‚Šç•Œé•è¦æƒæ
        self._scan_cross_boundary_violations()

        # æ¼‚ç§»åµæ¸¬
        self._detect_drift()

        # å½™ç¸½
        self.results["summary"] = {
            "total": len(self.modules),
            "passed": passed,
            "failed": failed,
            "warnings": warnings,
            "pass_rate": round(passed / max(len(self.modules), 1) * 100, 2),
            "violations_count": len(self.results["violations"]),
            "drift_count": len(self.results["drift_detected"]),
            "remediation_count": len(self.results["remediation_required"]),
            "scan_completed_at": utc_now(),
        }

        print(f"\n[{self.scan_id}] æƒæå®Œæˆ:")
        print(f"  é€šé: {passed} | å¤±æ•—: {failed} | è­¦å‘Š: {warnings}")
        print(f"  é•è¦: {len(self.results['violations'])} | æ¼‚ç§»: {len(self.results['drift_detected'])}")

        return self.results

    def _scan_module(self, module: Dict[str, Any]) -> Dict[str, Any]:
        """æƒæå–®ä¸€æ²»ç†æ¨¡çµ„ã€‚"""
        module_id = module["id"]
        directory = module["directory"]
        module_path = self.repo_root / directory

        result: Dict[str, Any] = {
            "module_id": module_id,
            "directory": directory,
            "checks": [],
            "status": "PASS",
            "hash": None,
            "file_count": 0,
        }

        # æª¢æŸ¥ 1: ç›®éŒ„å­˜åœ¨æ€§
        exists = module_path.is_dir()
        result["checks"].append({
            "check": "directory_exists",
            "passed": exists,
            "detail": f"{'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}: {directory}",
        })
        if not exists:
            result["status"] = "FAIL"
            self.results["remediation_required"].append({
                "module_id": module_id,
                "issue": "ç›®éŒ„ä¸å­˜åœ¨",
                "action": f"mkdir -p {directory}",
                "severity": "CRITICAL",
            })
            return result

        # æª¢æŸ¥ 2: README.md å­˜åœ¨
        readme_exists = (module_path / "README.md").is_file()
        result["checks"].append({
            "check": "readme_exists",
            "passed": readme_exists,
            "detail": f"README.md {'å­˜åœ¨' if readme_exists else 'ç¼ºå¤±'}",
        })
        if not readme_exists:
            self.results["remediation_required"].append({
                "module_id": module_id,
                "issue": "ç¼ºå°‘ README.md",
                "action": f"generate_readme:{directory}",
                "severity": "HIGH",
            })

        # æª¢æŸ¥ 3: æª”æ¡ˆè¨ˆæ•¸
        files = list(module_path.rglob("*"))
        file_count = sum(1 for f in files if f.is_file())
        result["file_count"] = file_count
        has_content = file_count > 0
        result["checks"].append({
            "check": "has_content",
            "passed": has_content,
            "detail": f"æª”æ¡ˆæ•¸: {file_count}",
        })

        # æª¢æŸ¥ 4: é›œæ¹Šå®Œæ•´æ€§
        try:
            dir_hash = compute_directory_hash(module_path)
            result["hash"] = dir_hash
            result["checks"].append({
                "check": "hash_computed",
                "passed": True,
                "detail": f"SHA-256: {dir_hash[:16]}...",
            })
        except Exception as e:
            result["checks"].append({
                "check": "hash_computed",
                "passed": False,
                "detail": f"é›œæ¹Šè¨ˆç®—å¤±æ•—: {str(e)}",
            })

        # æª¢æŸ¥ 5: å­ç›®éŒ„çµæ§‹
        subdirs = [d.name for d in module_path.iterdir() if d.is_dir()]
        result["checks"].append({
            "check": "subdirectory_structure",
            "passed": len(subdirs) > 0 or file_count > 1,
            "detail": f"å­ç›®éŒ„: {subdirs}" if subdirs else "ç„¡å­ç›®éŒ„",
        })

        # æ±ºå®šæœ€çµ‚ç‹€æ…‹
        failed_checks = [c for c in result["checks"] if not c["passed"]]
        if any(c["check"] in ("directory_exists", "has_content") for c in failed_checks):
            result["status"] = "FAIL"
        elif failed_checks:
            result["status"] = "WARNING"

        status_icon = {"PASS": "âœ…", "FAIL": "âŒ", "WARNING": "âš ï¸"}
        print(f"  {status_icon.get(result['status'], '?')} {module_id}: {result['status']} ({file_count} files)")

        return result

    def _scan_cross_boundary_violations(self):
        """æƒæè·¨é‚Šç•Œé•è¦ã€‚"""
        print(f"\n[{self.scan_id}] æƒæè·¨é‚Šç•Œé•è¦...")

        for boundary_dir, rules in CROSS_BOUNDARY_RULES.items():
            boundary_path = self.repo_root / boundary_dir
            if not boundary_path.is_dir():
                continue

            for file_path in boundary_path.rglob("*"):
                if not file_path.is_file():
                    continue
                filename = file_path.name
                for pattern in rules["forbidden_patterns"]:
                    if re.search(pattern, filename):
                        violation = {
                            "boundary": boundary_dir,
                            "file": str(file_path.relative_to(self.repo_root)),
                            "pattern": pattern,
                            "reason": rules["reason"],
                            "severity": "HIGH",
                            "action": "move_to_correct_boundary",
                        }
                        self.results["violations"].append(violation)
                        print(f"  âš ï¸ é•è¦: {violation['file']} â€” {rules['reason']}")

    def _detect_drift(self):
        """èˆ‡ä¸Šæ¬¡æƒææ¯”å°ï¼Œåµæ¸¬é›œæ¹Šæ¼‚ç§»ã€‚"""
        if not self.previous_scan:
            print(f"\n[{self.scan_id}] ç„¡å…ˆå‰æƒæå ±å‘Šï¼Œè·³éæ¼‚ç§»åµæ¸¬")
            return

        print(f"\n[{self.scan_id}] åŸ·è¡Œæ¼‚ç§»åµæ¸¬...")
        prev_modules = {m["module_id"]: m for m in self.previous_scan.get("modules", [])}

        for current in self.results["modules"]:
            module_id = current["module_id"]
            prev = prev_modules.get(module_id)
            if not prev:
                continue

            current_hash = current.get("hash")
            prev_hash = prev.get("hash")

            if current_hash and prev_hash and current_hash != prev_hash:
                drift = {
                    "module_id": module_id,
                    "previous_hash": prev_hash[:16] + "...",
                    "current_hash": current_hash[:16] + "...",
                    "detected_at": utc_now(),
                }
                self.results["drift_detected"].append(drift)
                print(f"  ğŸ”„ æ¼‚ç§»åµæ¸¬: {module_id}")

    def save_report(self) -> Path:
        """å„²å­˜æƒæå ±å‘Šã€‚"""
        report_dir = self.repo_root / REPORT_DIR
        report_dir.mkdir(parents=True, exist_ok=True)

        # å„²å­˜å¸¶æ™‚é–“æˆ³çš„å ±å‘Š
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%S")
        report_file = report_dir / f"scan-report-{timestamp}.json"
        with report_file.open("w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        # åŒæ™‚å„²å­˜ç‚º scan-report.jsonï¼ˆæœ€æ–°ï¼‰
        latest_file = report_dir / "scan-report.json"
        with latest_file.open("w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"\n[{self.scan_id}] å ±å‘Šå·²å„²å­˜: {report_file}")
        return report_file

    def emit_event(self):
        """å°‡æƒæäº‹ä»¶å¯«å…¥æ²»ç†äº‹ä»¶æµã€‚"""
        event_file = self.repo_root / EVENT_STREAM
        event_file.parent.mkdir(parents=True, exist_ok=True)

        # è®€å–ç¾æœ‰äº‹ä»¶ä»¥å–å¾—ä¸‹ä¸€å€‹ event_id
        existing_events = []
        if event_file.exists():
            with event_file.open("r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:
                        try:
                            existing_events.append(json.loads(line))
                        except json.JSONDecodeError:
                            pass

        next_id = max((e.get("event_id", 0) for e in existing_events), default=0) + 1

        event = {
            "event_id": next_id,
            "timestamp": utc_now(),
            "event_type": "autonomous_scan_completed",
            "namespace": "/governance/sensing/",
            "layer": "sensing",
            "platform": "all",
            "era": "Era-1",
            "payload": {
                "scan_id": self.scan_id,
                "total_modules": self.results["summary"]["total"],
                "passed": self.results["summary"]["passed"],
                "failed": self.results["summary"]["failed"],
                "warnings": self.results["summary"]["warnings"],
                "violations": self.results["summary"]["violations_count"],
                "drift_count": self.results["summary"]["drift_count"],
                "pass_rate": self.results["summary"]["pass_rate"],
                "scanner_version": "2.0.0",
            },
        }

        with event_file.open("a", encoding="utf-8") as f:
            f.write(json.dumps(event, ensure_ascii=False) + "\n")

        print(f"[{self.scan_id}] äº‹ä»¶å·²å¯«å…¥: event_id={next_id}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸»ç¨‹å¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """ä¸»å…¥å£ã€‚"""
    # è‡ªå‹•åµæ¸¬ repo root
    repo_root = Path(__file__).resolve().parent.parent
    if not (repo_root / REGISTRY_PATH).exists():
        # å˜—è©¦å¾ CWD
        repo_root = Path.cwd()
    if not (repo_root / REGISTRY_PATH).exists():
        print("[FATAL] ç„¡æ³•æ‰¾åˆ°æ²»ç†æ¨¡çµ„è¨»å†Šè¡¨ï¼Œè«‹åœ¨ repo æ ¹ç›®éŒ„åŸ·è¡Œ")
        sys.exit(1)

    scanner = AutonomousScanner(repo_root)
    scanner.scan_all()
    scanner.save_report()
    scanner.emit_event()

    # å›å‚³é€€å‡ºç¢¼
    summary = scanner.results["summary"]
    if summary["failed"] > 0:
        print(f"\n[çµæœ] æƒæç™¼ç¾ {summary['failed']} å€‹å¤±æ•—æ¨¡çµ„ï¼Œéœ€è¦è£œæ•‘")
        sys.exit(1)
    elif summary["violations_count"] > 0:
        print(f"\n[çµæœ] æƒæç™¼ç¾ {summary['violations_count']} å€‹é•è¦ï¼Œéœ€è¦è™•ç†")
        sys.exit(1)
    else:
        print(f"\n[çµæœ] æ‰€æœ‰æ¨¡çµ„é€šéæƒæ âœ…")
        sys.exit(0)


if __name__ == "__main__":
    main()
