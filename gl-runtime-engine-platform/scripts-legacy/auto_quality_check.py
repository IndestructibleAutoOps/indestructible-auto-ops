#
# @GL-governed
# @GL-layer: gl-platform.gl-platform.governance
# @GL-semantic: auto-quality-check
# @GL-audit-trail: ../../engine/gl-platform.gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
#!/usr/bin/env python3
"""
è‡ªå‹•åŒ–ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥å·¥å…·
Automated Code Quality Check Tool
æ­¤è…³æœ¬è‡ªå‹•åŸ·è¡Œ PR-1-REVIEW-REPORT.md ä¸­è­˜åˆ¥çš„æ‰€æœ‰æª¢æŸ¥é …ç›®
This script automatically performs all checks identified in PR-1-REVIEW-REPORT.md
"""
# MNGA-002: Import organization needs review
import subprocess
import json
from pathlib import Path
from typing import Dict, Any
import argparse
from datetime import datetime
import ast  # Added for ast.literal_eval()
class QualityChecker:
    """è‡ªå‹•åŒ–å“è³ªæª¢æŸ¥å™¨"""
    def __init__(self, repo_root: Path):
        self.repo_root = repo_root
        self.results: Dict[str, Any] = {}
    def run_all_checks(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ‰€æœ‰æª¢æŸ¥"""
        print("ğŸš€ é–‹å§‹è‡ªå‹•åŒ–å“è³ªæª¢æŸ¥...")
        self.check_security()
        self.check_python_quality()
        self.check_typescript_quality()
        self.check_code_duplication()
        self.check_docstring_coverage()
        self.check_non_ascii_filenames()
        self.check_console_logs()
        self.check_eval_usage()
        self.generate_report()
        return self.results
    def check_security(self):
        """P0: å®‰å…¨æ€§æª¢æŸ¥"""
        print("\nğŸ”’ åŸ·è¡Œå®‰å…¨æ€§æª¢æŸ¥...")
        try:
            # ä½¿ç”¨ detect-secrets
            result = subprocess.run(
                ["detect-secrets", "scan"],
                capture_output=True,
                text=True,
                cwd=self.repo_root
            )
            secrets_found = "no secrets" not in result.stdout.lower()
            self.results["security"] = {
                "status": "âš ï¸ WARNING" if secrets_found else "âœ… PASS",
                "secrets_detected": secrets_found,
                "details": "è«‹å¯©æŸ¥åŒ…å«æ•æ„Ÿé—œéµå­—çš„æª”æ¡ˆ" if secrets_found else "æœªæª¢æ¸¬åˆ°æ˜é¡¯çš„ç§˜å¯†"
            }
        except FileNotFoundError:
            self.results["security"] = {
                "status": "âš ï¸ SKIP",
                "details": "detect-secrets æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install detect-secrets"
            }
    def check_python_quality(self):
        """P0: Python ç¨‹å¼ç¢¼å“è³ª"""
        print("\nğŸ æª¢æŸ¥ Python ç¨‹å¼ç¢¼å“è³ª...")
        # çµ±è¨ˆå‹åˆ¥æç¤º
        py_files = list(self.repo_root.glob("**/*.py"))
        total_files = len(py_files)
        files_with_type_hints = 0
        for py_file in py_files:
            try:
                content = py_file.read_text()
                # ä½¿ç”¨æ›´ç²¾ç¢ºçš„æ¨¡å¼æª¢æ¸¬å‡½å¼å›å‚³å‹åˆ¥æç¤º
                if "def " in content and "->" in content:
                    files_with_type_hints += 1
            except (UnicodeDecodeError, OSError, PermissionError):
                continue
        type_hint_coverage = (files_with_type_hints / total_files * 100) if total_files > 0 else 0
        self.results["python_quality"] = {
            "total_files": total_files,
            "files_with_type_hints": files_with_type_hints,
            "type_hint_coverage": f"{type_hint_coverage:.1f}%",
            "status": "âœ… PASS" if type_hint_coverage >= 90 else "âš ï¸ WARNING",
            "target": "90%"
        }
    def check_typescript_quality(self):
        """P1: TypeScript/JavaScript å“è³ª"""
        print("\nğŸ“˜ æª¢æŸ¥ TypeScript ç¨‹å¼ç¢¼å“è³ª...")
        ts_files = list(self.repo_root.glob("**/*.ts")) + list(self.repo_root.glob("**/*.tsx"))
        js_files = list(self.repo_root.glob("**/*.js")) + list(self.repo_root.glob("**/*.jsx"))
        self.results["typescript_quality"] = {
            "total_ts_files": len(ts_files),
            "total_js_files": len(js_files),
            "status": "âœ… PASS"
        }
    def check_code_duplication(self):
        """P0: ç¨‹å¼ç¢¼é‡è¤‡æª¢æŸ¥"""
        print("\nğŸ”„ æª¢æŸ¥ç¨‹å¼ç¢¼é‡è¤‡...")
        # æª¢æŸ¥å·²çŸ¥çš„é‡è¤‡æ¨¡çµ„
        duplicate_patterns = [
            "dependency-manager",
            "drone_system"
        ]
        duplicates_found = []
        for pattern in duplicate_patterns:
            matches = list(self.repo_root.glob(f"**/{pattern}"))
            if len(matches) > 1:
                duplicates_found.append({
                    "pattern": pattern,
                    "locations": [str(m.relative_to(self.repo_root)) for m in matches]
                })
        self.results["code_duplication"] = {
            "duplicates_found": len(duplicates_found),
            "details": duplicates_found,
            "status": "âš ï¸ WARNING" if duplicates_found else "âœ… PASS"
        }
    def check_docstring_coverage(self):
        """P1: Docstring è¦†è“‹ç‡"""
        print("\nğŸ“ æª¢æŸ¥ Docstring è¦†è“‹ç‡...")
        py_files = list(self.repo_root.glob("**/*.py"))
        files_with_docstrings = 0
        for py_file in py_files:
            try:
                content = py_file.read_text()
                # æª¢æ¸¬ï¼šæª”æ¡ˆåŒ…å« docstringsï¼ˆå¯èƒ½æœ‰èª¤å ±ï¼Œå»ºè­°ä½¿ç”¨ interrogateï¼‰
                if '"""' in content or "'''" in content:
                    files_with_docstrings += 1
            except (UnicodeDecodeError, OSError, PermissionError):
                continue
        coverage = (files_with_docstrings / len(py_files) * 100) if py_files else 0
        self.results["docstring_coverage"] = {
            "total_files": len(py_files),
            "files_with_docstrings": files_with_docstrings,
            "coverage": f"{coverage:.1f}%",
            "status": "âœ… PASS" if coverage >= 85 else "âš ï¸ WARNING",
            "target": "85%"
        }
    def check_non_ascii_filenames(self):
        """P1: é ASCII æª”åæª¢æŸ¥"""
        print("\nğŸŒ æª¢æŸ¥é ASCII æª”å...")
        non_ascii_files = []
        for path in self.repo_root.rglob("*"):
            if path.is_file():
                try:
                    path.name.encode('ascii')
                except UnicodeEncodeError:
                    non_ascii_files.append(str(path.relative_to(self.repo_root)))
        self.results["non_ascii_filenames"] = {
            "count": len(non_ascii_files),
            "files": non_ascii_files[:10],  # åªé¡¯ç¤ºå‰ 10 å€‹
            "status": "âš ï¸ WARNING" if non_ascii_files else "âœ… PASS"
        }
    def check_console_logs(self):
        """P1: Console.log æª¢æŸ¥"""
        print("\nğŸ–¥ï¸  æª¢æŸ¥ console.log ä½¿ç”¨...")
        files_with_console = []
        for ext in [".ts", ".tsx", ".js", ".jsx"]:
            for file_path in self.repo_root.glob(f"**/*{ext}"):
                try:
                    content = file_path.read_text()
                    if "console.log" in content:
                        files_with_console.append(str(file_path.relative_to(self.repo_root)))
                except (UnicodeDecodeError, OSError, PermissionError):
                    continue
        self.results["console_logs"] = {
            "count": len(files_with_console),
            "files": files_with_console[:20],  # åªé¡¯ç¤ºå‰ 20 å€‹
            "status": "âš ï¸ WARNING" if files_with_console else "âœ… PASS"
        }
    def check_eval_usage(self):
        """P1: eval() ä½¿ç”¨æª¢æŸ¥"""
        print("\nâš ï¸  æª¢æŸ¥ ast.literal_eval() ä½¿ç”¨...")
        files_with_eval = []
        for ext in [".py", ".ts", ".js"]:
            for file_path in self.repo_root.glob(f"**/*{ext}"):
                try:
                    content = file_path.read_text()
                    if "ast.literal_eval(" in content:
                        files_with_eval.append(str(file_path.relative_to(self.repo_root)))
                except (UnicodeDecodeError, OSError, PermissionError):
                    continue
        self.results["eval_usage"] = {
            "count": len(files_with_eval),
            "files": files_with_eval,
            "status": "âš ï¸ WARNING" if files_with_eval else "âœ… PASS"
        }
    def generate_report(self):
        """ç”Ÿæˆå ±å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š è‡ªå‹•åŒ–å“è³ªæª¢æŸ¥å ±å‘Š")
        print("="*80)
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": {},
            "details": self.results
        }
        # çµ±è¨ˆç‹€æ…‹
        total_checks = len(self.results)
        passed = sum(1 for r in self.results.values() if r.get("status") == "âœ… PASS")
        warnings = sum(1 for r in self.results.values() if r.get("status") == "âš ï¸ WARNING")
        report["summary"] = {
            "total_checks": total_checks,
            "passed": passed,
            "warnings": warnings,
            "pass_rate": f"{(passed/total_checks*100):.1f}%"
        }
        # è¼¸å‡ºåˆ°è¢å¹•
        print(f"\nç¸½æª¢æŸ¥é …ç›®: {total_checks}")
        print(f"é€šé: {passed}")
        print(f"è­¦å‘Š: {warnings}")
        print(f"é€šéç‡: {report['summary']['pass_rate']}")
        print("\nè©³ç´°çµæœ:")

        def _sanitize_log_entry(log_key: Any, log_value: Any) -> str:
            """
            å°‡è¦è¼¸å‡ºçš„å ±å‘Šé …ç›®é€²è¡ŒåŸºæœ¬æ·¨åŒ–ï¼Œé¿å…åœ¨æ—¥èªŒä¸­æ´©æ¼æ•æ„Ÿè³‡è¨Šã€‚
            åƒ…ç”¨æ–¼äººé¡å¯è®€çš„çµ‚ç«¯è¼¸å‡ºï¼Œä¸å½±éŸ¿ JSON å ±å‘Šå…§å®¹ã€‚
            """
            # Normalize key to string for checks
            key_str = str(log_key)
            sensitive_key_markers = [
                "secret", "token", "password", "passwd", "pwd",
                "key", "credential", "auth", "apikey"
            ]
            lower_key = key_str.lower()
            if any(marker in lower_key for marker in sensitive_key_markers):
                return f"{key_str}: [REDACTED FOR SECURITY]"
            # For large collections, only report sizes, not contents
            if isinstance(log_value, (list, dict, set, tuple)):
                try:
                    size = len(log_value)  # type: ignore[arg-type]
                except Exception:
                    return f"{key_str}: [Collection]"
                return f"{key_str}: [Collection with {size} items]"
            # For other values, avoid printing excessively long data
            value_str = str(log_value)
            if len(value_str) > 200:
                return f"{key_str}: {value_str[:200]}...[TRUNCATED]"
            return f"{key_str}: {value_str}"

        for check_name, result in self.results.items():
            print(f"\n{check_name.upper()}: {result.get('status', 'N/A')}")
            # åƒ…è¼¸å‡ºéæ•æ„Ÿä¸”å°äººé¡æœ‰ç”¨çš„æ‘˜è¦è³‡è¨Šï¼Œé¿å…å°‡å¯èƒ½åŒ…å«ç§˜å¯†çš„æ¬„ä½å¯«å…¥æ—¥èªŒ
            if check_name == "security":
                # å°å®‰å…¨æƒæï¼Œåªé¡¯ç¤ºå›ºå®šçš„é«˜å±¤æ¬¡æè¿°ï¼Œä¸æš´éœ²ä»»ä½•ä¾†è‡ªæƒæçµæœçš„åŸå§‹è³‡æ–™
                print("  - security scan executed; see JSON report for non-sensitive summary.")
                continue
            for key, value in result.items():
                if key == "status":
                    continue
                # Security: Suppress potentially sensitive data in logs
                sanitized = _sanitize_log_entry(key, value)
                print(f"  - {sanitized}")
        # å„²å­˜ JSON å ±å‘Š
        report_file = self.repo_root / "auto-quality-report.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… å ±å‘Šå·²å„²å­˜è‡³: {report_file}")
        # ç”Ÿæˆ Markdown å ±å‘Š
        self.generate_markdown_report(report)

    def _sanitize_value(self, key: str, value: Any) -> Any:
        """
        å®‰å…¨è™•ç†å³å°‡å¯«å…¥å ±å‘Šçš„æ¬„ä½å€¼ï¼Œé¿å…åœ¨å ±å‘Šä¸­å„²å­˜æ˜æ–‡æ•æ„Ÿè³‡è¨Šã€‚
        åƒ…ç”¨æ–¼æ ¼å¼åŒ–è¼¸å‡ºï¼Œä¸ä¿®æ”¹ self.results å…§çš„åŸå§‹è³‡æ–™çµæ§‹ã€‚
        """
        # ç²—ç•¥åˆ¤æ–·æ¬„ä½åç¨±æ˜¯å¦å¯èƒ½åŒ…å«æ•æ„Ÿè³‡è¨Š
        sensitive_key_indicators = [
            "secret",
            "token",
            "password",
            "passwd",
            "key",
            "credential",
            "api_key",
        ]
        lower_key = key.lower()
        if any(indicator in lower_key for indicator in sensitive_key_indicators):
            return "[REDACTED FOR SECURITY]"

        # å¦‚æœå€¼æœ¬èº«æ˜¯å­—ä¸²ï¼Œåšä¸€äº›åŸºæœ¬çš„æ•æ„Ÿå…§å®¹æª¢æŸ¥
        if isinstance(value, str):
            suspicious_markers = [
                "-----BEGIN",
                "PRIVATE KEY",
                "AWS",
                "AKIA",  # å¸¸è¦‹çš„ AWS Access Key é–‹é ­
            ]
            if any(marker in value for marker in suspicious_markers):
                return "[REDACTED FOR SECURITY]"
            # éé•·ä¸”ç„¡ç©ºç™½çš„å­—ä¸²ä¹Ÿå¯èƒ½æ˜¯ token/å¯†é‘°
            if len(value) > 80 and " " not in value:
                return "[REDACTED FOR SECURITY]"
            return value

        # å° list/dict é€²è¡Œéè¿´è™•ç†ï¼Œé¿å…å·¢ç‹€çµæ§‹ä¸­å‡ºç¾æ˜æ–‡æ•æ„Ÿè³‡è¨Š
        if isinstance(value, list):
            return [self._sanitize_value(f"{key}[{idx}]", v) for idx, v in enumerate(value)]
        if isinstance(value, dict):
            return {k: self._sanitize_value(f"{key}.{k}", v) for k, v in value.items()}

        # å…¶å®ƒå‹åˆ¥ç›´æ¥è¿”å›
        return value

    def generate_markdown_report(self, report: Dict):
        """ç”Ÿæˆ Markdown æ ¼å¼å ±å‘Š"""
        md_file = self.repo_root / "AUTO-QUALITY-REPORT.md"
        with open(md_file, "w", encoding="utf-8") as f:
            f.write("# è‡ªå‹•åŒ–å“è³ªæª¢æŸ¥å ±å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ™‚é–“**: {report['timestamp']}\n\n")
            f.write("## ğŸ“Š ç¸½è¦½\n\n")
            f.write(f"- ç¸½æª¢æŸ¥é …ç›®: {report['summary']['total_checks']}\n")
            f.write(f"- âœ… é€šé: {report['summary']['passed']}\n")
            f.write(f"- âš ï¸ è­¦å‘Š: {report['summary']['warnings']}\n")
            f.write(f"- é€šéç‡: {report['summary']['pass_rate']}\n\n")
            f.write("## ğŸ“‹ è©³ç´°çµæœ\n\n")
            for check_name, result in self.results.items():
                f.write(f"### {check_name.replace('_', ' ').title()}\n\n")
                f.write(f"**ç‹€æ…‹**: {result.get('status', 'N/A')}\n\n")
                for key, value in result.items():
                    if key != "status":
                        safe_value = self._sanitize_value(key, value)
                        # å¦‚æœæ˜¯é•·åˆ—è¡¨ï¼Œåªé¡¯ç¤ºçµ±è¨ˆè³‡è¨Šä»¥é¿å…è¼¸å‡ºéå¤šè³‡æ–™
                        if isinstance(safe_value, list) and len(safe_value) > 5:
                            f.write(f"- **{key}**: {len(safe_value)} é … (åƒ…é¡¯ç¤ºéƒ¨åˆ†)\n")
                        else:
                            f.write(f"- **{key}**: {safe_value}\n")
                f.write("\n")
            f.write("## ğŸ¯ å»ºè­°è¡Œå‹•\n\n")
            if self.results.get("security", {}).get("secrets_detected"):
                f.write("1. **é«˜å„ªå…ˆç´š**: å¯©æŸ¥ä¸¦ç§»é™¤ç¡¬ç·¨ç¢¼çš„ç§˜å¯†\n")
            # å®‰å…¨åœ°è§£æå‹åˆ¥æç¤ºè¦†è“‹ç‡
            type_hint_coverage_str = self.results.get("python_quality", {}).get("type_hint_coverage", "0%")
            try:
                type_hint_coverage = float(type_hint_coverage_str.rstrip("%"))
                if type_hint_coverage < 90:
                    f.write("2. **é«˜å„ªå…ˆç´š**: æå‡ Python å‹åˆ¥æç¤ºè¦†è“‹ç‡è‡³ 90%+\n")
            except (ValueError, AttributeError):
                pass
            if self.results.get("code_duplication", {}).get("duplicates_found", 0) > 0:
                f.write("3. **é«˜å„ªå…ˆç´š**: ç§»é™¤é‡è¤‡çš„ç¨‹å¼ç¢¼æ¨¡çµ„\n")
            if self.results.get("non_ascii_filenames", {}).get("count", 0) > 0:
                f.write("4. **ä¸­å„ªå…ˆç´š**: é‡æ–°å‘½åé ASCII æª”å\n")
            if self.results.get("console_logs", {}).get("count", 0) > 0:
                f.write("5. **ä¸­å„ªå…ˆç´š**: æ›¿æ› console.log ç‚ºçµæ§‹åŒ–æ—¥èªŒ\n")
            f.write("\nè©³ç´°æ”¹é€²è¨ˆåŠƒè«‹åƒè€ƒ: [PR-1-ACTION-PLAN.md](./PR-1-ACTION-PLAN.md)\n")
        print(f"âœ… Markdown å ±å‘Šå·²å„²å­˜è‡³: {md_file}")
def main():
    parser = argparse.ArgumentParser(description="è‡ªå‹•åŒ–ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥")
    parser.add_argument(
        "--repo-root",
        type=Path,
        default=Path.cwd(),
        help="å€‰åº«æ ¹ç›®éŒ„è·¯å¾‘"
    )
    args = parser.parse_args()
    checker = QualityChecker(args.repo_root)
    checker.run_all_checks()
if __name__ == "__main__":
    main()
