{
  "analysis_date": "2025-12-14",
  "source": "llm-stats.com/benchmarks/gsm8k",
  "total_models": 46,
  "open_source_models_count": 14,
  "benchmark_info": {
    "name": "GSM8K (Grade School Math 8K)",
    "description": "8.5K高质量语言多样性的小学数学应用题数据集，需要多步推理和基础算术运算",
    "score_range": "0.0 - 1.0 (准确率)",
    "paper_url": "https://arxiv.org/abs/2110.14168"
  },
  "top_performers": {
    "highest_score": 0.973,
    "highest_model": "Kimi K2 Instruct (Moonshot AI)",
    "open_source_highest": 0.968,
    "open_source_leader": "Llama 3.1 405B Instruct"
  },
  "open_source_models": {
    "llama_series": {
      "description": "Meta开发的Llama系列开源模型",
      "models": [
        {
          "rank": 4,
          "model_name": "Llama 3.1 405B Instruct",
          "developer": "Meta",
          "score": 0.968,
          "percentage": "96.8%",
          "category": "大语言模型"
        },
        {
          "rank": 22,
          "model_name": "Llama 3.1 Nemotron 70B Instruct",
          "developer": "NVIDIA",
          "score": 0.914,
          "percentage": "91.4%",
          "category": "大语言模型"
        },
        {
          "rank": 39,
          "model_name": "Llama 3.2 3B Instruct",
          "developer": "Meta",
          "score": 0.777,
          "percentage": "77.7%",
          "category": "轻量级模型"
        }
      ]
    },
    "qwen_series": {
      "description": "阿里巴巴云/千问团队开发的Qwen系列开源模型",
      "models": [
        {
          "rank": 7,
          "model_name": "Qwen2.5 32B Instruct",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.959,
          "percentage": "95.9%",
          "category": "大语言模型"
        },
        {
          "rank": 9,
          "model_name": "Qwen2.5 72B Instruct",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.958,
          "percentage": "95.8%",
          "category": "大语言模型"
        },
        {
          "rank": 12,
          "model_name": "Qwen2.5 14B Instruct",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.948,
          "percentage": "94.8%",
          "category": "中型模型"
        },
        {
          "rank": 16,
          "model_name": "Qwen3 235B A22B",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.944,
          "percentage": "94.4%",
          "category": "超大语言模型"
        },
        {
          "rank": 21,
          "model_name": "Qwen2.5 7B Instruct",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.916,
          "percentage": "91.6%",
          "category": "中型模型"
        },
        {
          "rank": 23,
          "model_name": "Qwen2.5-Coder 32B Instruct",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.911,
          "percentage": "91.1%",
          "category": "代码专用模型"
        },
        {
          "rank": 23,
          "model_name": "Qwen2 72B Instruct",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.911,
          "percentage": "91.1%",
          "category": "大语言模型"
        },
        {
          "rank": 29,
          "model_name": "Qwen2.5-Omni-7B",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.887,
          "percentage": "88.7%",
          "category": "多模态模型"
        },
        {
          "rank": 35,
          "model_name": "Qwen2.5-Coder 7B Instruct",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.839,
          "percentage": "83.9%",
          "category": "代码专用模型"
        },
        {
          "rank": 36,
          "model_name": "Qwen2 7B Instruct",
          "developer": "Alibaba Cloud / Qwen Team",
          "score": 0.823,
          "percentage": "82.3%",
          "category": "中型模型"
        }
      ]
    },
    "deepseek_series": {
      "description": "DeepSeek开发的DeepSeek系列开源模型",
      "models": [
        {
          "rank": 10,
          "model_name": "DeepSeek-V2.5",
          "developer": "DeepSeek",
          "score": 0.951,
          "percentage": "95.1%",
          "category": "大语言模型",
          "additional_info": {
            "context_window": "8K tokens",
            "pricing": "$0.14 per million input tokens",
            "release_date": "2024-05-08",
            "features": "集成通用和编码能力，优化人类偏好、写作和指令遵循",
            "other_benchmarks": {
              "MATH": "0.75",
              "MMLU": "0.80",
              "HumanEval": "0.89",
              "MT-Bench": "0.90/100"
            }
          }
        }
      ]
    }
  },
  "analysis_summary": {
    "key_findings": [
      "开源模型在GSM8K基准测试中表现强劲，共有14个开源模型进入前46名",
      "Llama 3.1 405B Instruct是开源模型中表现最好的，排名第4，分数0.968",
      "Qwen系列表现突出，共有10个模型上榜，是开源模型中数量最多的系列",
      "DeepSeek-V2.5排名第10，分数0.951，展现了优秀的数学推理能力",
      "开源模型覆盖了从轻量级3B到超大405B的各个规模段",
      "代码专用模型（如Qwen2.5-Coder系列）也展现出良好的数学推理能力"
    ],
    "performance_tiers": {
      "tier_1_excellent": {
        "score_range": "0.95+",
        "models": [
          "Llama 3.1 405B Instruct (0.968)",
          "Qwen2.5 32B Instruct (0.959)",
          "Qwen2.5 72B Instruct (0.958)",
          "DeepSeek-V2.5 (0.951)"
        ],
        "count": 4
      },
      "tier_2_very_good": {
        "score_range": "0.90-0.95",
        "models": [
          "Qwen2.5 14B Instruct (0.948)",
          "Qwen3 235B A22B (0.944)",
          "Qwen2.5 7B Instruct (0.916)",
          "Llama 3.1 Nemotron 70B Instruct (0.914)",
          "Qwen2.5-Coder 32B Instruct (0.911)",
          "Qwen2 72B Instruct (0.911)"
        ],
        "count": 6
      },
      "tier_3_good": {
        "score_range": "0.80-0.90",
        "models": [
          "Qwen2.5-Omni-7B (0.887)",
          "Qwen2.5-Coder 7B Instruct (0.839)",
          "Qwen2 7B Instruct (0.823)",
          "Llama 3.2 3B Instruct (0.777)"
        ],
        "count": 4
      }
    }
  },
  "methodology_notes": [
    "所有模型性能结果为自报告数据，目前未经验证",
    "GSM8K评估数学推理能力，需要多步推理和基础算术运算",
    "分数范围为0.0-1.0，表示解决数学问题的准确率",
    "开源模型定义为公开可用且可复现的模型"
  ]
}