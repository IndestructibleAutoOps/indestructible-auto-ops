#
# @GL-governed
# @GL-layer: GL30-49
# @GL-semantic: general
# @GL-audit-trail: ../../governance/GL_SEMANTIC_ANCHOR.json
#
"""
SelfAuditor - GLæ²»ç†åŸ·è¡Œå±¤çš„è‡ªæˆ‘å¯©è¨ˆçµ„ä»¶

è² è²¬å°AIåŠ©ç†çš„æ“ä½œæ­·å²é€²è¡ŒæŒçºŒå¯©è¨ˆï¼Œæª¢æŸ¥ï¼š
1. æ“ä½œæ˜¯å¦éµå®ˆæ²»ç†åˆç´„
2. å ±å‘Šæ˜¯å¦åŒ…å«è¶³å¤ çš„è­‰æ“š
3. æ˜¯å¦æœ‰é•ç¦çŸ­èª
4. æ²»ç†é•è¦è¶¨å‹¢åˆ†æ

åŠŸèƒ½ï¼š
- å®šæœŸæƒææ“ä½œæ—¥èªŒ
- è­˜åˆ¥æ²»ç†é•è¦
- ç”Ÿæˆå¯©è¨ˆå ±å‘Š
- è§¸ç™¼è‡ªå‹•ä¿®å¾©
- é•è¦è¶¨å‹¢åˆ†æ
"""

import os
import json
import yaml
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
from collections import defaultdict, Counter


class SelfAuditor:
    """GLæ²»ç†åŸ·è¡Œå±¤çš„è‡ªæˆ‘å¯©è¨ˆå™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–è‡ªæˆ‘å¯©è¨ˆå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾‘ï¼Œé»˜èªç‚º ecosystem/gates/self-auditor-config.yaml
        """
        if config_path is None:
            config_path = "ecosystem/gates/self-auditor-config.yaml"
        
        self.config_path = config_path
        self.config = self._load_config()
        
        # è¨­ç½®æ—¥èªŒç›®éŒ„
        self.audit_logs_dir = Path("ecosystem/logs/audit-logs")
        self.audit_logs_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¦æ­¢çŸ­èªåˆ—è¡¨ï¼ˆå¾gl-fact-pipelineè¦ç¯„ï¼‰
        self.forbidden_phrases = self.config.get('forbidden_phrases', [
            # CRITICALç´šåˆ¥ - çµ•å°ç¦æ­¢
            ("100% å®Œæˆ", "CRITICAL", "åŸºæ–¼å·²å¯¦ç¾çš„åŠŸèƒ½é›†"),
            ("å®Œå…¨ç¬¦åˆ", "CRITICAL", "åœ¨[æ–¹é¢]èˆ‡æ¨™æº–å°é½Š"),
            ("å·²å…¨éƒ¨å¯¦ç¾", "CRITICAL", "å·²å¯¦ç¾[å…·é«”åŠŸèƒ½åˆ—è¡¨]"),
            ("ä¸€å®š", "CRITICAL", "å»ºè­°/å¯èƒ½/æ ¹æ“šåˆ†æ"),
            ("å¿…é ˆ", "CRITICAL", "æ‡‰è©²/å»ºè­°/æ¨è–¦"),
            
            # HIGHç´šåˆ¥ - éœ€è¦é¿å…
            ("æ‡‰è©²æ˜¯", "HIGH", "æ ¹æ“š[è­‰æ“š]ï¼Œå»ºè­°"),
            ("å¯èƒ½æ˜¯", "HIGH", "åŸºæ–¼[è­‰æ“š]ï¼Œæ¨æ¸¬"),
            ("æˆ‘èªç‚º", "HIGH", "åŸºæ–¼[è­‰æ“š]ï¼Œåˆ†æè¡¨æ˜"),
            ("é¡¯ç„¶", "HIGH", "æ ¹æ“š[è­‰æ“š]"),
            ("æ¯«ç„¡ç–‘å•", "HIGH", "æ ¹æ“šè­‰æ“šåˆ†æ"),
            
            # MEDIUMç´šåˆ¥ - éœ€è¦æ”¹é€²
            ("æ‡‰è©²", "MEDIUM", "å»ºè­°"),
            ("å¯èƒ½", "MEDIUM", "å¯èƒ½å­˜åœ¨"),
            ("æˆ–è¨±", "MEDIUM", "å¯èƒ½"),
            ("å¤§æ¦‚", "MEDIUM", "å¤§ç´„"),
            
            # LOWç´šåˆ¥ - èªè¨€é¢¨æ ¼
            ("ä¼¼ä¹", "LOW", "çœ‹èµ·ä¾†"),
            ("çœ‹èµ·ä¾†", "LOW", "å¾åˆ†æä¾†çœ‹"),
            ("æ„Ÿè¦º", "LOW", "åˆ†æé¡¯ç¤º"),
        ])
        
        # è­‰æ“šè¦†è“‹ç‡é–¾å€¼
        self.evidence_coverage_threshold = self.config.get('evidence_coverage_threshold', 0.90)
        
        # å¯©è¨ˆæ­·å²
        self.audit_history: List[Dict] = []
        
    def _load_config(self) -> Dict:
        """åŠ è¼‰é…ç½®æ–‡ä»¶"""
        if os.path.exists(self.config_path):
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return {
            'audit_interval_hours': 24,
            'max_audit_days': 7,
            'forbidden_phrases': [],
            'evidence_coverage_threshold': 0.90,
            'trend_analysis_window_days': 30,
            'critical_violation_threshold': 5,
        }
    
    def scan_audit_logs(self, days: int = 7) -> List[Dict]:
        """
        æƒæå¯©è¨ˆæ—¥èªŒ
        
        Args:
            days: æƒææœ€è¿‘å¹¾å¤©çš„æ—¥èªŒ
            
        Returns:
            å¯©è¨ˆæ—¥èªŒåˆ—è¡¨
        """
        audit_logs = []
        cutoff_date = datetime.now() - timedelta(days=days)
        
        for log_file in self.audit_logs_dir.glob("*.json"):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    log = json.load(f)
                    
                    # æª¢æŸ¥æ—¥èªŒæ—¥æœŸ
                    log_date = datetime.fromisoformat(log.get('timestamp', ''))
                    if log_date >= cutoff_date:
                        audit_logs.append(log)
            except Exception as e:
                print(f"è®€å–æ—¥èªŒæ–‡ä»¶å¤±æ•— {log_file}: {e}")
        
        return audit_logs
    
    def check_forbidden_phrases(self, text: str) -> List[Dict]:
        """
        æª¢æŸ¥æ–‡æœ¬ä¸­çš„ç¦æ­¢çŸ­èª
        
        Args:
            text: è¦æª¢æŸ¥çš„æ–‡æœ¬
            
        Returns:
            é•è¦åˆ—è¡¨
        """
        violations = []
        
        for phrase, severity, replacement in self.forbidden_phrases:
            if phrase in text:
                # æ‰¾åˆ°æ‰€æœ‰å‡ºç¾ä½ç½®
                matches = list(re.finditer(re.escape(phrase), text))
                for match in matches:
                    violations.append({
                        'phrase': phrase,
                        'severity': severity,
                        'replacement': replacement,
                        'position': match.start(),
                        'context': text[max(0, match.start()-20):match.end()+20]
                    })
        
        return violations
    
    def calculate_evidence_coverage(self, report_text: str) -> float:
        """
        è¨ˆç®—è­‰æ“šè¦†è“‹ç‡
        
        Args:
            report_text: å ±å‘Šæ–‡æœ¬
            
        Returns:
            è¦†è“‹ç‡ï¼ˆ0.0-1.0ï¼‰
        """
        # è­‰æ“šéˆæ¥æ ¼å¼ï¼š[è­‰æ“š: path/to/file.yaml#L10-L15]
        evidence_pattern = r'\[è­‰æ“š:\s*[^\]]+\]'
        evidence_links = re.findall(evidence_pattern, report_text)
        
        # è¨ˆç®—è²æ˜å¥æ•¸ï¼ˆä»¥å¥è™Ÿã€å•è™Ÿã€æ„Ÿæ­è™Ÿçµå°¾ï¼‰
        statement_pattern = r'[^.!?ã€‚ï¼Ÿï¼]+[.!?ã€‚ï¼Ÿï¼]'
        statements = re.findall(statement_pattern, report_text)
        total_statements = len(statements)
        
        if total_statements == 0:
            return 0.0
        
        coverage = len(evidence_links) / total_statements
        return min(coverage, 1.0)
    
    def analyze_governance_compliance(self, audit_log: Dict) -> Dict:
        """
        åˆ†ææ²»ç†åˆè¦æ€§
        
        Args:
            audit_log: å¯©è¨ˆæ—¥èªŒ
            
        Returns:
            åˆè¦æ€§åˆ†æçµæœ
        """
        analysis = {
            'audit_id': audit_log.get('audit_id'),
            'timestamp': audit_log.get('timestamp'),
            'operation_type': audit_log.get('operation_type'),
            'compliance': {
                'status': 'COMPLIANT',
                'violations': []
            }
        }
        
        # æª¢æŸ¥è­‰æ“šéˆ
        if 'evidence_chain' in audit_log:
            evidence_chain = audit_log['evidence_chain']
            if not evidence_chain or len(evidence_chain) == 0:
                analysis['compliance']['violations'].append({
                    'rule': 'GA-003',
                    'description': 'ç¼ºå°‘è­‰æ“šéˆ',
                    'severity': 'CRITICAL'
                })
                analysis['compliance']['status'] = 'NON_COMPLIANT'
        
        # æª¢æŸ¥å ±å‘Šé©—è­‰
        if 'report_validation' in audit_log:
            validation = audit_log['report_validation']
            if validation.get('has_unverified_claims', False):
                analysis['compliance']['violations'].append({
                    'rule': 'GA-004',
                    'description': 'å ±å‘ŠåŒ…å«æœªé©—è­‰çš„è²æ˜',
                    'severity': 'CRITICAL'
                })
                analysis['compliance']['status'] = 'NON_COMPLIANT'
            
            evidence_coverage = validation.get('evidence_coverage', 0.0)
            if evidence_coverage < self.evidence_coverage_threshold:
                analysis['compliance']['violations'].append({
                    'rule': 'GA-003',
                    'description': f'è­‰æ“šè¦†è“‹ç‡ä¸è¶³: {evidence_coverage:.1%} < {self.evidence_coverage_threshold:.1%}',
                    'severity': 'HIGH'
                })
                if analysis['compliance']['status'] == 'COMPLIANT':
                    analysis['compliance']['status'] = 'WARNING'
            
            if validation.get('forbidden_phrase_violations'):
                analysis['compliance']['violations'].append({
                    'rule': 'GA-004',
                    'description': f'å ±å‘ŠåŒ…å«ç¦æ­¢çŸ­èª: {len(validation["forbidden_phrase_violations"])}å€‹',
                    'severity': 'HIGH'
                })
                if analysis['compliance']['status'] == 'COMPLIANT':
                    analysis['compliance']['status'] = 'WARNING'
        
        return analysis
    
    def audit_operation(self, operation_data: Dict) -> Dict:
        """
        å¯©è¨ˆå–®å€‹æ“ä½œ
        
        Args:
            operation_data: æ“ä½œæ•¸æ“š
            
        Returns:
            å¯©è¨ˆçµæœ
        """
        audit_result = {
            'audit_id': f"audit-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            'timestamp': datetime.now().isoformat(),
            'operation_type': operation_data.get('operation_type'),
            'operation_id': operation_data.get('operation_id'),
            'status': 'PASSED',
            'findings': [],
            'recommendations': []
        }
        
        # æª¢æŸ¥æ²»ç†åˆç´„å¼•ç”¨
        if 'governance_contracts' not in operation_data or not operation_data['governance_contracts']:
            audit_result['findings'].append({
                'type': 'MISSING_CONTRACTS',
                'severity': 'CRITICAL',
                'description': 'æ“ä½œæœªå¼•ç”¨ç›¸é—œæ²»ç†åˆç´„',
                'rule': 'GA-001'
            })
            audit_result['status'] = 'FAILED'
            audit_result['recommendations'].append(
                'è«‹åœ¨æ“ä½œå‰æŸ¥è©¢ä¸¦å¼•ç”¨ç›¸é—œçš„æ²»ç†åˆç´„'
            )
        
        # æª¢æŸ¥è­‰æ“šéˆ
        if 'evidence_chain' not in operation_data or not operation_data['evidence_chain']:
            audit_result['findings'].append({
                'type': 'MISSING_EVIDENCE',
                'severity': 'CRITICAL',
                'description': 'æ“ä½œç¼ºå°‘è­‰æ“šéˆ',
                'rule': 'GA-003'
            })
            audit_result['status'] = 'FAILED'
            audit_result['recommendations'].append(
                'è«‹æä¾›å®Œæ•´çš„è­‰æ“šéˆï¼ŒåŒ…æ‹¬æºæ–‡ä»¶ã€åˆç´„å¼•ç”¨ã€é©—è­‰è¼¸å‡ºç­‰'
            )
        
        # æª¢æŸ¥å ±å‘Šé©—è­‰
        if 'report' in operation_data:
            report_text = operation_data['report']
            
            # æª¢æŸ¥ç¦æ­¢çŸ­èª
            forbidden_violations = self.check_forbidden_phrases(report_text)
            if forbidden_violations:
                audit_result['findings'].append({
                    'type': 'FORBIDDEN_PHRASES',
                    'severity': 'HIGH',
                    'description': f'å ±å‘ŠåŒ…å« {len(forbidden_violations)} å€‹ç¦æ­¢çŸ­èª',
                    'details': forbidden_violations,
                    'rule': 'GA-004'
                })
                if audit_result['status'] == 'PASSED':
                    audit_result['status'] = 'WARNING'
                audit_result['recommendations'].append(
                    f'æ›¿æ›ç¦æ­¢çŸ­èªç‚ºæ›´ç²¾ç¢ºçš„è¡¨è¿°ï¼Œåƒè¦‹è©³ç´°é•è¦åˆ—è¡¨'
                )
            
            # æª¢æŸ¥è­‰æ“šè¦†è“‹ç‡
            evidence_coverage = self.calculate_evidence_coverage(report_text)
            if evidence_coverage < self.evidence_coverage_threshold:
                audit_result['findings'].append({
                    'type': 'LOW_EVIDENCE_COVERAGE',
                    'severity': 'HIGH',
                    'description': f'è­‰æ“šè¦†è“‹ç‡ä¸è¶³: {evidence_coverage:.1%} < {self.evidence_coverage_threshold:.1%}',
                    'rule': 'GA-003'
                })
                if audit_result['status'] == 'PASSED':
                    audit_result['status'] = 'WARNING'
                audit_result['recommendations'].append(
                    'å¢åŠ è­‰æ“šéˆæ¥ï¼Œç¢ºä¿è‡³å°‘90%çš„è²æ˜æœ‰è­‰æ“šæ”¯æŒ'
                )
        
        # ä¿å­˜å¯©è¨ˆçµæœ
        self.audit_history.append(audit_result)
        
        return audit_result
    
    def analyze_violation_trends(self, days: int = 30) -> Dict:
        """
        åˆ†æé•è¦è¶¨å‹¢
        
        Args:
            days: åˆ†ææœ€è¿‘å¹¾å¤©çš„æ•¸æ“š
            
        Returns:
            è¶¨å‹¢åˆ†æçµæœ
        """
        audit_logs = self.scan_audit_logs(days)
        
        # çµ±è¨ˆé•è¦é¡å‹
        violation_by_type = Counter()
        violation_by_severity = Counter()
        violation_by_operation = Counter()
        daily_violations = defaultdict(int)
        
        for log in audit_logs:
            # æª¢æŸ¥åˆè¦æ€§åˆ†æ
            compliance = log.get('compliance', {})
            violations = compliance.get('violations', [])
            
            for violation in violations:
                rule = violation.get('rule')
                severity = violation.get('severity')
                operation = log.get('operation_type')
                date = log.get('timestamp', '')[:10]
                
                violation_by_type[rule] += 1
                violation_by_severity[severity] += 1
                violation_by_operation[operation] += 1
                daily_violations[date] += 1
        
        # è¨ˆç®—è¶¨å‹¢
        trend = {
            'total_violations': sum(violation_by_type.values()),
            'by_type': dict(violation_by_type),
            'by_severity': dict(violation_by_severity),
            'by_operation': dict(violation_by_operation),
            'daily': dict(daily_violations),
            'trend_direction': 'UNKNOWN',
            'critical_findings': []
        }
        
        # åˆ†æè¶¨å‹¢æ–¹å‘
        if len(daily_violations) >= 2:
            recent_week = list(daily_violations.values())[-7:]
            previous_week = list(daily_violations.values())[-14:-7] if len(daily_violations) >= 14 else recent_week
            
            if len(recent_week) > 0 and len(previous_week) > 0:
                avg_recent = sum(recent_week) / len(recent_week)
                avg_previous = sum(previous_week) / len(previous_week)
                
                if avg_recent > avg_previous * 1.2:
                    trend['trend_direction'] = 'INCREASING'
                elif avg_recent < avg_previous * 0.8:
                    trend['trend_direction'] = 'DECREASING'
                else:
                    trend['trend_direction'] = 'STABLE'
        
        # è­˜åˆ¥é—œéµå•é¡Œ
        critical_threshold = self.config.get('critical_violation_threshold', 5)
        for rule, count in violation_by_type.items():
            if count >= critical_threshold:
                trend['critical_findings'].append({
                    'rule': rule,
                    'count': count,
                    'description': f'è¦å‰‡ {rule} é•è¦æ¬¡æ•¸è¶…éé–¾å€¼ {critical_threshold}'
                })
        
        return trend
    
    def generate_audit_report(self, days: int = 7) -> Dict:
        """
        ç”Ÿæˆå¯©è¨ˆå ±å‘Š
        
        Args:
            days: å ±å‘Šè¦†è“‹çš„å¤©æ•¸
            
        Returns:
            å¯©è¨ˆå ±å‘Š
        """
        audit_logs = self.scan_audit_logs(days)
        
        # çµ±è¨ˆæŒ‡æ¨™
        total_operations = len(audit_logs)
        compliant_operations = 0
        non_compliant_operations = 0
        warning_operations = 0
        
        violations_by_type = Counter()
        violations_by_severity = Counter()
        
        # åˆ†ææ¯å€‹æ“ä½œ
        for log in audit_logs:
            compliance = log.get('compliance', {})
            status = compliance.get('status', 'UNKNOWN')
            
            if status == 'COMPLIANT':
                compliant_operations += 1
            elif status == 'NON_COMPLIANT':
                non_compliant_operations += 1
            elif status == 'WARNING':
                warning_operations += 1
            
            # çµ±è¨ˆé•è¦
            for violation in compliance.get('violations', []):
                rule = violation.get('rule')
                severity = violation.get('severity')
                violations_by_type[rule] += 1
                violations_by_severity[severity] += 1
        
        # è¶¨å‹¢åˆ†æ
        trend = self.analyze_violation_trends(days)
        
        report = {
            'report_id': f"audit-report-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            'generated_at': datetime.now().isoformat(),
            'report_period_days': days,
            'summary': {
                'total_operations': total_operations,
                'compliant_operations': compliant_operations,
                'non_compliant_operations': non_compliant_operations,
                'warning_operations': warning_operations,
                'compliance_rate': compliant_operations / total_operations if total_operations > 0 else 0.0,
                'violation_count': sum(violations_by_type.values())
            },
            'violations': {
                'by_type': dict(violations_by_type),
                'by_severity': dict(violations_by_severity)
            },
            'trends': trend,
            'recommendations': self._generate_recommendations(trend, violations_by_type, violations_by_severity)
        }
        
        return report
    
    def _generate_recommendations(self, trend: Dict, by_type: Counter, by_severity: Counter) -> List[str]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []
        
        # åŸºæ–¼è¶¨å‹¢çš„å»ºè­°
        if trend['trend_direction'] == 'INCREASING':
            recommendations.append(
                'âš ï¸ é•è¦è¶¨å‹¢ä¸Šå‡ï¼Œå»ºè­°åŠ å¼·æ²»ç†åŸ¹è¨“å’Œå¯©æŸ¥æµç¨‹'
            )
        
        # åŸºæ–¼é—œéµå•é¡Œçš„å»ºè­°
        for finding in trend.get('critical_findings', []):
            recommendations.append(
                f"ğŸš¨ é—œéµå•é¡Œï¼š{finding['description']}"
            )
        
        # åŸºæ–¼é•è¦é¡å‹çš„å»ºè­°
        if 'GA-001' in by_type:
            recommendations.append(
                'å»ºè­°ï¼šåœ¨åŸ·è¡Œæ“ä½œå‰ï¼Œç¢ºä¿æŸ¥è©¢ä¸¦å¼•ç”¨ç›¸é—œæ²»ç†åˆç´„'
            )
        if 'GA-002' in by_type:
            recommendations.append(
                'å»ºè­°ï¼šä½¿ç”¨æ¨™æº–åŒ–é©—è­‰å·¥å…·ï¼Œç¢ºä¿æ²»ç†åˆç´„ç¬¦åˆæ€§'
            )
        if 'GA-003' in by_type:
            recommendations.append(
                'å»ºè­°ï¼šæä¾›å®Œæ•´çš„è­‰æ“šéˆï¼ŒåŒ…æ‹¬æºæ–‡ä»¶ã€åˆç´„å¼•ç”¨ã€é©—è­‰è¼¸å‡º'
            )
        if 'GA-004' in by_type:
            recommendations.append(
                'å»ºè­°ï¼šé¿å…ä½¿ç”¨ç¦æ­¢çŸ­èªï¼Œæä¾›åŸºæ–¼è­‰æ“šçš„æº–ç¢ºå ±å‘Š'
            )
        
        # åŸºæ–¼åš´é‡ç¨‹åº¦çš„å»ºè­°
        if by_severity.get('CRITICAL', 0) > 0:
            recommendations.append(
                'ğŸš¨ ç™¼ç¾CRITICALç´šåˆ¥é•è¦ï¼Œéœ€è¦ç«‹å³è™•ç†'
            )
        if by_severity.get('HIGH', 0) > 5:
            recommendations.append(
                'âš ï¸ HIGHç´šåˆ¥é•è¦è¼ƒå¤šï¼Œå»ºè­°å„ªå…ˆè™•ç†'
            )
        
        return recommendations
    
    def save_audit_report(self, report: Dict, filename: Optional[str] = None) -> str:
        """
        ä¿å­˜å¯©è¨ˆå ±å‘Š
        
        Args:
            report: å¯©è¨ˆå ±å‘Š
            filename: æ–‡ä»¶åï¼Œé»˜èªä½¿ç”¨å ±å‘ŠID
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾‘
        """
        if filename is None:
            filename = f"{report['report_id']}.json"
        
        filepath = self.audit_logs_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        return str(filepath)
    
    def trigger_auto_remediation(self, violations: List[Dict]) -> List[Dict]:
        """
        è§¸ç™¼è‡ªå‹•ä¿®å¾©ï¼ˆå¯é¸åŠŸèƒ½ï¼‰
        
        Args:
            violations: é•è¦åˆ—è¡¨
            
        Returns:
            ä¿®å¾©çµæœåˆ—è¡¨
        """
        remediation_results = []
        
        # é€™è£¡å¯ä»¥å¯¦ç¾è‡ªå‹•ä¿®å¾©é‚è¼¯
        # ä¾‹å¦‚ï¼šè‡ªå‹•æ·»åŠ è­‰æ“šéˆæ¥ã€æ›¿æ›ç¦æ­¢çŸ­èªç­‰
        
        return remediation_results


def main():
    """æ¸¬è©¦SelfAuditor"""
    print("=== SelfAuditor æ¸¬è©¦ ===\n")
    
    # å‰µå»ºå¯©è¨ˆå™¨
    auditor = SelfAuditor()
    
    # æ¸¬è©¦ç¦æ­¢çŸ­èªæª¢æŸ¥
    print("1. æ¸¬è©¦ç¦æ­¢çŸ­èªæª¢æŸ¥")
    test_text = "é€™å€‹é …ç›®å·²ç¶“100%å®Œæˆäº†ï¼Œå®Œå…¨ç¬¦åˆæ¨™æº–ï¼Œå¿…é ˆæˆåŠŸã€‚"
    violations = auditor.check_forbidden_phrases(test_text)
    print(f"   ç™¼ç¾ {len(violations)} å€‹é•è¦:")
    for v in violations[:3]:
        print(f"   - '{v['phrase']}' ({v['severity']}) -> '{v['replacement']}'")
    print()
    
    # æ¸¬è©¦è­‰æ“šè¦†è“‹ç‡è¨ˆç®—
    print("2. æ¸¬è©¦è­‰æ“šè¦†è“‹ç‡è¨ˆç®—")
    report_text = """
    æ ¹æ“šGLæ²»ç†åˆç´„[è­‰æ“š: ecosystem/contracts/platforms/gl-platforms.yaml]ï¼Œ
    è©²å¹³å°ç¬¦åˆæ¨™æº–ã€‚
    å¦å¤–ï¼Œæ–‡ä»¶[è­‰æ“š: gl-platforms.yaml#L10-L20]ä¹Ÿç¢ºèªäº†é€™ä¸€é»ã€‚
    ç¬¬ä¸‰å€‹é»æ˜¯åŸºæ–¼é©—è­‰çµæœ[è­‰æ“š: validation/output.json]ã€‚
    """
    coverage = auditor.calculate_evidence_coverage(report_text)
    print(f"   è­‰æ“šè¦†è“‹ç‡: {coverage:.1%}")
    print(f"   é–¾å€¼: {auditor.evidence_coverage_threshold:.1%}")
    print(f"   ç‹€æ…‹: {'âœ… é€šé' if coverage >= auditor.evidence_coverage_threshold else 'âŒ æœªé€šé'}")
    print()
    
    # æ¸¬è©¦æ“ä½œå¯©è¨ˆ
    print("3. æ¸¬è©¦æ“ä½œå¯©è¨ˆ")
    test_operation = {
        'operation_type': 'file_migration',
        'operation_id': 'test-001',
        'governance_contracts': ['file-naming-content-contract.yaml'],
        'evidence_chain': [
            {'type': 'source_file', 'path': 'ecosystem/contracts/governance/file-naming-content-contract.yaml'}
        ],
        'report': 'æ ¹æ“šæ²»ç†åˆç´„[è­‰æ“š: file-naming-content-contract.yaml]ï¼Œè©²æ“ä½œç¬¦åˆè¦ç¯„ã€‚'
    }
    audit_result = auditor.audit_operation(test_operation)
    print(f"   å¯©è¨ˆID: {audit_result['audit_id']}")
    print(f"   ç‹€æ…‹: {audit_result['status']}")
    print(f"   ç™¼ç¾: {len(audit_result['findings'])} å€‹")
    for finding in audit_result['findings']:
        print(f"   - {finding['type']}: {finding['description']}")
    print()
    
    # æ¸¬è©¦ç”Ÿæˆå¯©è¨ˆå ±å‘Š
    print("4. æ¸¬è©¦ç”Ÿæˆå¯©è¨ˆå ±å‘Š")
    report = auditor.generate_audit_report(days=7)
    print(f"   å ±å‘ŠID: {report['report_id']}")
    print(f"   ç¸½æ“ä½œæ•¸: {report['summary']['total_operations']}")
    print(f"   åˆè¦ç‡: {report['summary']['compliance_rate']:.1%}")
    print(f"   é•è¦æ•¸: {report['summary']['violation_count']}")
    print(f"   è¶¨å‹¢: {report['trends']['trend_direction']}")
    print()
    
    # ä¿å­˜å ±å‘Š
    report_path = auditor.save_audit_report(report)
    print(f"   å ±å‘Šå·²ä¿å­˜: {report_path}")
    print()
    
    print("=== SelfAuditor æ¸¬è©¦å®Œæˆ ===")


if __name__ == "__main__":
    main()